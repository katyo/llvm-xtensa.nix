--- llvm-10.0.1.src/include/llvm/ADT/Triple.h
+++ llvm-10.0.1.src~patched/include/llvm/ADT/Triple.h
@@ -78,6 +78,7 @@ public:
     x86,            // X86: i[3-9]86
     x86_64,         // X86-64: amd64, x86_64
     xcore,          // XCore: xcore
+    xtensa,         // Tensilica Xtensa
     nvptx,          // NVPTX: 32-bit
     nvptx64,        // NVPTX: 64-bit
     le32,           // le32: generic little-endian 32-bit CPU (PNaCl)
--- llvm-10.0.1.src/include/llvm/BinaryFormat/ELF.h
+++ llvm-10.0.1.src~patched/include/llvm/BinaryFormat/ELF.h
@@ -767,6 +767,21 @@ enum {
 #include "ELFRelocs/MSP430.def"
 };
 
+// Xtensa specific e_flags
+enum : unsigned {
+  // Four-bit Xtensa machine type mask.
+  EF_XTENSA_MACH = 0x0000000f,
+  // Various CPU types.
+  EF_XTENSA_MACH_NONE = 0x00000000, //A base Xtensa implementation
+  EF_XTENSA_XT_INSN = 0x00000100,
+  EF_XTENSA_XT_LIT = 0x00000200,
+};
+
+// ELF Relocation types for Xtensa
+enum {
+#include "ELFRelocs/Xtensa.def"
+};
+
 #undef ELF_RELOC
 
 // Section header.
--- /dev/null
+++ llvm-10.0.1.src~patched/include/llvm/BinaryFormat/ELFRelocs/Xtensa.def
@@ -0,0 +1,59 @@
+#ifndef ELF_RELOC
+#error "ELF_RELOC must be defined"
+#endif
+
+ELF_RELOC (R_XTENSA_NONE, 0)
+ELF_RELOC (R_XTENSA_32, 1)
+ELF_RELOC (R_XTENSA_RTLD, 2)
+ELF_RELOC (R_XTENSA_GLOB_DAT, 3)
+ELF_RELOC (R_XTENSA_JMP_SLOT, 4)
+ELF_RELOC (R_XTENSA_RELATIVE, 5)
+ELF_RELOC (R_XTENSA_PLT, 6)
+ELF_RELOC (R_XTENSA_OP0, 8)
+ELF_RELOC (R_XTENSA_OP1, 9)
+ELF_RELOC (R_XTENSA_OP2, 10)
+ELF_RELOC (R_XTENSA_ASM_EXPAND, 11)
+ELF_RELOC (R_XTENSA_ASM_SIMPLIFY, 12)
+ELF_RELOC (R_XTENSA_32_PCREL, 14)
+ELF_RELOC (R_XTENSA_GNU_VTINHERIT, 15)
+ELF_RELOC (R_XTENSA_GNU_VTENTRY, 16)
+ELF_RELOC (R_XTENSA_DIFF8, 17)
+ELF_RELOC (R_XTENSA_DIFF16, 18)
+ELF_RELOC (R_XTENSA_DIFF32, 19)
+ELF_RELOC (R_XTENSA_SLOT0_OP, 20)
+ELF_RELOC (R_XTENSA_SLOT1_OP, 21)
+ELF_RELOC (R_XTENSA_SLOT2_OP, 22)
+ELF_RELOC (R_XTENSA_SLOT3_OP, 23)
+ELF_RELOC (R_XTENSA_SLOT4_OP, 24)
+ELF_RELOC (R_XTENSA_SLOT5_OP, 25)
+ELF_RELOC (R_XTENSA_SLOT6_OP, 26)
+ELF_RELOC (R_XTENSA_SLOT7_OP, 27)
+ELF_RELOC (R_XTENSA_SLOT8_OP, 28)
+ELF_RELOC (R_XTENSA_SLOT9_OP, 29)
+ELF_RELOC (R_XTENSA_SLOT10_OP, 30)
+ELF_RELOC (R_XTENSA_SLOT11_OP, 31)
+ELF_RELOC (R_XTENSA_SLOT12_OP, 32)
+ELF_RELOC (R_XTENSA_SLOT13_OP, 33)
+ELF_RELOC (R_XTENSA_SLOT14_OP, 34)
+ELF_RELOC (R_XTENSA_SLOT0_ALT, 35)
+ELF_RELOC (R_XTENSA_SLOT1_ALT, 36)
+ELF_RELOC (R_XTENSA_SLOT2_ALT, 37)
+ELF_RELOC (R_XTENSA_SLOT3_ALT, 38)
+ELF_RELOC (R_XTENSA_SLOT4_ALT, 39)
+ELF_RELOC (R_XTENSA_SLOT5_ALT, 40)
+ELF_RELOC (R_XTENSA_SLOT6_ALT, 41)
+ELF_RELOC (R_XTENSA_SLOT7_ALT, 42)
+ELF_RELOC (R_XTENSA_SLOT8_ALT, 43)
+ELF_RELOC (R_XTENSA_SLOT9_ALT, 44)
+ELF_RELOC (R_XTENSA_SLOT10_ALT, 45)
+ELF_RELOC (R_XTENSA_SLOT11_ALT, 46)
+ELF_RELOC (R_XTENSA_SLOT12_ALT, 47)
+ELF_RELOC (R_XTENSA_SLOT13_ALT, 48)
+ELF_RELOC (R_XTENSA_SLOT14_ALT, 49)
+ELF_RELOC (R_XTENSA_TLSDESC_FN, 50)
+ELF_RELOC (R_XTENSA_TLSDESC_ARG, 51)
+ELF_RELOC (R_XTENSA_TLS_DTPOFF, 52)
+ELF_RELOC (R_XTENSA_TLS_TPOFF, 53)
+ELF_RELOC (R_XTENSA_TLS_FUNC, 54)
+ELF_RELOC (R_XTENSA_TLS_ARG, 55)
+ELF_RELOC (R_XTENSA_TLS_CALL, 56)
--- llvm-10.0.1.src/include/llvm/IR/CMakeLists.txt
+++ llvm-10.0.1.src~patched/include/llvm/IR/CMakeLists.txt
@@ -18,4 +18,5 @@ tablegen(LLVM IntrinsicsS390.h -gen-intrinsic-enums -intrinsic-prefix=s390)
 tablegen(LLVM IntrinsicsWebAssembly.h -gen-intrinsic-enums -intrinsic-prefix=wasm)
 tablegen(LLVM IntrinsicsX86.h -gen-intrinsic-enums -intrinsic-prefix=x86)
 tablegen(LLVM IntrinsicsXCore.h -gen-intrinsic-enums -intrinsic-prefix=xcore)
+tablegen(LLVM IntrinsicsXtensa.h -gen-intrinsic-enums -intrinsic-prefix=xtensa)
 add_public_tablegen_target(intrinsics_gen)
--- llvm-10.0.1.src/include/llvm/IR/Intrinsics.td
+++ llvm-10.0.1.src~patched/include/llvm/IR/Intrinsics.td
@@ -1358,3 +1358,4 @@ include "llvm/IR/IntrinsicsBPF.td"
 include "llvm/IR/IntrinsicsSystemZ.td"
 include "llvm/IR/IntrinsicsWebAssembly.td"
 include "llvm/IR/IntrinsicsRISCV.td"
+include "llvm/IR/IntrinsicsXtensa.td"
--- /dev/null
+++ llvm-10.0.1.src~patched/include/llvm/IR/IntrinsicsXtensa.td
@@ -0,0 +1,251 @@
+//===- IntrinsicsXtensa.td - Defines Xtensa intrinsics -----*- tablegen -*-===//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file defines all of the Xtensa-specific intrinsics.
+//
+//===----------------------------------------------------------------------===//
+
+let TargetPrefix = "xtensa" in {  // All intrinsics start with "llvm.xtensa.".
+
+def int_xtensa_umul_aa_ll: GCCBuiltin<"__builtin_xtensa_umul_aa_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_umul_aa_hl: GCCBuiltin<"__builtin_xtensa_umul_aa_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_umul_aa_lh: GCCBuiltin<"__builtin_xtensa_umul_aa_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_umul_aa_hh: GCCBuiltin<"__builtin_xtensa_umul_aa_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+
+def int_xtensa_mul_aa_ll: GCCBuiltin<"__builtin_xtensa_mul_aa_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_mul_aa_hl: GCCBuiltin<"__builtin_xtensa_mul_aa_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_mul_aa_lh: GCCBuiltin<"__builtin_xtensa_mul_aa_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_mul_aa_hh: GCCBuiltin<"__builtin_xtensa_mul_aa_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+
+def int_xtensa_mul_ad_ll: GCCBuiltin<"__builtin_xtensa_mul_ad_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+def int_xtensa_mul_ad_hl: GCCBuiltin<"__builtin_xtensa_mul_ad_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+def int_xtensa_mul_ad_lh: GCCBuiltin<"__builtin_xtensa_mul_ad_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+def int_xtensa_mul_ad_hh: GCCBuiltin<"__builtin_xtensa_mul_ad_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+
+def int_xtensa_mul_da_ll: GCCBuiltin<"__builtin_xtensa_mul_da_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+def int_xtensa_mul_da_hl: GCCBuiltin<"__builtin_xtensa_mul_da_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+def int_xtensa_mul_da_lh: GCCBuiltin<"__builtin_xtensa_mul_da_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+def int_xtensa_mul_da_hh: GCCBuiltin<"__builtin_xtensa_mul_da_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+
+def int_xtensa_mul_dd_ll: GCCBuiltin<"__builtin_xtensa_mul_dd_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+def int_xtensa_mul_dd_hl: GCCBuiltin<"__builtin_xtensa_mul_dd_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+def int_xtensa_mul_dd_lh: GCCBuiltin<"__builtin_xtensa_mul_dd_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+def int_xtensa_mul_dd_hh: GCCBuiltin<"__builtin_xtensa_mul_dd_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+
+def int_xtensa_mula_aa_ll: GCCBuiltin<"__builtin_xtensa_mula_aa_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_mula_aa_hl: GCCBuiltin<"__builtin_xtensa_mula_aa_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_mula_aa_lh: GCCBuiltin<"__builtin_xtensa_mula_aa_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_mula_aa_hh: GCCBuiltin<"__builtin_xtensa_mula_aa_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+
+def int_xtensa_mula_ad_ll: GCCBuiltin<"__builtin_xtensa_mula_ad_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+def int_xtensa_mula_ad_hl: GCCBuiltin<"__builtin_xtensa_mula_ad_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+def int_xtensa_mula_ad_lh: GCCBuiltin<"__builtin_xtensa_mula_ad_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+def int_xtensa_mula_ad_hh: GCCBuiltin<"__builtin_xtensa_mula_ad_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+
+def int_xtensa_mula_da_ll: GCCBuiltin<"__builtin_xtensa_mula_da_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+def int_xtensa_mula_da_hl: GCCBuiltin<"__builtin_xtensa_mula_da_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+def int_xtensa_mula_da_lh: GCCBuiltin<"__builtin_xtensa_mula_da_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+def int_xtensa_mula_da_hh: GCCBuiltin<"__builtin_xtensa_mula_da_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+
+def int_xtensa_mula_dd_ll: GCCBuiltin<"__builtin_xtensa_mula_dd_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+def int_xtensa_mula_dd_hl: GCCBuiltin<"__builtin_xtensa_mula_dd_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+def int_xtensa_mula_dd_lh: GCCBuiltin<"__builtin_xtensa_mula_dd_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+def int_xtensa_mula_dd_hh: GCCBuiltin<"__builtin_xtensa_mula_dd_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+
+def int_xtensa_muls_aa_ll: GCCBuiltin<"__builtin_xtensa_muls_aa_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_muls_aa_hl: GCCBuiltin<"__builtin_xtensa_muls_aa_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_muls_aa_lh: GCCBuiltin<"__builtin_xtensa_muls_aa_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+def int_xtensa_muls_aa_hh: GCCBuiltin<"__builtin_xtensa_muls_aa_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], []>;
+
+def int_xtensa_muls_ad_ll: GCCBuiltin<"__builtin_xtensa_muls_ad_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+def int_xtensa_muls_ad_hl: GCCBuiltin<"__builtin_xtensa_muls_ad_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+def int_xtensa_muls_ad_lh: GCCBuiltin<"__builtin_xtensa_muls_ad_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+def int_xtensa_muls_ad_hh: GCCBuiltin<"__builtin_xtensa_muls_ad_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<1>]>;
+
+def int_xtensa_muls_da_ll: GCCBuiltin<"__builtin_xtensa_muls_da_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+def int_xtensa_muls_da_hl: GCCBuiltin<"__builtin_xtensa_muls_da_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+def int_xtensa_muls_da_lh: GCCBuiltin<"__builtin_xtensa_muls_da_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+def int_xtensa_muls_da_hh: GCCBuiltin<"__builtin_xtensa_muls_da_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>]>;
+
+def int_xtensa_muls_dd_ll: GCCBuiltin<"__builtin_xtensa_muls_dd_ll">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+def int_xtensa_muls_dd_hl: GCCBuiltin<"__builtin_xtensa_muls_dd_hl">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+def int_xtensa_muls_dd_lh: GCCBuiltin<"__builtin_xtensa_muls_dd_lh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+def int_xtensa_muls_dd_hh: GCCBuiltin<"__builtin_xtensa_muls_dd_hh">,
+  Intrinsic<[], [llvm_i32_ty, llvm_i32_ty], [ImmArg<0>, ImmArg<1>]>;
+
+
+def int_xtensa_mula_da_ll_lddec: GCCBuiltin<"__builtin_xtensa_mula_da_ll_lddec">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>]>;
+def int_xtensa_mula_da_lh_lddec: GCCBuiltin<"__builtin_xtensa_mula_da_lh_lddec">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>]>;
+def int_xtensa_mula_da_hl_lddec: GCCBuiltin<"__builtin_xtensa_mula_da_hl_lddec">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>]>;
+def int_xtensa_mula_da_hh_lddec: GCCBuiltin<"__builtin_xtensa_mula_da_hh_lddec">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>]>;
+
+def int_xtensa_mula_da_ll_ldinc: GCCBuiltin<"__builtin_xtensa_mula_da_ll_ldinc">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>]>;
+def int_xtensa_mula_da_lh_ldinc: GCCBuiltin<"__builtin_xtensa_mula_da_lh_ldinc">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>]>;
+def int_xtensa_mula_da_hl_ldinc: GCCBuiltin<"__builtin_xtensa_mula_da_hl_ldinc">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>]>;
+def int_xtensa_mula_da_hh_ldinc: GCCBuiltin<"__builtin_xtensa_mula_da_hh_ldinc">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>]>;
+
+def int_xtensa_mula_dd_ll_lddec: GCCBuiltin<"__builtin_xtensa_mula_dd_ll_lddec">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>, ImmArg<3>]>;
+def int_xtensa_mula_dd_lh_lddec: GCCBuiltin<"__builtin_xtensa_mula_dd_lh_lddec">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>, ImmArg<3>]>;
+def int_xtensa_mula_dd_hl_lddec: GCCBuiltin<"__builtin_xtensa_mula_dd_hl_lddec">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>, ImmArg<3>]>;
+def int_xtensa_mula_dd_hh_lddec: GCCBuiltin<"__builtin_xtensa_mula_dd_hh_lddec">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>, ImmArg<3>]>;
+
+def int_xtensa_mula_dd_ll_ldinc: GCCBuiltin<"__builtin_xtensa_mula_dd_ll_ldinc">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>, ImmArg<3>]>;
+def int_xtensa_mula_dd_lh_ldinc: GCCBuiltin<"__builtin_xtensa_mula_dd_lh_ldinc">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>, ImmArg<3>]>;
+def int_xtensa_mula_dd_hl_ldinc: GCCBuiltin<"__builtin_xtensa_mula_dd_hl_ldinc">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>, ImmArg<3>]>;
+def int_xtensa_mula_dd_hh_ldinc: GCCBuiltin<"__builtin_xtensa_mula_dd_hh_ldinc">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty, llvm_i32_ty, llvm_i32_ty],
+            [ImmArg<0>, ImmArg<2>, ImmArg<3>]>;
+
+//===----------------------------------------------------------------------===//
+// Load operations
+
+def int_xtensa_lddec: GCCBuiltin<"__builtin_xtensa_lddec">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty], [ImmArg<0>]>;
+
+def int_xtensa_ldinc: GCCBuiltin<"__builtin_xtensa_ldinc">,
+  Intrinsic<[], [llvm_i32_ty, llvm_ptr_ty], [ImmArg<0>]>;
+
+//===----------------------------------------------------------------------===//
+// WSR/XSR/RSR
+
+def int_xtensa_wsr_acclo: GCCBuiltin<"__builtin_xtensa_wsr_acclo">,
+  Intrinsic<[], [llvm_i32_ty], []>;
+
+def int_xtensa_rsr_acclo: GCCBuiltin<"__builtin_xtensa_rsr_acclo">,
+  Intrinsic<[llvm_i32_ty], [], []>;
+
+def int_xtensa_xsr_acclo: GCCBuiltin<"__builtin_xtensa_xsr_acclo">,
+  Intrinsic<[], [llvm_ptr_ty], []>;
+
+def int_xtensa_wsr_acchi: GCCBuiltin<"__builtin_xtensa_wsr_acchi">,
+  Intrinsic<[], [llvm_i32_ty], []>;
+
+def int_xtensa_rsr_acchi: GCCBuiltin<"__builtin_xtensa_rsr_acchi">,
+  Intrinsic<[llvm_i32_ty], [], []>;
+
+def int_xtensa_xsr_acchi: GCCBuiltin<"__builtin_xtensa_xsr_acchi">,
+  Intrinsic<[], [llvm_ptr_ty], []>;
+
+def int_xtensa_wsr_m0: GCCBuiltin<"__builtin_xtensa_wsr_m0">,
+  Intrinsic<[], [llvm_i32_ty], []>;
+
+def int_xtensa_rsr_m0: GCCBuiltin<"__builtin_xtensa_rsr_m0">,
+  Intrinsic<[llvm_i32_ty]>;
+
+def int_xtensa_xsr_m0: GCCBuiltin<"__builtin_xtensa_xsr_m0">,
+  Intrinsic<[], [llvm_ptr_ty], []>;
+
+def int_xtensa_wsr_m1: GCCBuiltin<"__builtin_xtensa_wsr_m1">,
+  Intrinsic<[], [llvm_i32_ty], []>;
+
+def int_xtensa_rsr_m1: GCCBuiltin<"__builtin_xtensa_rsr_m1">,
+  Intrinsic<[llvm_i32_ty], [], []>;
+
+def int_xtensa_xsr_m1: GCCBuiltin<"__builtin_xtensa_xsr_m1">,
+  Intrinsic<[], [llvm_ptr_ty], []>;
+
+def int_xtensa_wsr_m2: GCCBuiltin<"__builtin_xtensa_wsr_m2">,
+  Intrinsic<[], [llvm_i32_ty], []>;
+
+def int_xtensa_rsr_m2: GCCBuiltin<"__builtin_xtensa_rsr_m2">,
+  Intrinsic<[llvm_i32_ty], [], []>;
+
+def int_xtensa_xsr_m2: GCCBuiltin<"__builtin_xtensa_xsr_m2">,
+  Intrinsic<[], [llvm_ptr_ty], []>;
+
+def int_xtensa_wsr_m3: GCCBuiltin<"__builtin_xtensa_wsr_m3">,
+  Intrinsic<[], [llvm_i32_ty], []>;
+
+def int_xtensa_rsr_m3: GCCBuiltin<"__builtin_xtensa_rsr_m3">,
+  Intrinsic<[llvm_i32_ty], [], []>;
+
+def int_xtensa_xsr_m3: GCCBuiltin<"__builtin_xtensa_xsr_m3">,
+  Intrinsic<[], [llvm_ptr_ty], []>;
+
+}
--- llvm-10.0.1.src/include/llvm/Object/ELFObjectFile.h
+++ llvm-10.0.1.src~patched/include/llvm/Object/ELFObjectFile.h
@@ -1085,6 +1085,8 @@ StringRef ELFObjectFile<ELFT>::getFileFormatName() const {
       return "ELF32-sparc";
     case ELF::EM_AMDGPU:
       return "ELF32-amdgpu";
+    case ELF::EM_XTENSA:
+      return "ELF32-Xtensa";
     default:
       return "ELF32-unknown";
     }
@@ -1187,7 +1189,8 @@ template <class ELFT> Triple::ArchType ELFObjectFile<ELFT>::getArch() const {
 
   case ELF::EM_BPF:
     return IsLittleEndian ? Triple::bpfel : Triple::bpfeb;
-
+  case ELF::EM_XTENSA:
+    return Triple::xtensa;
   default:
     return Triple::UnknownArch;
   }
--- llvm-10.0.1.src/include/llvm/module.modulemap
+++ llvm-10.0.1.src~patched/include/llvm/module.modulemap
@@ -72,6 +72,7 @@ module LLVM_BinaryFormat {
     textual header "BinaryFormat/ELFRelocs/Sparc.def"
     textual header "BinaryFormat/ELFRelocs/SystemZ.def"
     textual header "BinaryFormat/ELFRelocs/x86_64.def"
+    textual header "BinaryFormat/ELFRelocs/Xtensa.def"
     textual header "BinaryFormat/WasmRelocs.def"
     textual header "BinaryFormat/MsgPack.def"
 }
--- llvm-10.0.1.src/lib/IR/Function.cpp
+++ llvm-10.0.1.src~patched/lib/IR/Function.cpp
@@ -45,6 +45,7 @@
 #include "llvm/IR/IntrinsicsWebAssembly.h"
 #include "llvm/IR/IntrinsicsX86.h"
 #include "llvm/IR/IntrinsicsXCore.h"
+#include "llvm/IR/IntrinsicsXtensa.h"
 #include "llvm/IR/LLVMContext.h"
 #include "llvm/IR/MDBuilder.h"
 #include "llvm/IR/Metadata.h"
--- llvm-10.0.1.src/lib/MC/MCObjectFileInfo.cpp
+++ llvm-10.0.1.src~patched/lib/MC/MCObjectFileInfo.cpp
@@ -326,6 +326,9 @@ void MCObjectFileInfo::initELFMCObjectFileInfo(const Triple &T, bool Large) {
     FDECFIEncoding =
         PositionIndependent ? dwarf::DW_EH_PE_pcrel : dwarf::DW_EH_PE_absptr;
     break;
+  case Triple::xtensa:
+    FDECFIEncoding = dwarf::DW_EH_PE_sdata4;
+    break;
   default:
     FDECFIEncoding = dwarf::DW_EH_PE_pcrel | dwarf::DW_EH_PE_sdata4;
     break;
--- llvm-10.0.1.src/lib/Object/ELF.cpp
+++ llvm-10.0.1.src~patched/lib/Object/ELF.cpp
@@ -145,6 +145,13 @@ StringRef llvm::object::getELFRelocationTypeName(uint32_t Machine,
       break;
     }
     break;
+  case ELF::EM_XTENSA:
+    switch (Type) {
+#include "llvm/BinaryFormat/ELFRelocs/Xtensa.def"
+    default:
+      break;
+    }
+    break;
   default:
     break;
   }
--- llvm-10.0.1.src/lib/ObjectYAML/ELFYAML.cpp
+++ llvm-10.0.1.src~patched/lib/ObjectYAML/ELFYAML.cpp
@@ -428,6 +428,11 @@ void ScalarBitSetTraits<ELFYAML::ELF_EF>::bitset(IO &IO,
     break;
   case ELF::EM_X86_64:
     break;
+  case ELF::EM_XTENSA:
+    BCase(EF_XTENSA_XT_INSN);
+    BCaseMask(EF_XTENSA_MACH_NONE, EF_XTENSA_MACH);
+    BCase(EF_XTENSA_XT_LIT);
+    break;
   default:
     llvm_unreachable("Unsupported architecture");
   }
@@ -657,6 +662,9 @@ void ScalarEnumerationTraits<ELFYAML::ELF_REL>::enumeration(
   case ELF::EM_PPC64:
 #include "llvm/BinaryFormat/ELFRelocs/PowerPC64.def"
     break;
+  case ELF::EM_XTENSA:
+#include "llvm/BinaryFormat/ELFRelocs/Xtensa.def"
+    break;
   default:
     // Nothing to do.
     break;
--- llvm-10.0.1.src/lib/Support/Triple.cpp
+++ llvm-10.0.1.src~patched/lib/Support/Triple.cpp
@@ -71,6 +71,7 @@ StringRef Triple::getArchTypeName(ArchType Kind) {
   case x86:            return "i386";
   case x86_64:         return "x86_64";
   case xcore:          return "xcore";
+  case xtensa:         return "xtensa";
   }
 
   llvm_unreachable("Invalid ArchType!");
@@ -147,6 +148,8 @@ StringRef Triple::getArchTypePrefix(ArchType Kind) {
   case riscv64:     return "riscv";
 
   case ve:          return "ve";
+
+  case xtensa:      return "xtensa";
   }
 }
 
@@ -317,6 +320,7 @@ Triple::ArchType Triple::getArchTypeForLLVMName(StringRef Name) {
     .Case("renderscript32", renderscript32)
     .Case("renderscript64", renderscript64)
     .Case("ve", ve)
+    .Case("xtensa", xtensa)
     .Default(UnknownArch);
 }
 
@@ -446,6 +450,7 @@ static Triple::ArchType parseArch(StringRef ArchName) {
     .Case("ve", Triple::ve)
     .Case("wasm32", Triple::wasm32)
     .Case("wasm64", Triple::wasm64)
+    .Case("xtensa", Triple::xtensa)
     .Default(Triple::UnknownArch);
 
   // Some architectures require special parsing logic just to compute the
@@ -706,6 +711,7 @@ static Triple::ObjectFormatType getDefaultFormat(const Triple &T) {
   case Triple::thumbeb:
   case Triple::ve:
   case Triple::xcore:
+  case Triple::xtensa:
     return Triple::ELF;
 
   case Triple::ppc64:
@@ -1267,6 +1273,7 @@ static unsigned getArchPointerBitWidth(llvm::Triple::ArchType Arch) {
   case llvm::Triple::wasm32:
   case llvm::Triple::x86:
   case llvm::Triple::xcore:
+  case llvm::Triple::xtensa:
     return 32;
 
   case llvm::Triple::aarch64:
@@ -1350,6 +1357,7 @@ Triple Triple::get32BitArchVariant() const {
   case Triple::wasm32:
   case Triple::x86:
   case Triple::xcore:
+  case Triple::xtensa:
     // Already 32-bit.
     break;
 
@@ -1388,6 +1396,7 @@ Triple Triple::get64BitArchVariant() const {
   case Triple::tce:
   case Triple::tcele:
   case Triple::xcore:
+  case Triple::xtensa:
     T.setArch(UnknownArch);
     break;
 
@@ -1471,6 +1480,7 @@ Triple Triple::getBigEndianArchVariant() const {
   case Triple::x86_64:
   case Triple::xcore:
   case Triple::ve:
+  case Triple::xtensa:
 
   // ARM is intentionally unsupported here, changing the architecture would
   // drop any arch suffixes.
@@ -1563,6 +1573,7 @@ bool Triple::isLittleEndian() const {
   case Triple::x86:
   case Triple::x86_64:
   case Triple::xcore:
+  case Triple::xtensa:
     return true;
   default:
     return false;
--- llvm-10.0.1.src/lib/Target/LLVMBuild.txt
+++ llvm-10.0.1.src~patched/lib/Target/LLVMBuild.txt
@@ -36,6 +36,7 @@ subdirectories =
  WebAssembly
  X86
  XCore
+ Xtensa
  VE
 
 ; This is a special group whose required libraries are extended (by llvm-build)
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/AsmParser/CMakeLists.txt
@@ -0,0 +1,7 @@
+include_directories( ${CMAKE_CURRENT_BINARY_DIR}/.. ${CMAKE_CURRENT_SOURCE_DIR}/.. )
+
+add_llvm_component_library(LLVMXtensaAsmParser
+  XtensaAsmParser.cpp
+  )
+
+add_dependencies(LLVMXtensaAsmParser XtensaCommonTableGen)
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/AsmParser/LLVMBuild.txt
@@ -0,0 +1,22 @@
+;===- ./lib/Target/AsmParser/LLVMBuild.txt --------------------*- Conf -*--===;
+;
+; Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+; See https://llvm.org/LICENSE.txt for license information.
+; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+[component_0]
+type = Library
+name = XtensaAsmParser
+parent = Xtensa
+required_libraries = XtensaDesc XtensaInfo MC MCParser Support
+add_to_library_groups = Xtensa
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/AsmParser/XtensaAsmParser.cpp
@@ -0,0 +1,1079 @@
+//===- XtensaAsmParser.cpp - Parse Xtensa assembly to MCInst instructions -===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#include "MCTargetDesc/XtensaMCExpr.h"
+#include "MCTargetDesc/XtensaMCTargetDesc.h"
+#include "MCTargetDesc/XtensaTargetStreamer.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/StringSwitch.h"
+#include "llvm/MC/MCContext.h"
+#include "llvm/MC/MCExpr.h"
+#include "llvm/MC/MCInst.h"
+#include "llvm/MC/MCParser/MCAsmLexer.h"
+#include "llvm/MC/MCParser/MCParsedAsmOperand.h"
+#include "llvm/MC/MCParser/MCTargetAsmParser.h"
+#include "llvm/MC/MCRegisterInfo.h"
+#include "llvm/MC/MCStreamer.h"
+#include "llvm/MC/MCSubtargetInfo.h"
+#include "llvm/Support/Casting.h"
+#include "llvm/Support/TargetRegistry.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "xtensa-asm-parser"
+
+struct XtensaOperand;
+
+class XtensaAsmParser : public MCTargetAsmParser {
+
+  SMLoc getLoc() const { return getParser().getTok().getLoc(); }
+
+  XtensaTargetStreamer &getTargetStreamer() {
+    MCTargetStreamer &TS = *getParser().getStreamer().getTargetStreamer();
+    return static_cast<XtensaTargetStreamer &>(TS);
+  }
+
+  // Override MCTargetAsmParser.
+  bool ParseDirective(AsmToken DirectiveID) override;
+  bool ParseRegister(unsigned &RegNo, SMLoc &StartLoc, SMLoc &EndLoc) override;
+  bool ParseInstruction(ParseInstructionInfo &Info, StringRef Name,
+                        SMLoc NameLoc, OperandVector &Operands) override;
+  bool MatchAndEmitInstruction(SMLoc IDLoc, unsigned &Opcode,
+                               OperandVector &Operands, MCStreamer &Out,
+                               uint64_t &ErrorInfo,
+                               bool MatchingInlineAsm) override;
+  unsigned validateTargetOperandClass(MCParsedAsmOperand &Op,
+                                      unsigned Kind) override;
+
+  bool processInstruction(MCInst &Inst, SMLoc IDLoc, MCStreamer &Out,
+                          const MCSubtargetInfo *STI);
+
+// Auto-generated instruction matching functions
+#define GET_ASSEMBLER_HEADER
+#include "XtensaGenAsmMatcher.inc"
+
+  OperandMatchResultTy parseImmediate(OperandVector &Operands);
+  OperandMatchResultTy parseRegister(OperandVector &Operands,
+                                     bool AllowParens = false, bool SR = false,
+                                     bool UR = false);
+  OperandMatchResultTy parseOperandWithModifier(OperandVector &Operands);
+  bool parseOperand(OperandVector &Operands, StringRef Mnemonic,
+                    bool SR = false, bool UR = false);
+  bool ParseInstructionWithSR(ParseInstructionInfo &Info, StringRef Name,
+                              SMLoc NameLoc, OperandVector &Operands);
+  OperandMatchResultTy parsePCRelTarget(OperandVector &Operands);
+  bool checkRegister(unsigned RegNo);
+
+public:
+  enum XtensaMatchResultTy {
+    Match_Dummy = FIRST_TARGET_MATCH_RESULT_TY,
+#define GET_OPERAND_DIAGNOSTIC_TYPES
+#include "XtensaGenAsmMatcher.inc"
+#undef GET_OPERAND_DIAGNOSTIC_TYPES
+  };
+
+  XtensaAsmParser(const MCSubtargetInfo &STI, MCAsmParser &Parser,
+                  const MCInstrInfo &MII, const MCTargetOptions &Options)
+      : MCTargetAsmParser(Options, STI, MII) {
+    setAvailableFeatures(ComputeAvailableFeatures(STI.getFeatureBits()));
+  }
+
+  bool hasWindowed() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureWindowed];
+  };
+
+  bool hasSingleFloat() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureSingleFloat];
+  };
+
+  bool hasLoop() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureLoop];
+  };
+
+  bool hasMAC16() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureMAC16];
+  };
+
+  bool hasBoolean() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureBoolean];
+  };
+
+  bool hasDFPAccel() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureDFPAccel];
+  };
+
+  bool hasS32C1I() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureS32C1I];
+  };
+
+  bool hasTHREADPTR() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureTHREADPTR];
+  };
+
+  bool hasExtendedL32R() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureExtendedL32R];
+  }
+
+  bool hasATOMCTL() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureATOMCTL];
+  }
+
+  bool hasMEMCTL() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureMEMCTL];
+  }
+
+  bool hasDebug() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureDebug];
+  }
+
+  bool hasException() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureException];
+  }
+
+  bool hasHighPriInterrupts() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureHighPriInterrupts];
+  }
+
+  bool hasCoprocessor() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureCoprocessor];
+  }
+
+  bool hasInterrupt() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureInterrupt];
+  }
+
+  bool hasRelocatableVector() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureRelocatableVector];
+  }
+
+  bool hasTimerInt() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureTimerInt];
+  }
+
+  bool hasPRID() const {
+    return getSTI().getFeatureBits()[Xtensa::FeaturePRID];
+  }
+
+  bool hasMiscSR() const {
+    return getSTI().getFeatureBits()[Xtensa::FeatureMiscSR];
+  }
+};
+
+// Return true if Expr is in the range [MinValue, MaxValue].
+static bool inRange(const MCExpr *Expr, int64_t MinValue, int64_t MaxValue) {
+  if (auto *CE = dyn_cast<MCConstantExpr>(Expr)) {
+    int64_t Value = CE->getValue();
+    return Value >= MinValue && Value <= MaxValue;
+  }
+  return false;
+}
+
+struct XtensaOperand : public MCParsedAsmOperand {
+
+  enum KindTy {
+    Token,
+    Register,
+    Immediate,
+  } Kind;
+
+  struct RegOp {
+    unsigned RegNum;
+  };
+
+  struct ImmOp {
+    const MCExpr *Val;
+  };
+
+  SMLoc StartLoc, EndLoc;
+  union {
+    StringRef Tok;
+    RegOp Reg;
+    ImmOp Imm;
+  };
+
+  XtensaOperand(KindTy K) : MCParsedAsmOperand(), Kind(K) {}
+
+public:
+  XtensaOperand(const XtensaOperand &o) : MCParsedAsmOperand() {
+    Kind = o.Kind;
+    StartLoc = o.StartLoc;
+    EndLoc = o.EndLoc;
+    switch (Kind) {
+    case Register:
+      Reg = o.Reg;
+      break;
+    case Immediate:
+      Imm = o.Imm;
+      break;
+    case Token:
+      Tok = o.Tok;
+      break;
+    }
+  }
+
+  bool isToken() const override { return Kind == Token; }
+  bool isReg() const override { return Kind == Register; }
+  bool isImm() const override { return Kind == Immediate; }
+  bool isMem() const override { return false; }
+
+  bool isImm(int64_t MinValue, int64_t MaxValue) const {
+    return Kind == Immediate && inRange(getImm(), MinValue, MaxValue);
+  }
+
+  bool isImm8() const { return isImm(-128, 127); }
+
+  bool isImm8_sh8() const {
+    return isImm(-32768, 32512) &&
+           ((dyn_cast<MCConstantExpr>(getImm())->getValue() & 0xFF) == 0);
+  }
+
+  bool isImm12() const { return isImm(-2048, 2047); }
+
+  // Convert MOVI to literal load, when immediate is not in range (-2048, 2047)
+  bool isImm12m() const { return isImm(LONG_MIN, LONG_MAX); }
+
+  bool isOffset4m32() const {
+    return isImm(0, 60) &&
+           ((dyn_cast<MCConstantExpr>(getImm())->getValue() & 0x3) == 0);
+  }
+
+  bool isOffset8m8() const { return isImm(0, 255); }
+
+  bool isOffset8m16() const {
+    return isImm(0, 510) &&
+           ((dyn_cast<MCConstantExpr>(getImm())->getValue() & 0x1) == 0);
+  }
+
+  bool isOffset8m32() const {
+    return isImm(0, 1020) &&
+           ((dyn_cast<MCConstantExpr>(getImm())->getValue() & 0x3) == 0);
+  }
+
+  bool isentry_imm12() const { return isImm(0, 32760); }
+
+  bool isUimm4() const { return isImm(0, 15); }
+
+  bool isUimm5() const { return isImm(0, 31); }
+
+  bool isImm8n_7() const { return isImm(-8, 7); }
+
+  bool isShimm1_31() const { return isImm(1, 31); }
+
+  bool isImm16_31() const { return isImm(16, 31); }
+
+  bool isImm1_16() const { return isImm(1, 16); }
+
+  bool isImm1n_15() const { return (isImm(1, 15) || isImm(-1, -1)); }
+
+  bool isImm32n_95() const { return isImm(-32, 95); }
+
+  bool isImm64n_4n() const {
+    return isImm(-64, -4) &&
+           ((dyn_cast<MCConstantExpr>(getImm())->getValue() & 0x3) == 0);
+  }
+
+  bool isB4const() const {
+    if (Kind != Immediate)
+      return false;
+    if (auto *CE = dyn_cast<MCConstantExpr>(getImm())) {
+      int64_t Value = CE->getValue();
+      switch (Value) {
+      case -1:
+      case 1:
+      case 2:
+      case 3:
+      case 4:
+      case 5:
+      case 6:
+      case 7:
+      case 8:
+      case 10:
+      case 12:
+      case 16:
+      case 32:
+      case 64:
+      case 128:
+      case 256:
+        return true;
+      default:
+        return false;
+      }
+    }
+    return false;
+  }
+
+  bool isB4constu() const {
+    if (Kind != Immediate)
+      return false;
+    if (auto *CE = dyn_cast<MCConstantExpr>(getImm())) {
+      int64_t Value = CE->getValue();
+      switch (Value) {
+      case 32768:
+      case 65536:
+      case 2:
+      case 3:
+      case 4:
+      case 5:
+      case 6:
+      case 7:
+      case 8:
+      case 10:
+      case 12:
+      case 16:
+      case 32:
+      case 64:
+      case 128:
+      case 256:
+        return true;
+      default:
+        return false;
+      }
+    }
+    return false;
+  }
+
+  bool isseimm7_22() const { return isImm(7, 22); }
+
+  /// getStartLoc - Gets location of the first token of this operand
+  SMLoc getStartLoc() const override { return StartLoc; }
+  /// getEndLoc - Gets location of the last token of this operand
+  SMLoc getEndLoc() const override { return EndLoc; }
+
+  unsigned getReg() const override {
+    assert(Kind == Register && "Invalid type access!");
+    return Reg.RegNum;
+  }
+
+  const MCExpr *getImm() const {
+    assert(Kind == Immediate && "Invalid type access!");
+    return Imm.Val;
+  }
+
+  StringRef getToken() const {
+    assert(Kind == Token && "Invalid type access!");
+    return Tok;
+  }
+
+  void print(raw_ostream &OS) const override {
+    switch (Kind) {
+    case Immediate:
+      OS << *getImm();
+      break;
+    case Register:
+      OS << "<register x";
+      OS << getReg() << ">";
+      break;
+    case Token:
+      OS << "'" << getToken() << "'";
+      break;
+    }
+  }
+
+  static std::unique_ptr<XtensaOperand> createToken(StringRef Str, SMLoc S) {
+    auto Op = std::make_unique<XtensaOperand>(Token);
+    Op->Tok = Str;
+    Op->StartLoc = S;
+    Op->EndLoc = S;
+    return Op;
+  }
+
+  static std::unique_ptr<XtensaOperand> createReg(unsigned RegNo, SMLoc S,
+                                                  SMLoc E) {
+    auto Op = std::make_unique<XtensaOperand>(Register);
+    Op->Reg.RegNum = RegNo;
+    Op->StartLoc = S;
+    Op->EndLoc = E;
+    return Op;
+  }
+
+  static std::unique_ptr<XtensaOperand> createImm(const MCExpr *Val, SMLoc S,
+                                                  SMLoc E) {
+    auto Op = std::make_unique<XtensaOperand>(Immediate);
+    Op->Imm.Val = Val;
+    Op->StartLoc = S;
+    Op->EndLoc = E;
+    return Op;
+  }
+
+  void addExpr(MCInst &Inst, const MCExpr *Expr) const {
+    assert(Expr && "Expr shouldn't be null!");
+    int64_t Imm = 0;
+    bool IsConstant = false;
+
+    if (auto *CE = dyn_cast<MCConstantExpr>(Expr)) {
+      IsConstant = true;
+      Imm = CE->getValue();
+    }
+
+    if (IsConstant)
+      Inst.addOperand(MCOperand::createImm(Imm));
+    else
+      Inst.addOperand(MCOperand::createExpr(Expr));
+  }
+
+  // Used by the TableGen Code
+  void addRegOperands(MCInst &Inst, unsigned N) const {
+    assert(N == 1 && "Invalid number of operands!");
+    Inst.addOperand(MCOperand::createReg(getReg()));
+  }
+
+  void addImmOperands(MCInst &Inst, unsigned N) const {
+    assert(N == 1 && "Invalid number of operands!");
+    addExpr(Inst, getImm());
+  }
+};
+
+#define GET_REGISTER_MATCHER
+#define GET_MATCHER_IMPLEMENTATION
+#include "XtensaGenAsmMatcher.inc"
+
+unsigned XtensaAsmParser::validateTargetOperandClass(MCParsedAsmOperand &AsmOp,
+                                                     unsigned Kind) {
+  return Match_InvalidOperand;
+}
+
+static SMLoc RefineErrorLoc(const SMLoc Loc, const OperandVector &Operands,
+                            uint64_t ErrorInfo) {
+  if (ErrorInfo != ~0ULL && ErrorInfo < Operands.size()) {
+    SMLoc ErrorLoc = Operands[ErrorInfo]->getStartLoc();
+    if (ErrorLoc == SMLoc())
+      return Loc;
+    return ErrorLoc;
+  }
+  return Loc;
+}
+
+bool XtensaAsmParser::processInstruction(MCInst &Inst, SMLoc IDLoc,
+                                         MCStreamer &Out,
+                                         const MCSubtargetInfo *STI) {
+  Inst.setLoc(IDLoc);
+  const unsigned Opcode = Inst.getOpcode();
+
+  switch (Opcode) {
+  case Xtensa::L32R: {
+    const MCSymbolRefExpr *OpExpr =
+        (const MCSymbolRefExpr *)Inst.getOperand(1).getExpr();
+    XtensaMCExpr::VariantKind Kind = XtensaMCExpr::VK_Xtensa_None;
+    const MCExpr *NewOpExpr = XtensaMCExpr::create(OpExpr, Kind, getContext());
+    Inst.getOperand(1).setExpr(NewOpExpr);
+  } break;
+  case Xtensa::MOVI: {
+    if (!Inst.getOperand(1).isExpr()) {
+      uint64_t ImmOp64 = Inst.getOperand(1).getImm();
+      int32_t Imm = ImmOp64;
+      if ((Imm < -2048) || (Imm > 2047)) {
+        XtensaTargetStreamer &TS = this->getTargetStreamer();
+        MCInst TmpInst;
+        TmpInst.setLoc(IDLoc);
+        TmpInst.setOpcode(Xtensa::L32R);
+        const MCExpr *Value = MCConstantExpr::create(ImmOp64, getContext());
+        MCSymbol *Sym = getContext().createTempSymbol();
+        const MCExpr *Expr = MCSymbolRefExpr::create(
+            Sym, MCSymbolRefExpr::VK_None, getContext());
+        const MCExpr *OpExpr = XtensaMCExpr::create(
+            Expr, XtensaMCExpr::VK_Xtensa_None, getContext());
+        TmpInst.addOperand(Inst.getOperand(0));
+        MCOperand Op1 = MCOperand::createExpr(OpExpr);
+        TmpInst.addOperand(Op1);
+        TS.emitLiteralLabel(Sym, IDLoc);
+        TS.emitLiteral(Value, IDLoc);
+        Inst = TmpInst;
+      }
+    } else {
+      MCInst TmpInst;
+      TmpInst.setLoc(IDLoc);
+      TmpInst.setOpcode(Xtensa::L32R);
+      const MCExpr *Expr = Inst.getOperand(1).getExpr();
+      const MCExpr *OpExpr = XtensaMCExpr::create(
+          Expr, XtensaMCExpr::VK_Xtensa_None, getContext());
+      TmpInst.addOperand(Inst.getOperand(0));
+      MCOperand Op1 = MCOperand::createExpr(OpExpr);
+      TmpInst.addOperand(Op1);
+      Inst = TmpInst;
+    }
+  } break;
+  default:
+    break;
+  }
+  return true;
+}
+
+bool XtensaAsmParser::MatchAndEmitInstruction(SMLoc IDLoc, unsigned &Opcode,
+                                              OperandVector &Operands,
+                                              MCStreamer &Out,
+                                              uint64_t &ErrorInfo,
+                                              bool MatchingInlineAsm) {
+  MCInst Inst;
+  auto Result =
+      MatchInstructionImpl(Operands, Inst, ErrorInfo, MatchingInlineAsm);
+
+  switch (Result) {
+  default:
+    break;
+  case Match_Success:
+    processInstruction(Inst, IDLoc, Out, STI);
+    Inst.setLoc(IDLoc);
+    Out.EmitInstruction(Inst, getSTI());
+    return false;
+  case Match_MissingFeature:
+    return Error(IDLoc, "instruction use requires an option to be enabled");
+  case Match_MnemonicFail:
+    return Error(IDLoc, "unrecognized instruction mnemonic");
+  case Match_InvalidOperand: {
+    SMLoc ErrorLoc = IDLoc;
+    if (ErrorInfo != ~0U) {
+      if (ErrorInfo >= Operands.size())
+        return Error(ErrorLoc, "too few operands for instruction");
+
+      ErrorLoc = ((XtensaOperand &)*Operands[ErrorInfo]).getStartLoc();
+      if (ErrorLoc == SMLoc())
+        ErrorLoc = IDLoc;
+    }
+    return Error(ErrorLoc, "invalid operand for instruction");
+  }
+  case Match_InvalidImm8:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [-128, 127]");
+  case Match_InvalidImm8_sh8:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [-32768, 32512], first 8 bits "
+                 "should be zero");
+  case Match_InvalidB4const:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected b4const immediate");
+  case Match_InvalidB4constu:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected b4constu immediate");
+  case Match_InvalidImm12:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [-2048, 2047]");
+  case Match_InvalidImm1_16:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [1, 16]");
+  case Match_InvalidImm1n_15:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [-1, 15] except 0");
+  case Match_InvalidImm32n_95:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [-32, 95] except 0");
+  case Match_InvalidImm64n_4n:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [-64, -4]");
+  case Match_InvalidImm8n_7:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [-8, 7]");
+  case Match_InvalidShimm1_31:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [1, 31]");
+  case Match_InvalidUimm4:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [0, 15]");
+  case Match_InvalidUimm5:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [0, 31]");
+  case Match_InvalidOffset8m8:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [0, 255]");
+  case Match_InvalidOffset8m16:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [0, 510], first bit "
+                 "should be zero");
+  case Match_InvalidOffset8m32:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [0, 1020], first 2 bits "
+                 "should be zero");
+  case Match_InvalidOffset4m32:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [0, 60], first 2 bits "
+                 "should be zero");
+  case Match_Invalidentry_imm12:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [0, 32760]");
+  case Match_Invalidseimm7_22:
+    return Error(RefineErrorLoc(IDLoc, Operands, ErrorInfo),
+                 "expected immediate in range [7, 22]");
+  }
+
+  llvm_unreachable("Unknown match type detected!");
+}
+
+OperandMatchResultTy
+XtensaAsmParser::parsePCRelTarget(OperandVector &Operands) {
+  MCAsmParser &Parser = getParser();
+  LLVM_DEBUG(dbgs() << "parsePCRelTarget\n");
+
+  SMLoc S = getLexer().getLoc();
+
+  // Expressions are acceptable
+  const MCExpr *Expr = nullptr;
+  if (Parser.parseExpression(Expr)) {
+    // We have no way of knowing if a symbol was consumed so we must ParseFail
+    return MatchOperand_ParseFail;
+  }
+
+  // Currently not support constants
+  if (Expr->getKind() == MCExpr::ExprKind::Constant) {
+    Error(getLoc(), "unknown operand");
+    return MatchOperand_ParseFail;
+  }
+
+  Operands.push_back(XtensaOperand::createImm(Expr, S, getLexer().getLoc()));
+  return MatchOperand_Success;
+}
+
+bool XtensaAsmParser::ParseRegister(unsigned &RegNo, SMLoc &StartLoc,
+                                    SMLoc &EndLoc) {
+  const AsmToken &Tok = getParser().getTok();
+  StartLoc = Tok.getLoc();
+  EndLoc = Tok.getEndLoc();
+  RegNo = 0;
+  StringRef Name = getLexer().getTok().getIdentifier();
+
+  if ((!MatchRegisterName(Name)) && (!MatchRegisterAltName(Name))) {
+    getParser().Lex(); // Eat identifier token.
+    return false;
+  }
+
+  return Error(StartLoc, "invalid register name");
+}
+
+OperandMatchResultTy XtensaAsmParser::parseRegister(OperandVector &Operands,
+                                                    bool AllowParens, bool SR,
+                                                    bool UR) {
+  SMLoc FirstS = getLoc();
+  bool HadParens = false;
+  AsmToken Buf[2];
+  std::string RegName = "";
+  int64_t Num;
+
+  // If this a parenthesised register name is allowed, parse it atomically
+  if (AllowParens && getLexer().is(AsmToken::LParen)) {
+    size_t ReadCount = getLexer().peekTokens(Buf);
+    if (ReadCount == 2 && Buf[1].getKind() == AsmToken::RParen) {
+      HadParens = true;
+      getParser().Lex(); // Eat '('
+    }
+  }
+
+  switch (getLexer().getKind()) {
+  default:
+    return MatchOperand_NoMatch;
+  case AsmToken::Integer:
+    if ((!SR) && (!UR))
+      return MatchOperand_NoMatch;
+
+    Num = getLexer().getTok().getIntVal();
+    // Parse case when we expect UR operand as special case,
+    // because SR and UR registers may have the same number
+    // and such situation may lead to confilct
+    if (UR) {
+      if (Num == 0)
+        RegName = "GPIO_OUT";
+      if (Num == 230)
+        RegName = "EXPSTATE";
+      if (Num == 231)
+        RegName = "THREADPTR";
+      if (Num == 232)
+        RegName = "FCR";
+      if (Num == 233)
+        RegName = "FSR";
+      if (Num == 234)
+        RegName = "F64R_LO";
+      if (Num == 235)
+        RegName = "F64R_HI";
+      if (Num == 236)
+        RegName = "F64S";
+    } else
+      RegName = std::to_string(Num);
+    break;
+  case AsmToken::Identifier:
+    RegName = getLexer().getTok().getIdentifier();
+    break;
+  }
+
+  unsigned RegNo = MatchRegisterName(RegName);
+  if (RegNo == 0)
+    RegNo = MatchRegisterAltName(RegName);
+
+  if (RegNo == 0) {
+    if (HadParens)
+      getLexer().UnLex(Buf[0]);
+    return MatchOperand_NoMatch;
+  }
+
+  if (!checkRegister(RegNo)) {
+    return MatchOperand_NoMatch;
+  }
+
+  if (HadParens)
+    Operands.push_back(XtensaOperand::createToken("(", FirstS));
+  SMLoc S = getLoc();
+  SMLoc E = SMLoc::getFromPointer(S.getPointer() - 1);
+  getLexer().Lex();
+  Operands.push_back(XtensaOperand::createReg(RegNo, S, E));
+
+  if (HadParens) {
+    getParser().Lex(); // Eat ')'
+    Operands.push_back(XtensaOperand::createToken(")", getLoc()));
+  }
+
+  return MatchOperand_Success;
+}
+
+OperandMatchResultTy XtensaAsmParser::parseImmediate(OperandVector &Operands) {
+  SMLoc S = getLoc();
+  SMLoc E = SMLoc::getFromPointer(S.getPointer() - 1);
+  const MCExpr *Res;
+
+  switch (getLexer().getKind()) {
+  default:
+    return MatchOperand_NoMatch;
+  case AsmToken::LParen:
+  case AsmToken::Minus:
+  case AsmToken::Plus:
+  case AsmToken::Tilde:
+  case AsmToken::Integer:
+  case AsmToken::String:
+    if (getParser().parseExpression(Res))
+      return MatchOperand_ParseFail;
+    break;
+  case AsmToken::Identifier: {
+    StringRef Identifier;
+    if (getParser().parseIdentifier(Identifier))
+      return MatchOperand_ParseFail;
+
+    MCSymbol *Sym = getContext().getOrCreateSymbol(Identifier);
+    Res = MCSymbolRefExpr::create(Sym, MCSymbolRefExpr::VK_None, getContext());
+    break;
+  }
+  case AsmToken::Percent:
+    return parseOperandWithModifier(Operands);
+  }
+
+  Operands.push_back(XtensaOperand::createImm(Res, S, E));
+  return MatchOperand_Success;
+}
+
+OperandMatchResultTy
+XtensaAsmParser::parseOperandWithModifier(OperandVector &Operands) {
+  return MatchOperand_ParseFail;
+}
+
+/// Looks at a token type and creates the relevant operand
+/// from this information, adding to Operands.
+/// If operand was parsed, returns false, else true.
+bool XtensaAsmParser::parseOperand(OperandVector &Operands, StringRef Mnemonic,
+                                   bool SR, bool UR) {
+  // Check if the current operand has a custom associated parser, if so, try to
+  // custom parse the operand, or fallback to the general approach.
+  OperandMatchResultTy ResTy = MatchOperandParserImpl(Operands, Mnemonic);
+  if (ResTy == MatchOperand_Success)
+    return false;
+
+  // If there wasn't a custom match, try the generic matcher below. Otherwise,
+  // there was a match, but an error occurred, in which case, just return that
+  // the operand parsing failed.
+  if (ResTy == MatchOperand_ParseFail)
+    return true;
+
+  // Attempt to parse token as register
+  if (parseRegister(Operands, true, SR, UR) == MatchOperand_Success)
+    return false;
+
+  // Attempt to parse token as an immediate
+  if (parseImmediate(Operands) == MatchOperand_Success) {
+    return false;
+  }
+
+  // Finally we have exhausted all options and must declare defeat.
+  Error(getLoc(), "unknown operand");
+  return true;
+}
+
+bool XtensaAsmParser::ParseInstructionWithSR(ParseInstructionInfo &Info,
+                                             StringRef Name, SMLoc NameLoc,
+                                             OperandVector &Operands) {
+  bool IsSR = Name.startswith("wsr") || Name.startswith("rsr") ||
+              Name.startswith("xsr");
+  bool IsUR = Name.startswith("wur") || Name.startswith("rur");
+
+  if ((Name.startswith("wsr.") || Name.startswith("rsr.") ||
+       Name.startswith("xsr.") || Name.startswith("rur.") ||
+       Name.startswith("wur.")) &&
+      (Name.size() > 4)) {
+    // Parse case when instruction name is concatenated with SR register
+    // name, like "wsr.sar a1"
+
+    // First operand is token for instruction
+    Operands.push_back(XtensaOperand::createToken(Name.take_front(3), NameLoc));
+
+    StringRef RegName = Name.drop_front(4);
+    unsigned RegNo = MatchRegisterName(RegName);
+
+    if (RegNo == 0)
+      RegNo = MatchRegisterAltName(RegName);
+
+    if (RegNo == 0) {
+      Error(NameLoc, "invalid register name");
+      return true;
+    }
+
+    if (!checkRegister(RegNo)) {
+      Error(NameLoc, "invalid register name");
+      return true;
+    }
+
+    // Parse operand
+    if (parseOperand(Operands, Name))
+      return true;
+
+    SMLoc S = getLoc();
+    SMLoc E = SMLoc::getFromPointer(S.getPointer() - 1);
+    Operands.push_back(XtensaOperand::createReg(RegNo, S, E));
+  } else {
+    // First operand is token for instruction
+    Operands.push_back(XtensaOperand::createToken(Name, NameLoc));
+
+    // Parse first operand
+    if (parseOperand(Operands, Name))
+      return true;
+
+    if (!getLexer().is(AsmToken::Comma)) {
+      SMLoc Loc = getLexer().getLoc();
+      getParser().eatToEndOfStatement();
+      return Error(Loc, "unexpected token");
+    }
+
+    getLexer().Lex();
+
+    // Parse second operand
+    if (parseOperand(Operands, Name, IsSR, IsUR))
+      return true;
+  }
+
+  if (getLexer().isNot(AsmToken::EndOfStatement)) {
+    SMLoc Loc = getLexer().getLoc();
+    getParser().eatToEndOfStatement();
+    return Error(Loc, "unexpected token");
+  }
+
+  getParser().Lex(); // Consume the EndOfStatement.
+  return false;
+}
+
+bool XtensaAsmParser::ParseInstruction(ParseInstructionInfo &Info,
+                                       StringRef Name, SMLoc NameLoc,
+                                       OperandVector &Operands) {
+  if (Name.startswith("wsr") || Name.startswith("rsr") ||
+      Name.startswith("xsr") || Name.startswith("rur") ||
+      Name.startswith("wur")) {
+    return ParseInstructionWithSR(Info, Name, NameLoc, Operands);
+  }
+
+  // First operand is token for instruction
+  Operands.push_back(XtensaOperand::createToken(Name, NameLoc));
+
+  // If there are no more operands, then finish
+  if (getLexer().is(AsmToken::EndOfStatement))
+    return false;
+
+  // Parse first operand
+  if (parseOperand(Operands, Name))
+    return true;
+
+  // Parse until end of statement, consuming commas between operands
+  while (getLexer().is(AsmToken::Comma)) {
+    // Consume comma token
+    getLexer().Lex();
+
+    // Parse next operand
+    if (parseOperand(Operands, Name))
+      return true;
+  }
+
+  if (getLexer().isNot(AsmToken::EndOfStatement)) {
+    SMLoc Loc = getLexer().getLoc();
+    getParser().eatToEndOfStatement();
+    return Error(Loc, "unexpected token");
+  }
+
+  getParser().Lex(); // Consume the EndOfStatement.
+  return false;
+}
+
+bool XtensaAsmParser::ParseDirective(AsmToken DirectiveID) { return true; }
+
+// Verify SR and UR
+bool XtensaAsmParser::checkRegister(unsigned RegNo) {
+  StringRef CPU = getSTI().getCPU();
+  unsigned NumIntLevels = 0;
+  unsigned NumTimers = 0;
+  unsigned NumMiscSR = 0;
+  bool IsESP32 = false;
+  bool IsESP32_S2 = false;
+  bool Res = true;
+
+  // Assume that CPU is esp32 by default
+  if ((CPU == "esp32") || (CPU == "")) {
+    NumIntLevels = 6;
+    NumTimers = 3;
+    NumMiscSR = 4;
+    IsESP32 = true;
+  } else if (CPU == "esp32-s2") {
+    NumIntLevels = 6;
+    NumTimers = 3;
+    NumMiscSR = 4;
+    IsESP32_S2 = true;
+  } else if (CPU == "esp8266") {
+    NumIntLevels = 2;
+    NumTimers = 1;
+  }
+
+  switch (RegNo) {
+  case Xtensa::LBEG:
+  case Xtensa::LEND:
+  case Xtensa::LCOUNT:
+    Res = hasLoop();
+    break;
+  case Xtensa::BREG:
+    Res = hasBoolean();
+    break;
+  case Xtensa::LITBASE:
+    Res = hasExtendedL32R();
+    break;
+  case Xtensa::SCOMPARE1:
+    Res = hasS32C1I();
+    break;
+  case Xtensa::ACCLO:
+  case Xtensa::ACCHI:
+  case Xtensa::M0:
+  case Xtensa::M1:
+  case Xtensa::M2:
+  case Xtensa::M3:
+    Res = hasMAC16();
+    break;
+  case Xtensa::WINDOWBASE:
+  case Xtensa::WINDOWSTART:
+    Res = hasWindowed();
+    break;
+  case Xtensa::IBREAKENABLE:
+  case Xtensa::IBREAKA0:
+  case Xtensa::IBREAKA1:
+  case Xtensa::DBREAKA0:
+  case Xtensa::DBREAKA1:
+  case Xtensa::DBREAKC0:
+  case Xtensa::DBREAKC1:
+  case Xtensa::DEBUGCAUSE:
+  case Xtensa::ICOUNT:
+  case Xtensa::ICOUNTLEVEL:
+    Res = hasDebug();
+    break;
+  case Xtensa::ATOMCTL:
+    Res = hasATOMCTL();
+    break;
+  case Xtensa::MEMCTL:
+    Res = hasMEMCTL();
+    break;
+  case Xtensa::EPC1:
+    Res = hasException();
+    break;
+  case Xtensa::EPC2:
+  case Xtensa::EPC3:
+  case Xtensa::EPC4:
+  case Xtensa::EPC5:
+  case Xtensa::EPC6:
+  case Xtensa::EPC7:
+    Res = hasHighPriInterrupts();
+    Res = Res & (NumIntLevels >= (RegNo - Xtensa::EPC1));
+    break;
+  case Xtensa::EPS2:
+  case Xtensa::EPS3:
+  case Xtensa::EPS4:
+  case Xtensa::EPS5:
+  case Xtensa::EPS6:
+  case Xtensa::EPS7:
+    Res = hasHighPriInterrupts();
+    Res = Res & (NumIntLevels > (RegNo - Xtensa::EPS2));
+    break;
+  case Xtensa::EXCSAVE1:
+    Res = hasException();
+    break;
+  case Xtensa::EXCSAVE2:
+  case Xtensa::EXCSAVE3:
+  case Xtensa::EXCSAVE4:
+  case Xtensa::EXCSAVE5:
+  case Xtensa::EXCSAVE6:
+  case Xtensa::EXCSAVE7:
+    Res = hasHighPriInterrupts();
+    Res = Res & (NumIntLevels >= (RegNo - Xtensa::EXCSAVE1));
+    break;
+  case Xtensa::DEPC:
+  case Xtensa::EXCCAUSE:
+  case Xtensa::EXCVADDR:
+    Res = hasException();
+    break;
+  case Xtensa::CPENABLE:
+    Res = hasCoprocessor();
+    break;
+  case Xtensa::VECBASE:
+    Res = hasRelocatableVector();
+    break;
+  case Xtensa::CCOUNT:
+    Res = hasTimerInt();
+    Res &= (NumTimers > 0);
+    break;
+  case Xtensa::CCOMPARE0:
+  case Xtensa::CCOMPARE1:
+  case Xtensa::CCOMPARE2:
+    Res = hasTimerInt();
+    Res &= (NumTimers > (RegNo - Xtensa::CCOMPARE0));
+    break;
+  case Xtensa::PRID:
+    Res = hasPRID();
+    break;
+  case Xtensa::INTSET:
+  case Xtensa::INTCLEAR:
+  case Xtensa::INTENABLE:
+    Res = hasInterrupt();
+    break;
+  case Xtensa::MISC0:
+  case Xtensa::MISC1:
+  case Xtensa::MISC2:
+  case Xtensa::MISC3:
+    Res = hasMiscSR();
+    Res &= (NumMiscSR > (RegNo - Xtensa::MISC0));
+    break;
+  case Xtensa::THREADPTR:
+    Res = hasTHREADPTR();
+    break;
+  case Xtensa::GPIO_OUT:
+    Res = IsESP32_S2;
+    break;
+  case Xtensa::EXPSTATE:
+    Res = IsESP32;
+    break;
+  case Xtensa::FCR:
+  case Xtensa::FSR:
+    Res = hasSingleFloat();
+    break;
+  case Xtensa::F64R_LO:
+  case Xtensa::F64R_HI:
+  case Xtensa::F64S:
+    Res = hasDFPAccel();
+    break;
+  }
+
+  return Res;
+}
+
+// Force static initialization.
+extern "C" LLVM_EXTERNAL_VISIBILITY void LLVMInitializeXtensaAsmParser() {
+  RegisterMCAsmParser<XtensaAsmParser> X(TheXtensaTarget);
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/CMakeLists.txt
@@ -0,0 +1,34 @@
+set(LLVM_TARGET_DEFINITIONS Xtensa.td)
+
+tablegen(LLVM XtensaGenAsmMatcher.inc -gen-asm-matcher)
+tablegen(LLVM XtensaGenAsmWriter.inc -gen-asm-writer)
+tablegen(LLVM XtensaGenCallingConv.inc -gen-callingconv)
+tablegen(LLVM XtensaGenDAGISel.inc -gen-dag-isel)
+tablegen(LLVM XtensaGenDisassemblerTables.inc -gen-disassembler)
+tablegen(LLVM XtensaGenInstrInfo.inc -gen-instr-info)
+tablegen(LLVM XtensaGenMCCodeEmitter.inc -gen-emitter)
+tablegen(LLVM XtensaGenRegisterInfo.inc -gen-register-info)
+tablegen(LLVM XtensaGenSubtargetInfo.inc -gen-subtarget)
+
+add_public_tablegen_target(XtensaCommonTableGen)
+
+add_llvm_target(XtensaCodeGen
+  XtensaAsmPrinter.cpp
+  XtensaConstantPoolValue.cpp
+  XtensaFrameLowering.cpp
+  XtensaInstrInfo.cpp
+  XtensaISelDAGToDAG.cpp
+  XtensaISelLowering.cpp
+  XtensaMachineFunctionInfo.cpp
+  XtensaMCInstLower.cpp
+  XtensaRegisterInfo.cpp
+  XtensaSizeReductionPass.cpp
+  XtensaSubtarget.cpp
+  XtensaTargetMachine.cpp
+  )
+
+add_subdirectory(AsmParser)
+add_subdirectory(Disassembler)
+add_subdirectory(MCTargetDesc)
+add_subdirectory(TargetInfo)
+
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/Disassembler/CMakeLists.txt
@@ -0,0 +1,3 @@
+add_llvm_component_library(LLVMXtensaDisassembler
+  XtensaDisassembler.cpp
+  )
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/Disassembler/LLVMBuild.txt
@@ -0,0 +1,24 @@
+;===-- ./lib/Target/Xtensa/Disassembler/LLVMBuild.txt ---------*- Conf -*--===;
+;
+;                     The LLVM Compiler Infrastructure
+;
+; Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+; See https://llvm.org/LICENSE.txt for license information.
+; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+[component_0]
+type = Library
+name = XtensaDisassembler
+parent = Xtensa
+required_libraries = MCDisassembler Support XtensaInfo
+add_to_library_groups = Xtensa
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/Disassembler/XtensaDisassembler.cpp
@@ -0,0 +1,682 @@
+//===-- XtensaDisassembler.cpp - Disassembler for Xtensa ------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements the XtensaDisassembler class.
+//
+//===----------------------------------------------------------------------===//
+
+#include "MCTargetDesc/XtensaMCTargetDesc.h"
+#include "llvm/MC/MCContext.h"
+#include "llvm/MC/MCDisassembler/MCDisassembler.h"
+#include "llvm/MC/MCFixedLenDisassembler.h"
+#include "llvm/MC/MCInst.h"
+#include "llvm/MC/MCRegisterInfo.h"
+#include "llvm/MC/MCSubtargetInfo.h"
+#include "llvm/Support/Endian.h"
+#include "llvm/Support/TargetRegistry.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "Xtensa-disassembler"
+
+using DecodeStatus = MCDisassembler::DecodeStatus;
+
+namespace {
+
+class XtensaDisassembler : public MCDisassembler {
+  bool IsLittleEndian;
+
+public:
+  XtensaDisassembler(const MCSubtargetInfo &STI, MCContext &Ctx, bool isLE)
+      : MCDisassembler(STI, Ctx), IsLittleEndian(isLE) {}
+
+  bool hasDensity() const {
+    return STI.getFeatureBits()[Xtensa::FeatureDensity];
+  }
+
+  DecodeStatus getInstruction(MCInst &Instr, uint64_t &Size,
+                              ArrayRef<uint8_t> Bytes, uint64_t Address,
+                              raw_ostream &CStream) const override;
+};
+} // end anonymous namespace
+
+static MCDisassembler *createXtensaDisassembler(const Target &T,
+                                                const MCSubtargetInfo &STI,
+                                                MCContext &Ctx) {
+  return new XtensaDisassembler(STI, Ctx, true);
+}
+
+extern "C" LLVM_EXTERNAL_VISIBILITY void LLVMInitializeXtensaDisassembler() {
+  TargetRegistry::RegisterMCDisassembler(TheXtensaTarget,
+                                         createXtensaDisassembler);
+}
+
+static const unsigned ARDecoderTable[] = {
+    Xtensa::A0,  Xtensa::SP,  Xtensa::A2,  Xtensa::A3, Xtensa::A4,  Xtensa::A5,
+    Xtensa::A6,  Xtensa::A7,  Xtensa::A8,  Xtensa::A9, Xtensa::A10, Xtensa::A11,
+    Xtensa::A12, Xtensa::A13, Xtensa::A14, Xtensa::A15};
+
+static DecodeStatus DecodeARRegisterClass(MCInst &Inst, uint64_t RegNo,
+                                          uint64_t Address,
+                                          const void *Decoder) {
+  if (RegNo >= array_lengthof(ARDecoderTable))
+    return MCDisassembler::Fail;
+
+  unsigned Reg = ARDecoderTable[RegNo];
+  Inst.addOperand(MCOperand::createReg(Reg));
+  return MCDisassembler::Success;
+}
+
+static const unsigned FPRDecoderTable[] = {
+    Xtensa::F0,  Xtensa::F1,  Xtensa::F2,  Xtensa::F3, Xtensa::F4,  Xtensa::F5,
+    Xtensa::F6,  Xtensa::F7,  Xtensa::F8,  Xtensa::F9, Xtensa::F10, Xtensa::F11,
+    Xtensa::F12, Xtensa::F13, Xtensa::F14, Xtensa::F15};
+
+static DecodeStatus DecodeFPRRegisterClass(MCInst &Inst, uint64_t RegNo,
+                                           uint64_t Address,
+                                           const void *Decoder) {
+  if (RegNo >= array_lengthof(FPRDecoderTable))
+    return MCDisassembler::Fail;
+
+  unsigned Reg = FPRDecoderTable[RegNo];
+  Inst.addOperand(MCOperand::createReg(Reg));
+  return MCDisassembler::Success;
+}
+
+static const unsigned BRDecoderTable[] = {
+    Xtensa::B0,  Xtensa::B1,  Xtensa::B2,  Xtensa::B3, Xtensa::B4,  Xtensa::B5,
+    Xtensa::B6,  Xtensa::B7,  Xtensa::B8,  Xtensa::B9, Xtensa::B10, Xtensa::B11,
+    Xtensa::B12, Xtensa::B13, Xtensa::B14, Xtensa::B15};
+
+static DecodeStatus DecodeBRRegisterClass(MCInst &Inst, uint64_t RegNo,
+                                          uint64_t Address,
+                                          const void *Decoder) {
+  if (RegNo >= array_lengthof(BRDecoderTable))
+    return MCDisassembler::Fail;
+
+  unsigned Reg = BRDecoderTable[RegNo];
+  Inst.addOperand(MCOperand::createReg(Reg));
+  return MCDisassembler::Success;
+}
+
+static const unsigned MRDecoderTable[] = {Xtensa::M0, Xtensa::M1, Xtensa::M2,
+                                          Xtensa::M3};
+
+static DecodeStatus DecodeMRRegisterClass(MCInst &Inst, uint64_t RegNo,
+                                          uint64_t Address,
+                                          const void *Decoder) {
+  if (RegNo >= array_lengthof(MRDecoderTable))
+    return MCDisassembler::Fail;
+
+  unsigned Reg = MRDecoderTable[RegNo];
+  Inst.addOperand(MCOperand::createReg(Reg));
+  return MCDisassembler::Success;
+}
+
+static const unsigned MR01DecoderTable[] = {Xtensa::M0, Xtensa::M1};
+
+static DecodeStatus DecodeMR01RegisterClass(MCInst &Inst, uint64_t RegNo,
+                                            uint64_t Address,
+                                            const void *Decoder) {
+  if (RegNo > 2)
+    return MCDisassembler::Fail;
+
+  unsigned Reg = MR01DecoderTable[RegNo];
+  Inst.addOperand(MCOperand::createReg(Reg));
+  return MCDisassembler::Success;
+}
+
+static const unsigned MR23DecoderTable[] = {Xtensa::M2, Xtensa::M3};
+
+static DecodeStatus DecodeMR23RegisterClass(MCInst &Inst, uint64_t RegNo,
+                                            uint64_t Address,
+                                            const void *Decoder) {
+  if ((RegNo < 2) || (RegNo > 3))
+    return MCDisassembler::Fail;
+
+  unsigned Reg = MR23DecoderTable[RegNo - 2];
+  Inst.addOperand(MCOperand::createReg(Reg));
+  return MCDisassembler::Success;
+}
+
+// Verify SR and UR
+bool CheckRegister(unsigned RegNo, MCSubtargetInfo STI) {
+  StringRef CPU = STI.getCPU();
+  unsigned NumIntLevels = 0;
+  unsigned NumTimers = 0;
+  unsigned NumMiscSR = 0;
+  bool IsESP32 = false;
+  bool IsESP32_S2 = false;
+  bool Res = true;
+
+  // Assume that CPU is esp32 by default
+  if ((CPU == "esp32") || (CPU == "")) {
+    NumIntLevels = 6;
+    NumTimers = 3;
+    NumMiscSR = 4;
+    IsESP32 = true;
+  } else if (CPU == "esp32-s2") {
+    NumIntLevels = 6;
+    NumTimers = 3;
+    NumMiscSR = 4;
+    IsESP32_S2 = true;
+  } else if (CPU == "esp8266") {
+    NumIntLevels = 2;
+    NumTimers = 1;
+  }
+
+  switch (RegNo) {
+  case Xtensa::LBEG:
+  case Xtensa::LEND:
+  case Xtensa::LCOUNT:
+    Res = STI.getFeatureBits()[Xtensa::FeatureLoop];
+    break;
+  case Xtensa::BREG:
+    Res = STI.getFeatureBits()[Xtensa::FeatureBoolean];
+    break;
+  case Xtensa::LITBASE:
+    Res = STI.getFeatureBits()[Xtensa::FeatureExtendedL32R];
+    break;
+  case Xtensa::SCOMPARE1:
+    Res = STI.getFeatureBits()[Xtensa::FeatureS32C1I];
+    break;
+  case Xtensa::ACCLO:
+  case Xtensa::ACCHI:
+  case Xtensa::M0:
+  case Xtensa::M1:
+  case Xtensa::M2:
+  case Xtensa::M3:
+    Res = STI.getFeatureBits()[Xtensa::FeatureMAC16];
+    break;
+  case Xtensa::WINDOWBASE:
+  case Xtensa::WINDOWSTART:
+    Res = STI.getFeatureBits()[Xtensa::FeatureWindowed];
+    break;
+  case Xtensa::IBREAKENABLE:
+  case Xtensa::IBREAKA0:
+  case Xtensa::IBREAKA1:
+  case Xtensa::DBREAKA0:
+  case Xtensa::DBREAKA1:
+  case Xtensa::DBREAKC0:
+  case Xtensa::DBREAKC1:
+  case Xtensa::DEBUGCAUSE:
+  case Xtensa::ICOUNT:
+  case Xtensa::ICOUNTLEVEL:
+    Res = STI.getFeatureBits()[Xtensa::FeatureDebug];
+    break;
+  case Xtensa::ATOMCTL:
+    Res = STI.getFeatureBits()[Xtensa::FeatureATOMCTL];
+    break;
+  case Xtensa::MEMCTL:
+    Res = STI.getFeatureBits()[Xtensa::FeatureMEMCTL];
+    break;
+  case Xtensa::EPC1:
+    Res = STI.getFeatureBits()[Xtensa::FeatureException];
+    break;
+  case Xtensa::EPC2:
+  case Xtensa::EPC3:
+  case Xtensa::EPC4:
+  case Xtensa::EPC5:
+  case Xtensa::EPC6:
+  case Xtensa::EPC7:
+    Res = STI.getFeatureBits()[Xtensa::FeatureHighPriInterrupts];
+    Res = Res & (NumIntLevels >= (RegNo - Xtensa::EPC1));
+    break;
+  case Xtensa::EPS2:
+  case Xtensa::EPS3:
+  case Xtensa::EPS4:
+  case Xtensa::EPS5:
+  case Xtensa::EPS6:
+  case Xtensa::EPS7:
+    Res = STI.getFeatureBits()[Xtensa::FeatureHighPriInterrupts];
+    Res = Res & (NumIntLevels > (RegNo - Xtensa::EPS2));
+    break;
+  case Xtensa::EXCSAVE1:
+    Res = STI.getFeatureBits()[Xtensa::FeatureException];
+    break;
+  case Xtensa::EXCSAVE2:
+  case Xtensa::EXCSAVE3:
+  case Xtensa::EXCSAVE4:
+  case Xtensa::EXCSAVE5:
+  case Xtensa::EXCSAVE6:
+  case Xtensa::EXCSAVE7:
+    Res = STI.getFeatureBits()[Xtensa::FeatureHighPriInterrupts];
+    Res = Res & (NumIntLevels >= (RegNo - Xtensa::EXCSAVE1));
+    break;
+  case Xtensa::DEPC:
+  case Xtensa::EXCCAUSE:
+  case Xtensa::EXCVADDR:
+    Res = STI.getFeatureBits()[Xtensa::FeatureException];
+    break;
+  case Xtensa::CPENABLE:
+    Res = STI.getFeatureBits()[Xtensa::FeatureCoprocessor];
+    break;
+  case Xtensa::VECBASE:
+    Res = STI.getFeatureBits()[Xtensa::FeatureRelocatableVector];
+    break;
+  case Xtensa::CCOUNT:
+    Res = STI.getFeatureBits()[Xtensa::FeatureTimerInt];
+    Res &= (NumTimers > 0);
+    break;
+  case Xtensa::CCOMPARE0:
+  case Xtensa::CCOMPARE1:
+  case Xtensa::CCOMPARE2:
+    Res = STI.getFeatureBits()[Xtensa::FeatureTimerInt];
+    Res &= (NumTimers > (RegNo - Xtensa::CCOMPARE0));
+    break;
+  case Xtensa::PRID:
+    Res = STI.getFeatureBits()[Xtensa::FeaturePRID];
+    break;
+  case Xtensa::INTSET:
+  case Xtensa::INTCLEAR:
+  case Xtensa::INTENABLE:
+    Res = STI.getFeatureBits()[Xtensa::FeatureInterrupt];
+    break;
+  case Xtensa::MISC0:
+  case Xtensa::MISC1:
+  case Xtensa::MISC2:
+  case Xtensa::MISC3:
+    Res = STI.getFeatureBits()[Xtensa::FeatureMiscSR];
+    Res &= (NumMiscSR > (RegNo - Xtensa::MISC0));
+    break;
+  case Xtensa::THREADPTR:
+    Res = STI.getFeatureBits()[Xtensa::FeatureTHREADPTR];
+    break;
+  case Xtensa::GPIO_OUT:
+    Res = IsESP32_S2;
+    break;
+  case Xtensa::EXPSTATE:
+    Res = IsESP32;
+    break;
+  case Xtensa::FCR:
+  case Xtensa::FSR:
+    Res = STI.getFeatureBits()[Xtensa::FeatureSingleFloat];
+    break;
+  case Xtensa::F64R_LO:
+  case Xtensa::F64R_HI:
+  case Xtensa::F64S:
+    Res = STI.getFeatureBits()[Xtensa::FeatureDFPAccel];
+    break;
+  }
+
+  return Res;
+}
+
+static const unsigned SRDecoderTable[] = {
+    Xtensa::LBEG,        0,   Xtensa::LEND,         1,
+    Xtensa::LCOUNT,      2,   Xtensa::SAR,          3,
+    Xtensa::BREG,        4,   Xtensa::LITBASE,      5,
+    Xtensa::SCOMPARE1,   12,  Xtensa::ACCLO,        16,
+    Xtensa::ACCHI,       17,  Xtensa::M0,           32,
+    Xtensa::M1,          33,  Xtensa::M2,           34,
+    Xtensa::M3,          35,  Xtensa::WINDOWBASE,   72,
+    Xtensa::WINDOWSTART, 73,  Xtensa::IBREAKENABLE, 96,
+    Xtensa::MEMCTL,      97,  Xtensa::ATOMCTL,      99,
+    Xtensa::DDR,         104, Xtensa::IBREAKA0,     128,
+    Xtensa::IBREAKA1,    129, Xtensa::DBREAKA0,     144,
+    Xtensa::DBREAKA1,    145, Xtensa::DBREAKC0,     160,
+    Xtensa::DBREAKC1,    161, Xtensa::CONFIGID0,    176,
+    Xtensa::EPC1,        177, Xtensa::EPC2,         178,
+    Xtensa::EPC3,        179, Xtensa::EPC4,         180,
+    Xtensa::EPC5,        181, Xtensa::EPC6,         182,
+    Xtensa::EPC7,        183, Xtensa::DEPC,         192,
+    Xtensa::EPS2,        194, Xtensa::EPS3,         195,
+    Xtensa::EPS4,        196, Xtensa::EPS5,         197,
+    Xtensa::EPS6,        198, Xtensa::EPS7,         199,
+    Xtensa::CONFIGID1,   208, Xtensa::EXCSAVE1,     209,
+    Xtensa::EXCSAVE2,    210, Xtensa::EXCSAVE3,     211,
+    Xtensa::EXCSAVE4,    212, Xtensa::EXCSAVE5,     213,
+    Xtensa::EXCSAVE6,    214, Xtensa::EXCSAVE7,     215,
+    Xtensa::CPENABLE,    224, Xtensa::INTSET,       226,
+    Xtensa::INTCLEAR,    227, Xtensa::INTENABLE,    228,
+    Xtensa::PS,          230, Xtensa::VECBASE,      231,
+    Xtensa::EXCCAUSE,    232, Xtensa::DEBUGCAUSE,   233,
+    Xtensa::CCOUNT,      234, Xtensa::PRID,         235,
+    Xtensa::ICOUNT,      236, Xtensa::ICOUNTLEVEL,  237,
+    Xtensa::EXCVADDR,    238, Xtensa::CCOMPARE0,    240,
+    Xtensa::CCOMPARE1,   241, Xtensa::CCOMPARE2,    242,
+    Xtensa::MISC0,       244, Xtensa::MISC1,        245,
+    Xtensa::MISC2,       246, Xtensa::MISC3,        247};
+
+static DecodeStatus DecodeSRRegisterClass(MCInst &Inst, uint64_t RegNo,
+                                          uint64_t Address,
+                                          const void *Decoder) {
+  const llvm::MCSubtargetInfo STI =
+      ((const MCDisassembler *)Decoder)->getSubtargetInfo();
+
+  if (RegNo > 255)
+    return MCDisassembler::Fail;
+
+  for (unsigned i = 0; i < array_lengthof(SRDecoderTable); i += 2) {
+    if (SRDecoderTable[i + 1] == RegNo) {
+      unsigned Reg = SRDecoderTable[i];
+
+      if (!CheckRegister(Reg, STI))
+        return MCDisassembler::Fail;
+
+      Inst.addOperand(MCOperand::createReg(Reg));
+      return MCDisassembler::Success;
+    }
+  }
+
+  return MCDisassembler::Fail;
+}
+
+static const unsigned URDecoderTable[] = {
+    Xtensa::GPIO_OUT, 0,   Xtensa::EXPSTATE, 230, Xtensa::THREADPTR, 231,
+    Xtensa::FCR,      232, Xtensa::FSR,      233, Xtensa::F64R_LO,   234,
+    Xtensa::F64R_HI,  235, Xtensa::F64S,     236};
+
+static DecodeStatus DecodeURRegisterClass(MCInst &Inst, uint64_t RegNo,
+                                          uint64_t Address,
+                                          const void *Decoder) {
+  const llvm::MCSubtargetInfo STI =
+      ((const MCDisassembler *)Decoder)->getSubtargetInfo();
+
+  if (RegNo > 255)
+    return MCDisassembler::Fail;
+
+  for (unsigned i = 0; i < array_lengthof(URDecoderTable); i += 2) {
+    if (URDecoderTable[i + 1] == RegNo) {
+      unsigned Reg = URDecoderTable[i];
+
+      if (!CheckRegister(Reg, STI))
+        return MCDisassembler::Fail;
+
+      Inst.addOperand(MCOperand::createReg(Reg));
+      return MCDisassembler::Success;
+    }
+  }
+
+  return MCDisassembler::Fail;
+}
+
+static bool tryAddingSymbolicOperand(int64_t Value, bool isBranch,
+                                     uint64_t Address, uint64_t Offset,
+                                     uint64_t Width, MCInst &MI,
+                                     const void *Decoder) {
+  const MCDisassembler *Dis = static_cast<const MCDisassembler *>(Decoder);
+  return Dis->tryAddingSymbolicOperand(MI, Value, Address, isBranch, Offset,
+                                       Width);
+}
+
+static DecodeStatus decodeCallOperand(MCInst &Inst, uint64_t Imm,
+                                      int64_t Address, const void *Decoder) {
+  assert(isUInt<18>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(SignExtend64<20>(Imm << 2)));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeJumpOperand(MCInst &Inst, uint64_t Imm,
+                                      int64_t Address, const void *Decoder) {
+  assert(isUInt<18>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(SignExtend64<18>(Imm)));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeBranchOperand(MCInst &Inst, uint64_t Imm,
+                                        int64_t Address, const void *Decoder) {
+  switch (Inst.getOpcode()) {
+  case Xtensa::BEQZ:
+  case Xtensa::BGEZ:
+  case Xtensa::BLTZ:
+  case Xtensa::BNEZ:
+    assert(isUInt<12>(Imm) && "Invalid immediate");
+    if (!tryAddingSymbolicOperand(SignExtend64<12>(Imm) + 4 + Address, true,
+                                  Address, 0, 3, Inst, Decoder))
+      Inst.addOperand(MCOperand::createImm(SignExtend64<12>(Imm)));
+    break;
+  default:
+    assert(isUInt<8>(Imm) && "Invalid immediate");
+    if (!tryAddingSymbolicOperand(SignExtend64<8>(Imm) + 4 + Address, true,
+                                  Address, 0, 3, Inst, Decoder))
+      Inst.addOperand(MCOperand::createImm(SignExtend64<8>(Imm)));
+  }
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeL32ROperand(MCInst &Inst, uint64_t Imm,
+                                      int64_t Address, const void *Decoder) {
+
+  assert(isUInt<16>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(
+      SignExtend64<17>((Imm << 2) + 0x40000 + (Address & 0x3))));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeImm8Operand(MCInst &Inst, uint64_t Imm,
+                                      int64_t Address, const void *Decoder) {
+  assert(isUInt<8>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(SignExtend64<8>(Imm)));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeImm8_sh8Operand(MCInst &Inst, uint64_t Imm,
+                                          int64_t Address,
+                                          const void *Decoder) {
+  assert(isUInt<8>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(SignExtend64<16>(Imm << 8)));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeImm12Operand(MCInst &Inst, uint64_t Imm,
+                                       int64_t Address, const void *Decoder) {
+  assert(isUInt<12>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(SignExtend64<12>(Imm)));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeUimm4Operand(MCInst &Inst, uint64_t Imm,
+                                       int64_t Address, const void *Decoder) {
+  assert(isUInt<4>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(Imm));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeUimm5Operand(MCInst &Inst, uint64_t Imm,
+                                       int64_t Address, const void *Decoder) {
+  assert(isUInt<5>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(Imm));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeImm1_16Operand(MCInst &Inst, uint64_t Imm,
+                                         int64_t Address, const void *Decoder) {
+  assert(isUInt<4>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(Imm + 1));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeImm1n_15Operand(MCInst &Inst, uint64_t Imm,
+                                          int64_t Address,
+                                          const void *Decoder) {
+  assert(isUInt<4>(Imm) && "Invalid immediate");
+  if (!Imm)
+    Inst.addOperand(MCOperand::createImm(-1));
+  else
+    Inst.addOperand(MCOperand::createImm(Imm));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeImm32n_95Operand(MCInst &Inst, uint64_t Imm,
+                                           int64_t Address,
+                                           const void *Decoder) {
+  assert(isUInt<7>(Imm) && "Invalid immediate");
+  if ((Imm & 0x60) == 0x60)
+    Inst.addOperand(MCOperand::createImm((~0x1f) | Imm));
+  else
+    Inst.addOperand(MCOperand::createImm(Imm));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeImm8n_7Operand(MCInst &Inst, uint64_t Imm,
+                                         int64_t Address, const void *Decoder) {
+  assert(isUInt<4>(Imm) && "Invalid immediate");
+  if (Imm > 7)
+    Inst.addOperand(MCOperand::createImm(Imm - 16));
+  else
+    Inst.addOperand(MCOperand::createImm(Imm));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeImm64n_4nOperand(MCInst &Inst, uint64_t Imm,
+                                           int64_t Address,
+                                           const void *Decoder) {
+  assert(isUInt<4>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm((~0x3f) | (Imm << 2)));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeEntry_Imm12OpValue(MCInst &Inst, uint64_t Imm,
+                                             int64_t Address,
+                                             const void *Decoder) {
+  assert(isUInt<12>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(Imm << 3));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeShimm1_31Operand(MCInst &Inst, uint64_t Imm,
+                                           int64_t Address,
+                                           const void *Decoder) {
+  assert(isUInt<5>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(32 - Imm));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeSeimm7_22Operand(MCInst &Inst, uint64_t Imm,
+                                           int64_t Address,
+                                           const void *Decoder) {
+  assert(isUInt<4>(Imm) && "Invalid immediate");
+  Inst.addOperand(MCOperand::createImm(Imm + 7));
+  return MCDisassembler::Success;
+}
+
+static int64_t TableB4const[16] = {-1, 1,  2,  3,  4,  5,  6,   7,
+                                   8,  10, 12, 16, 32, 64, 128, 256};
+static DecodeStatus decodeB4constOperand(MCInst &Inst, uint64_t Imm,
+                                         int64_t Address, const void *Decoder) {
+  assert(isUInt<4>(Imm) && "Invalid immediate");
+
+  Inst.addOperand(MCOperand::createImm(TableB4const[Imm]));
+  return MCDisassembler::Success;
+}
+
+static int64_t TableB4constu[16] = {32768, 65536, 2,  3,  4,  5,  6,   7,
+                                    8,     10,    12, 16, 32, 64, 128, 256};
+static DecodeStatus decodeB4constuOperand(MCInst &Inst, uint64_t Imm,
+                                          int64_t Address,
+                                          const void *Decoder) {
+  assert(isUInt<4>(Imm) && "Invalid immediate");
+
+  Inst.addOperand(MCOperand::createImm(TableB4constu[Imm]));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeMem8Operand(MCInst &Inst, uint64_t Imm,
+                                      int64_t Address, const void *Decoder) {
+  assert(isUInt<12>(Imm) && "Invalid immediate");
+  DecodeARRegisterClass(Inst, Imm & 0xf, Address, Decoder);
+  Inst.addOperand(MCOperand::createImm((Imm >> 4) & 0xff));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeMem16Operand(MCInst &Inst, uint64_t Imm,
+                                       int64_t Address, const void *Decoder) {
+  assert(isUInt<12>(Imm) && "Invalid immediate");
+  DecodeARRegisterClass(Inst, Imm & 0xf, Address, Decoder);
+  Inst.addOperand(MCOperand::createImm((Imm >> 3) & 0x1fe));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeMem32Operand(MCInst &Inst, uint64_t Imm,
+                                       int64_t Address, const void *Decoder) {
+  assert(isUInt<12>(Imm) && "Invalid immediate");
+  DecodeARRegisterClass(Inst, Imm & 0xf, Address, Decoder);
+  Inst.addOperand(MCOperand::createImm((Imm >> 2) & 0x3fc));
+  return MCDisassembler::Success;
+}
+
+static DecodeStatus decodeMem32nOperand(MCInst &Inst, uint64_t Imm,
+                                        int64_t Address, const void *Decoder) {
+  assert(isUInt<8>(Imm) && "Invalid immediate");
+  DecodeARRegisterClass(Inst, Imm & 0xf, Address, Decoder);
+  Inst.addOperand(MCOperand::createImm((Imm >> 2) & 0x3c));
+  return MCDisassembler::Success;
+}
+
+/// Read two bytes from the ArrayRef and return 16 bit data sorted
+/// according to the given endianness.
+static DecodeStatus readInstruction16(ArrayRef<uint8_t> Bytes, uint64_t Address,
+                                      uint64_t &Size, uint32_t &Insn,
+                                      bool IsLittleEndian) {
+  // We want to read exactly 2 Bytes of data.
+  if (Bytes.size() < 2) {
+    Size = 0;
+    return MCDisassembler::Fail;
+  }
+
+  if (!IsLittleEndian) {
+    llvm_unreachable("Big-endian mode currently is not supported!");
+  } else {
+    Insn = (Bytes[1] << 8) | Bytes[0];
+  }
+
+  return MCDisassembler::Success;
+}
+
+/// Read four bytes from the ArrayRef and return 24 bit data sorted
+/// according to the given endianness.
+static DecodeStatus readInstruction24(ArrayRef<uint8_t> Bytes, uint64_t Address,
+                                      uint64_t &Size, uint32_t &Insn,
+                                      bool IsLittleEndian) {
+  // We want to read exactly 3 Bytes of data.
+  if (Bytes.size() < 3) {
+    Size = 0;
+    return MCDisassembler::Fail;
+  }
+
+  if (!IsLittleEndian) {
+    llvm_unreachable("Big-endian mode currently is not supported!");
+  } else {
+    Insn = (Bytes[2] << 16) | (Bytes[1] << 8) | (Bytes[0] << 0);
+  }
+
+  return MCDisassembler::Success;
+}
+
+#include "XtensaGenDisassemblerTables.inc"
+
+DecodeStatus XtensaDisassembler::getInstruction(MCInst &MI, uint64_t &Size,
+                                                ArrayRef<uint8_t> Bytes,
+                                                uint64_t Address,
+                                                raw_ostream &CS) const {
+  uint32_t Insn;
+  DecodeStatus Result;
+
+  if (hasDensity()) {
+    Result = readInstruction16(Bytes, Address, Size, Insn, IsLittleEndian);
+    if (Result == MCDisassembler::Fail)
+      return MCDisassembler::Fail;
+    LLVM_DEBUG(dbgs() << "Trying Xtensa 16-bit instruction table :\n");
+    Result = decodeInstruction(DecoderTable16, MI, Insn, Address, this, STI);
+    if (Result != MCDisassembler::Fail) {
+      Size = 2;
+      return Result;
+    }
+  }
+
+  Result = readInstruction24(Bytes, Address, Size, Insn, IsLittleEndian);
+  if (Result == MCDisassembler::Fail)
+    return MCDisassembler::Fail;
+  LLVM_DEBUG(dbgs() << "Trying Xtensa 24-bit instruction table :\n");
+  Result = decodeInstruction(DecoderTable24, MI, Insn, Address, this, STI);
+  Size = 3;
+  return Result;
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/LLVMBuild.txt
@@ -0,0 +1,33 @@
+;===- ./lib/Target/Xtensa/LLVMBuild.txt ------------------------*- Conf -*--===;
+;
+; Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+; See https://llvm.org/LICENSE.txt for license information.
+; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+[common]
+subdirectories = AsmParser Disassembler TargetInfo MCTargetDesc
+
+[component_0]
+type = TargetGroup
+name = Xtensa
+parent = Target
+has_asmparser = 1
+has_asmprinter = 1
+has_disassembler = 1
+
+[component_1]
+type = Library
+name = XtensaCodeGen
+parent = Xtensa
+required_libraries = AsmPrinter CodeGen Core MC SelectionDAG XtensaDesc XtensaInfo Support Target
+add_to_library_groups = Xtensa
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/CMakeLists.txt
@@ -0,0 +1,10 @@
+add_llvm_component_library(LLVMXtensaDesc
+  XtensaAsmBackend.cpp
+  XtensaELFObjectWriter.cpp
+  XtensaInstPrinter.cpp
+  XtensaMCAsmInfo.cpp
+  XtensaMCCodeEmitter.cpp
+  XtensaMCExpr.cpp
+  XtensaMCTargetDesc.cpp
+  XtensaTargetStreamer.cpp
+ )
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/LLVMBuild.txt
@@ -0,0 +1,22 @@
+;===- ./lib/Target/MCTargetDesc/LLVMBuild.txt ------------------*- Conf -*--===;
+;
+; Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+; See https://llvm.org/LICENSE.txt for license information.
+; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+[component_0]
+type = Library
+name = XtensaDesc
+parent = Xtensa
+required_libraries = MC XtensaInfo Support
+add_to_library_groups = Xtensa
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaAsmBackend.cpp
@@ -0,0 +1,221 @@
+//===-- XtensaMCAsmBackend.cpp - Xtensa assembler backend ---------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===--------------------------------------------------------------------===//
+
+#include "MCTargetDesc/XtensaFixupKinds.h"
+#include "MCTargetDesc/XtensaMCTargetDesc.h"
+#include "llvm/MC/MCAsmBackend.h"
+#include "llvm/MC/MCAssembler.h"
+#include "llvm/MC/MCContext.h"
+#include "llvm/MC/MCELFObjectWriter.h"
+#include "llvm/MC/MCFixupKindInfo.h"
+#include "llvm/MC/MCInst.h"
+#include "llvm/MC/MCObjectWriter.h"
+#include "llvm/MC/MCSubtargetInfo.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+
+namespace llvm {
+class MCObjectTargetWriter;
+class XtensaMCAsmBackend : public MCAsmBackend {
+  uint8_t OSABI;
+  bool IsLittleEndian;
+
+public:
+  XtensaMCAsmBackend(uint8_t osABI, bool isLE)
+      : MCAsmBackend(support::little), OSABI(osABI), IsLittleEndian(isLE) {}
+
+  unsigned getNumFixupKinds() const override {
+    return Xtensa::NumTargetFixupKinds;
+  }
+  const MCFixupKindInfo &getFixupKindInfo(MCFixupKind Kind) const override;
+  void applyFixup(const MCAssembler &Asm, const MCFixup &Fixup,
+                  const MCValue &Target, MutableArrayRef<char> Data,
+                  uint64_t Value, bool IsResolved,
+                  const MCSubtargetInfo *STI) const override;
+  bool mayNeedRelaxation(const MCInst &Inst,
+                         const MCSubtargetInfo &STI) const override;
+  bool fixupNeedsRelaxation(const MCFixup &Fixup, uint64_t Value,
+                            const MCRelaxableFragment *Fragment,
+                            const MCAsmLayout &Layout) const override;
+  void relaxInstruction(const MCInst &Inst, const MCSubtargetInfo &STI,
+                        MCInst &Res) const override;
+  bool writeNopData(raw_ostream &OS, uint64_t Count) const override;
+
+  std::unique_ptr<MCObjectTargetWriter> createObjectTargetWriter() const {
+    return createXtensaObjectWriter(OSABI, IsLittleEndian);
+  }
+};
+} // namespace llvm
+
+const MCFixupKindInfo &
+XtensaMCAsmBackend::getFixupKindInfo(MCFixupKind Kind) const {
+  const static MCFixupKindInfo Infos[Xtensa::NumTargetFixupKinds] = {
+      // name                     offset bits  flags
+      {"fixup_xtensa_branch_6", 0, 16, MCFixupKindInfo::FKF_IsPCRel},
+      {"fixup_xtensa_branch_8", 16, 8, MCFixupKindInfo::FKF_IsPCRel},
+      {"fixup_xtensa_branch_12", 12, 12, MCFixupKindInfo::FKF_IsPCRel},
+      {"fixup_xtensa_jump_18", 6, 18, MCFixupKindInfo::FKF_IsPCRel},
+      {"fixup_xtensa_call_18", 6, 18,
+       MCFixupKindInfo::FKF_IsPCRel |
+           MCFixupKindInfo::FKF_IsAlignedDownTo32Bits},
+      {"fixup_xtensa_l32r_16", 8, 16,
+       MCFixupKindInfo::FKF_IsPCRel |
+           MCFixupKindInfo::FKF_IsAlignedDownTo32Bits}};
+
+  if (Kind < FirstTargetFixupKind)
+    return MCAsmBackend::getFixupKindInfo(Kind);
+  assert(unsigned(Kind - FirstTargetFixupKind) < getNumFixupKinds() &&
+         "Invalid kind!");
+  return Infos[Kind - FirstTargetFixupKind];
+}
+
+static uint64_t adjustFixupValue(const MCFixup &Fixup, uint64_t Value,
+                                 MCContext &Ctx) {
+  unsigned Kind = Fixup.getKind();
+  switch (Kind) {
+  default:
+    llvm_unreachable("Unknown fixup kind!");
+  case FK_Data_1:
+  case FK_Data_2:
+  case FK_Data_4:
+  case FK_Data_8:
+    return Value;
+  case Xtensa::fixup_xtensa_branch_6: {
+    Value -= 4;
+    if (!isInt<6>(Value))
+      Ctx.reportError(Fixup.getLoc(), "fixup value out of range");
+    unsigned Hi2 = (Value >> 4) & 0x3;
+    unsigned Lo4 = (Value)&0xf;
+    return (Hi2 << 4) | (Lo4 << 12);
+  }
+  case Xtensa::fixup_xtensa_branch_8:
+    Value -= 4;
+    if (!isInt<8>(Value))
+      Ctx.reportError(Fixup.getLoc(), "fixup value out of range");
+    return (Value & 0xff);
+  case Xtensa::fixup_xtensa_branch_12:
+    Value -= 4;
+    if (!isInt<12>(Value))
+      Ctx.reportError(Fixup.getLoc(), "fixup value out of range");
+    return (Value & 0xfff);
+  case Xtensa::fixup_xtensa_jump_18:
+    Value -= 4;
+    if (!isInt<18>(Value))
+      Ctx.reportError(Fixup.getLoc(), "fixup value out of range");
+    return (Value & 0x3ffff);
+  case Xtensa::fixup_xtensa_call_18:
+    Value -= 4;
+    if (!isInt<20>(Value))
+      Ctx.reportError(Fixup.getLoc(), "fixup value out of range");
+    if (Value & 0x3)
+      Ctx.reportError(Fixup.getLoc(), "fixup value must be 4-byte aligned");
+    return (Value & 0xffffc) >> 2;
+  case Xtensa::fixup_xtensa_l32r_16:
+    unsigned Offset = Fixup.getOffset();
+    if (Offset & 0x3)
+      Value -= 4;
+    if (!isInt<18>(Value) && (Value & 0x20000))
+      Ctx.reportError(Fixup.getLoc(), "fixup value out of range");
+    if (Value & 0x3)
+      Ctx.reportError(Fixup.getLoc(), "fixup value must be 4-byte aligned");
+    return (Value & 0x3fffc) >> 2;
+  }
+}
+
+static unsigned getSize(unsigned Kind) {
+  switch (Kind) {
+  default:
+    return 3;
+  case MCFixupKind::FK_Data_4:
+    return 4;
+  case Xtensa::fixup_xtensa_branch_6:
+    return 2;
+  }
+}
+
+void XtensaMCAsmBackend::applyFixup(const MCAssembler &Asm,
+                                    const MCFixup &Fixup, const MCValue &Target,
+                                    MutableArrayRef<char> Data, uint64_t Value,
+                                    bool IsResolved,
+                                    const MCSubtargetInfo *STI) const {
+  MCContext &Ctx = Asm.getContext();
+  MCFixupKindInfo Info = getFixupKindInfo(Fixup.getKind());
+
+  Value = adjustFixupValue(Fixup, Value, Ctx);
+
+  // Shift the value into position.
+  Value <<= Info.TargetOffset;
+
+  if (!Value)
+    return; // Doesn't change encoding.
+
+  unsigned Offset = Fixup.getOffset();
+  unsigned FullSize = getSize(Fixup.getKind());
+
+  for (unsigned i = 0; i != FullSize; ++i) {
+    Data[Offset + i] |= uint8_t((Value >> (i * 8)) & 0xff);
+  }
+}
+
+bool XtensaMCAsmBackend::mayNeedRelaxation(const MCInst &Inst,
+                                           const MCSubtargetInfo &STI) const {
+  return false;
+}
+
+bool XtensaMCAsmBackend::fixupNeedsRelaxation(
+    const MCFixup &Fixup, uint64_t Value, const MCRelaxableFragment *Fragment,
+    const MCAsmLayout &Layout) const {
+  return false;
+}
+
+void XtensaMCAsmBackend::relaxInstruction(const MCInst &Inst,
+                                          const MCSubtargetInfo &STI,
+                                          MCInst &Res) const {}
+
+bool XtensaMCAsmBackend::writeNopData(raw_ostream &OS, uint64_t Count) const {
+  uint64_t NumNops24b = Count / 3;
+
+  for (uint64_t i = 0; i != NumNops24b; ++i) {
+    // Currently just little-endian machine supported,
+    // but probably big-endian will be also implemented in future
+    if (IsLittleEndian) {
+      OS.write("\xf0", 1);
+      OS.write("\x20", 1);
+      OS.write("\0x00", 1);
+    } else {
+      llvm_unreachable("Big-endian mode currently is not supported!");
+    }
+    Count -= 3;
+  }
+
+  // TODO maybe function should return error if (Count > 0)
+  switch (Count) {
+  default:
+    break;
+  case 1:
+    OS.write("\0", 1);
+    break;
+  case 2:
+    OS.write("\0\0", 2);
+    break;
+  }
+
+  return true;
+}
+
+MCAsmBackend *llvm::createXtensaMCAsmBackend(const Target &T,
+                                             const MCSubtargetInfo &STI,
+                                             const MCRegisterInfo &MRI,
+                                             const MCTargetOptions &Options) {
+  uint8_t OSABI =
+      MCELFObjectTargetWriter::getOSABI(STI.getTargetTriple().getOS());
+  return new llvm::XtensaMCAsmBackend(OSABI, true);
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaELFObjectWriter.cpp
@@ -0,0 +1,70 @@
+//===-- XtensaMCObjectWriter.cpp - Xtensa ELF writer ----------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#include "MCTargetDesc/XtensaMCTargetDesc.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/BinaryFormat/ELF.h"
+#include "llvm/MC/MCELFObjectWriter.h"
+#include "llvm/MC/MCExpr.h"
+#include "llvm/MC/MCFixup.h"
+#include "llvm/MC/MCObjectWriter.h"
+#include "llvm/MC/MCValue.h"
+#include "llvm/Support/ErrorHandling.h"
+#include <cassert>
+#include <cstdint>
+
+using namespace llvm;
+
+namespace {
+class XtensaObjectWriter : public MCELFObjectTargetWriter {
+public:
+  XtensaObjectWriter(uint8_t OSABI);
+
+  virtual ~XtensaObjectWriter();
+
+protected:
+  unsigned getRelocType(MCContext &Ctx, const MCValue &Target,
+                        const MCFixup &Fixup, bool IsPCRel) const override;
+  bool needsRelocateWithSymbol(const MCSymbol &Sym,
+                               unsigned Type) const override;
+};
+} // namespace
+
+XtensaObjectWriter::XtensaObjectWriter(uint8_t OSABI)
+    : MCELFObjectTargetWriter(false, OSABI, ELF::EM_XTENSA,
+                              /*HasRelocationAddend=*/true) {}
+
+XtensaObjectWriter::~XtensaObjectWriter() {}
+
+unsigned XtensaObjectWriter::getRelocType(MCContext &Ctx, const MCValue &Target,
+                                          const MCFixup &Fixup,
+                                          bool IsPCRel) const {
+  MCSymbolRefExpr::VariantKind Modifier = Target.getAccessVariant();
+
+  switch ((unsigned)Fixup.getKind()) {
+  case FK_Data_4:
+    if (Modifier == MCSymbolRefExpr::VariantKind::VK_TPOFF)
+      return ELF::R_XTENSA_TLS_TPOFF;
+    else
+      return ELF::R_XTENSA_32;
+  default:
+    return ELF::R_XTENSA_SLOT0_OP;
+  }
+}
+
+std::unique_ptr<MCObjectTargetWriter>
+llvm::createXtensaObjectWriter(uint8_t OSABI, bool IsLittleEndian) {
+  return std::make_unique<XtensaObjectWriter>(OSABI);
+}
+
+bool XtensaObjectWriter::needsRelocateWithSymbol(const MCSymbol &Sym,
+                                                 unsigned Type) const {
+  return false;
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaFixupKinds.h
@@ -0,0 +1,32 @@
+//===-- XtensaMCFixups.h - Xtensa-specific fixup entries --------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSAMCFIXUPS_H
+#define LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSAMCFIXUPS_H
+
+#include "llvm/MC/MCFixup.h"
+
+namespace llvm {
+namespace Xtensa {
+enum FixupKind {
+  fixup_xtensa_branch_6 = FirstTargetFixupKind,
+  fixup_xtensa_branch_8,
+  fixup_xtensa_branch_12,
+  fixup_xtensa_jump_18,
+  fixup_xtensa_call_18,
+  fixup_xtensa_l32r_16,
+  fixup_xtensa_invalid,
+  LastTargetFixupKind,
+  NumTargetFixupKinds = LastTargetFixupKind - FirstTargetFixupKind
+};
+} // end namespace Xtensa
+} // end namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSAMCFIXUPS_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaInstPrinter.cpp
@@ -0,0 +1,423 @@
+//===- XtensaInstPrinter.cpp - Convert Xtensa MCInst to asm syntax --------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This class prints an Xtensa MCInst to a .s file.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaInstPrinter.h"
+#include "llvm/CodeGen/MachineOperand.h"
+#include "llvm/MC/MCExpr.h"
+#include "llvm/MC/MCInstrInfo.h"
+#include "llvm/MC/MCSymbol.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "asm-printer"
+
+#include "XtensaGenAsmWriter.inc"
+
+void XtensaInstPrinter::printAddress(unsigned Base, int64_t Disp,
+                                     raw_ostream &O) {
+  O << Disp;
+  if (Base) {
+    O << '(';
+    O << getRegisterName(Base) << ')';
+  }
+}
+
+static void printExpr(const MCExpr *Expr, raw_ostream &OS) {
+  int Offset = 0;
+  const MCSymbolRefExpr *SRE;
+
+  if (!(SRE = dyn_cast<MCSymbolRefExpr>(Expr)))
+    assert(false && "Unexpected MCExpr type.");
+
+  MCSymbolRefExpr::VariantKind Kind = SRE->getKind();
+
+  switch (Kind) {
+  case MCSymbolRefExpr::VK_None:
+    break;
+  // TODO
+  default:
+    llvm_unreachable("Invalid kind!");
+  }
+
+  OS << SRE->getSymbol();
+
+  if (Offset) {
+    if (Offset > 0)
+      OS << '+';
+    OS << Offset;
+  }
+
+  if (Kind != MCSymbolRefExpr::VK_None)
+    OS << ')';
+}
+
+void XtensaInstPrinter::printOperand(const MCOperand &MC, raw_ostream &O) {
+  if (MC.isReg())
+    O << getRegisterName(MC.getReg());
+  else if (MC.isImm())
+    O << MC.getImm();
+  else if (MC.isExpr())
+    printExpr(MC.getExpr(), O);
+  else
+    llvm_unreachable("Invalid operand");
+}
+
+void XtensaInstPrinter::printInst(const MCInst *MI, uint64_t Address,
+                                  StringRef Annot, const MCSubtargetInfo &STI,
+                                  raw_ostream &O) {
+  printInstruction(MI, Address, O);
+  printAnnotation(O, Annot);
+}
+
+void XtensaInstPrinter::printRegName(raw_ostream &O, unsigned RegNo) const {
+  O << getRegisterName(RegNo);
+}
+
+void XtensaInstPrinter::printOperand(const MCInst *MI, int OpNum,
+                                     raw_ostream &O) {
+  printOperand(MI->getOperand(OpNum), O);
+}
+
+void XtensaInstPrinter::printMemOperand(const MCInst *MI, int OpNum,
+                                        raw_ostream &OS) {
+  OS << getRegisterName(MI->getOperand(OpNum).getReg());
+  OS << ", ";
+  printOperand(MI, OpNum + 1, OS);
+}
+
+void XtensaInstPrinter::printBranchTarget(const MCInst *MI, int OpNum,
+                                          raw_ostream &OS) {
+  const MCOperand &MC = MI->getOperand(OpNum);
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Val = MC.getImm() + 4;
+    OS << ". ";
+    if (Val > 0)
+      OS << '+';
+    OS << Val;
+  } else if (MC.isExpr())
+    MC.getExpr()->print(OS, &MAI, true);
+  else
+    llvm_unreachable("Invalid operand");
+}
+
+void XtensaInstPrinter::printJumpTarget(const MCInst *MI, int OpNum,
+                                        raw_ostream &OS) {
+  const MCOperand &MC = MI->getOperand(OpNum);
+  if (MC.isImm()) {
+    int64_t Val = MC.getImm() + 4;
+    OS << ". ";
+    if (Val > 0)
+      OS << '+';
+    OS << Val;
+  } else if (MC.isExpr())
+    MC.getExpr()->print(OS, &MAI, true);
+  else
+    llvm_unreachable("Invalid operand");
+  ;
+}
+
+void XtensaInstPrinter::printCallOperand(const MCInst *MI, int OpNum,
+                                         raw_ostream &OS) {
+  const MCOperand &MC = MI->getOperand(OpNum);
+  if (MC.isImm()) {
+    int64_t Val = MC.getImm() + 4;
+    OS << ". ";
+    if (Val > 0)
+      OS << '+';
+    OS << Val;
+  } else if (MC.isExpr())
+    MC.getExpr()->print(OS, &MAI, true);
+  else
+    llvm_unreachable("Invalid operand");
+}
+
+void XtensaInstPrinter::printL32RTarget(const MCInst *MI, int OpNum,
+                                        raw_ostream &O) {
+  const MCOperand &MC = MI->getOperand(OpNum);
+  if (MC.isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    int64_t InstrOff = Value & 0x3;
+    Value -= InstrOff;
+    assert((Value >= -262144 && Value <= -4) &&
+           "Invalid argument, value must be in ranges [-262144,-4]");
+    Value += ((InstrOff + 0x3) & 0x4) - InstrOff;
+    O << ". ";
+    O << Value;
+  } else if (MC.isExpr())
+    MC.getExpr()->print(O, &MAI, true);
+  else
+    llvm_unreachable("Invalid operand");
+}
+
+void XtensaInstPrinter::printImm8_AsmOperand(const MCInst *MI, int OpNum,
+                                             raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= -128 && Value <= 127) &&
+           "Invalid argument, value must be in ranges [-128,127]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printImm8_sh8_AsmOperand(const MCInst *MI, int OpNum,
+                                                 raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= -32768 && Value <= 32512 && ((Value & 0xFF) == 0)) &&
+           "Invalid argument, value must be multiples of 256 in range "
+           "[-32768,32512]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printImm12_AsmOperand(const MCInst *MI, int OpNum,
+                                              raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= -2048 && Value <= 2047) &&
+           "Invalid argument, value must be in ranges [-2048,2047]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printImm12m_AsmOperand(const MCInst *MI, int OpNum,
+                                               raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= -2048 && Value <= 2047) &&
+           "Invalid argument, value must be in ranges [-2048,2047]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printUimm4_AsmOperand(const MCInst *MI, int OpNum,
+                                              raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= 0 && Value <= 15) && "Invalid argument");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printUimm5_AsmOperand(const MCInst *MI, int OpNum,
+                                              raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= 0 && Value <= 31) && "Invalid argument");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printShimm1_31_AsmOperand(const MCInst *MI, int OpNum,
+                                                  raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= 1 && Value <= 31) &&
+           "Invalid argument, value must be in range [1,31]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printImm1_16_AsmOperand(const MCInst *MI, int OpNum,
+                                                raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= 1 && Value <= 16) &&
+           "Invalid argument, value must be in range [1,16]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printImm1n_15_AsmOperand(const MCInst *MI, int OpNum,
+                                                 raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= -1 && (Value != 0) && Value <= 15) &&
+           "Invalid argument, value must be in ranges <-1,-1> or <1,15>");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printImm32n_95_AsmOperand(const MCInst *MI, int OpNum,
+                                                  raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= -32 && Value <= 95) &&
+           "Invalid argument, value must be in ranges <-32,95>");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printImm8n_7_AsmOperand(const MCInst *MI, int OpNum,
+                                                raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= -8 && Value <= 7) &&
+           "Invalid argument, value must be in ranges <-8,7>");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printImm64n_4n_AsmOperand(const MCInst *MI, int OpNum,
+                                                  raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= -64 && Value <= -4) & ((Value & 0x3) == 0) &&
+           "Invalid argument, value must be in ranges <-64,-4>");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printOffset8m8_AsmOperand(const MCInst *MI, int OpNum,
+                                                  raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= 0 && Value <= 255) &&
+           "Invalid argument, value must be in range [0,255]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printOffset8m16_AsmOperand(const MCInst *MI, int OpNum,
+                                                   raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= 0 && Value <= 510 && ((Value & 0x1) == 0)) &&
+           "Invalid argument, value must be multiples of two in range [0,510]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printOffset8m32_AsmOperand(const MCInst *MI, int OpNum,
+                                                   raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert(
+        (Value >= 0 && Value <= 1020 && ((Value & 0x3) == 0)) &&
+        "Invalid argument, value must be multiples of four in range [0,1020]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printOffset4m32_AsmOperand(const MCInst *MI, int OpNum,
+                                                   raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= 0 && Value <= 60 && ((Value & 0x3) == 0)) &&
+           "Invalid argument, value must be multiples of four in range [0,60]");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printEntry_Imm12_AsmOperand(const MCInst *MI, int OpNum,
+                                                    raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= 0 && Value <= 32760) &&
+           "Invalid argument, value must be multiples of eight in range "
+           "<0,32760>");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printB4const_AsmOperand(const MCInst *MI, int OpNum,
+                                                raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+
+    switch (Value) {
+    case -1:
+    case 1:
+    case 2:
+    case 3:
+    case 4:
+    case 5:
+    case 6:
+    case 7:
+    case 8:
+    case 10:
+    case 12:
+    case 16:
+    case 32:
+    case 64:
+    case 128:
+    case 256:
+      break;
+    default:
+      assert((0) && "Invalid B4const argument");
+    }
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printB4constu_AsmOperand(const MCInst *MI, int OpNum,
+                                                 raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+
+    switch (Value) {
+    case 32768:
+    case 65536:
+    case 2:
+    case 3:
+    case 4:
+    case 5:
+    case 6:
+    case 7:
+    case 8:
+    case 10:
+    case 12:
+    case 16:
+    case 32:
+    case 64:
+    case 128:
+    case 256:
+      break;
+    default:
+      assert((0) && "Invalid B4constu argument");
+    }
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
+
+void XtensaInstPrinter::printSeimm7_22_AsmOperand(const MCInst *MI, int OpNum,
+                                                  raw_ostream &O) {
+  if (MI->getOperand(OpNum).isImm()) {
+    int64_t Value = MI->getOperand(OpNum).getImm();
+    assert((Value >= 7 && Value <= 22) &&
+           "Invalid argument, value must be in range <7,22>");
+    O << Value;
+  } else
+    printOperand(MI, OpNum, O);
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaInstPrinter.h
@@ -0,0 +1,77 @@
+//===- XtensaInstPrinter.h - Convert Xtensa MCInst to asm syntax -*- C++ -*-==//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This class prints an Xtensa MCInst to a .s file.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSAINSTPRINTER_H
+#define LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSAINSTPRINTER_H
+
+#include "llvm/MC/MCInstPrinter.h"
+#include "llvm/Support/Compiler.h"
+
+namespace llvm {
+class MCOperand;
+
+class XtensaInstPrinter : public MCInstPrinter {
+public:
+  XtensaInstPrinter(const MCAsmInfo &MAI, const MCInstrInfo &MII,
+                    const MCRegisterInfo &MRI)
+      : MCInstPrinter(MAI, MII, MRI) {}
+
+  // Automatically generated by tblgen.
+  void printInstruction(const MCInst *MI, uint64_t Address, raw_ostream &O);
+  static const char *getRegisterName(unsigned RegNo);
+
+  // Print the given operand.
+  static void printOperand(const MCOperand &MO, raw_ostream &O);
+
+  // Print an address
+  static void printAddress(unsigned Base, int64_t Disp, raw_ostream &O); 
+
+  // Override MCInstPrinter.
+  void printRegName(raw_ostream &O, unsigned RegNo) const override;
+  void printInst(const MCInst *MI, uint64_t Address, StringRef Annot,
+                 const MCSubtargetInfo &STI, raw_ostream &O) override;
+
+private:
+  // Print various types of operand.
+  void printOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printMemOperand(const MCInst *MI, int OpNUm, raw_ostream &O);
+  void printBranchTarget(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printJumpTarget(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printCallOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printL32RTarget(const MCInst *MI, int OpNum, raw_ostream &O);
+
+  void printImm8_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printImm8_sh8_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printImm12_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printImm12m_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printUimm4_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printUimm5_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printShimm1_31_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printImm1_16_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printImm1n_15_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printImm32n_95_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printImm8n_7_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printImm64n_4n_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printOffset8m8_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printOffset8m16_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printOffset8m32_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printOffset4m32_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printEntry_Imm12_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printB4const_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printB4constu_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+  void printSeimm7_22_AsmOperand(const MCInst *MI, int OpNum, raw_ostream &O);
+};
+} // end namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSAINSTPRINTER_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaMCAsmInfo.cpp
@@ -0,0 +1,32 @@
+//===-- XtensaMCAsmInfo.cpp - Xtensa Asm Properties -----------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains the declarations of the XtensaMCAsmInfo properties.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaMCAsmInfo.h"
+#include "llvm/ADT/Triple.h"
+
+using namespace llvm;
+
+XtensaMCAsmInfo::XtensaMCAsmInfo(const Triple &TT) {
+  CodePointerSize = 4;
+  CalleeSaveStackSlotSize = 4;
+  PrivateGlobalPrefix = ".L";
+  CommentString = "#";
+  ZeroDirective = "\t.space\t";
+  Data64bitsDirective = "\t.quad\t";
+  GlobalDirective = "\t.global\t";
+  UsesELFSectionDirectiveForBSS = true;
+  SupportsDebugInformation = true;
+  ExceptionsType = ExceptionHandling::DwarfCFI;
+  AlignmentIsInBytes = false;
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaMCAsmInfo.h
@@ -0,0 +1,30 @@
+//===-- XtensaMCAsmInfo.h - Xtensa Asm Info --------------------*- C++ -*--===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains the declaration of the XtensaMCAsmInfo class.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSATARGETASMINFO_H
+#define LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSATARGETASMINFO_H
+
+#include "llvm/MC/MCAsmInfoELF.h"
+
+namespace llvm {
+class Triple;
+
+class XtensaMCAsmInfo : public MCAsmInfoELF {
+public:
+  explicit XtensaMCAsmInfo(const Triple &TT);
+};
+
+} // namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSATARGETASMINFO_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaMCCodeEmitter.cpp
@@ -0,0 +1,572 @@
+//===-- XtensaMCCodeEmitter.cpp - Convert Xtensa Code to Machine Code -----===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements the XtensaMCCodeEmitter class.
+//
+//===----------------------------------------------------------------------===//
+
+#define DEBUG_TYPE "mccodeemitter"
+#include "MCTargetDesc/XtensaFixupKinds.h"
+#include "MCTargetDesc/XtensaMCExpr.h"
+#include "MCTargetDesc/XtensaMCTargetDesc.h"
+#include "llvm/MC/MCCodeEmitter.h"
+#include "llvm/MC/MCContext.h"
+#include "llvm/MC/MCExpr.h"
+#include "llvm/MC/MCInst.h"
+#include "llvm/MC/MCInstrInfo.h"
+#include "llvm/MC/MCRegisterInfo.h"
+
+#define GET_INSTRMAP_INFO
+#include "XtensaGenInstrInfo.inc"
+#undef GET_INSTRMAP_INFO
+
+using namespace llvm;
+
+namespace {
+class XtensaMCCodeEmitter : public MCCodeEmitter {
+  const MCInstrInfo &MCII;
+  MCContext &Ctx;
+  bool IsLittleEndian;
+
+public:
+  XtensaMCCodeEmitter(const MCInstrInfo &mcii, MCContext &ctx, bool isLE)
+      : MCII(mcii), Ctx(ctx), IsLittleEndian(isLE) {}
+
+  ~XtensaMCCodeEmitter() {}
+
+  // OVerride MCCodeEmitter.
+  void encodeInstruction(const MCInst &MI, raw_ostream &OS,
+                         SmallVectorImpl<MCFixup> &Fixups,
+                         const MCSubtargetInfo &STI) const override;
+
+private:
+  // Automatically generated by TableGen.
+  uint64_t getBinaryCodeForInstr(const MCInst &MI,
+                                 SmallVectorImpl<MCFixup> &Fixups,
+                                 const MCSubtargetInfo &STI) const;
+
+  // Called by the TableGen code to get the binary encoding of operand
+  // MO in MI.  Fixups is the list of fixups against MI.
+  uint32_t getMachineOpValue(const MCInst &MI, const MCOperand &MO,
+                             SmallVectorImpl<MCFixup> &Fixups,
+                             const MCSubtargetInfo &STI) const;
+
+  uint32_t getJumpTargetEncoding(const MCInst &MI, unsigned int OpNum,
+                                 SmallVectorImpl<MCFixup> &Fixups,
+                                 const MCSubtargetInfo &STI) const;
+
+  uint32_t getBranchTargetEncoding(const MCInst &MI, unsigned int OpNum,
+                                   SmallVectorImpl<MCFixup> &Fixups,
+                                   const MCSubtargetInfo &STI) const;
+
+  uint32_t getCallEncoding(const MCInst &MI, unsigned int OpNum,
+                           SmallVectorImpl<MCFixup> &Fixups,
+                           const MCSubtargetInfo &STI) const;
+
+  uint32_t getL32RTargetEncoding(const MCInst &MI, unsigned OpNum,
+                                 SmallVectorImpl<MCFixup> &Fixups,
+                                 const MCSubtargetInfo &STI) const;
+
+  uint32_t getMemRegEncoding(const MCInst &MI, unsigned OpNo,
+                             SmallVectorImpl<MCFixup> &Fixups,
+                             const MCSubtargetInfo &STI) const;
+
+  uint32_t getImm8OpValue(const MCInst &MI, unsigned OpNo,
+                          SmallVectorImpl<MCFixup> &Fixups,
+                          const MCSubtargetInfo &STI) const;
+
+  uint32_t getImm8_sh8OpValue(const MCInst &MI, unsigned OpNo,
+                              SmallVectorImpl<MCFixup> &Fixups,
+                              const MCSubtargetInfo &STI) const;
+
+  uint32_t getImm12OpValue(const MCInst &MI, unsigned OpNo,
+                           SmallVectorImpl<MCFixup> &Fixups,
+                           const MCSubtargetInfo &STI) const;
+
+  uint32_t getUimm4OpValue(const MCInst &MI, unsigned OpNo,
+                           SmallVectorImpl<MCFixup> &Fixups,
+                           const MCSubtargetInfo &STI) const;
+
+  uint32_t getUimm5OpValue(const MCInst &MI, unsigned OpNo,
+                           SmallVectorImpl<MCFixup> &Fixups,
+                           const MCSubtargetInfo &STI) const;
+
+  uint32_t getImm1_16OpValue(const MCInst &MI, unsigned OpNo,
+                             SmallVectorImpl<MCFixup> &Fixups,
+                             const MCSubtargetInfo &STI) const;
+
+  uint32_t getImm1n_15OpValue(const MCInst &MI, unsigned OpNo,
+                              SmallVectorImpl<MCFixup> &Fixups,
+                              const MCSubtargetInfo &STI) const;
+
+  uint32_t getImm32n_95OpValue(const MCInst &MI, unsigned OpNo,
+                               SmallVectorImpl<MCFixup> &Fixups,
+                               const MCSubtargetInfo &STI) const;
+
+  uint32_t getImm8n_7OpValue(const MCInst &MI, unsigned OpNo,
+                             SmallVectorImpl<MCFixup> &Fixups,
+                             const MCSubtargetInfo &STI) const;
+
+  uint32_t getImm64n_4nOpValue(const MCInst &MI, unsigned OpNo,
+                               SmallVectorImpl<MCFixup> &Fixups,
+                               const MCSubtargetInfo &STI) const;
+
+  uint32_t getEntry_Imm12OpValue(const MCInst &MI, unsigned OpNo,
+                                 SmallVectorImpl<MCFixup> &Fixups,
+                                 const MCSubtargetInfo &STI) const;
+
+  uint32_t getShimm1_31OpValue(const MCInst &MI, unsigned OpNo,
+                               SmallVectorImpl<MCFixup> &Fixups,
+                               const MCSubtargetInfo &STI) const;
+
+  uint32_t getB4constOpValue(const MCInst &MI, unsigned OpNo,
+                             SmallVectorImpl<MCFixup> &Fixups,
+                             const MCSubtargetInfo &STI) const;
+
+  uint32_t getB4constuOpValue(const MCInst &MI, unsigned OpNo,
+                              SmallVectorImpl<MCFixup> &Fixups,
+                              const MCSubtargetInfo &STI) const;
+
+  uint32_t getSeimm7_22OpValue(const MCInst &MI, unsigned OpNo,
+                               SmallVectorImpl<MCFixup> &Fixups,
+                               const MCSubtargetInfo &STI) const;
+};
+} // namespace
+
+MCCodeEmitter *llvm::createXtensaMCCodeEmitter(const MCInstrInfo &MCII,
+                                               const MCRegisterInfo &MRI,
+                                               MCContext &Ctx) {
+  return new XtensaMCCodeEmitter(MCII, Ctx, true);
+}
+
+void XtensaMCCodeEmitter::encodeInstruction(const MCInst &MI, raw_ostream &OS,
+                                            SmallVectorImpl<MCFixup> &Fixups,
+                                            const MCSubtargetInfo &STI) const {
+  uint64_t Bits = getBinaryCodeForInstr(MI, Fixups, STI);
+  unsigned Size = MCII.get(MI.getOpcode()).getSize();
+
+  if (IsLittleEndian) {
+    // Little-endian insertion of Size bytes.
+    unsigned ShiftValue = 0;
+    for (unsigned I = 0; I != Size; ++I) {
+      OS << uint8_t(Bits >> ShiftValue);
+      ShiftValue += 8;
+    }
+  } else {
+    // TODO Big-endian insertion of Size bytes.
+    llvm_unreachable("Big-endian mode currently is not supported!");
+  }
+}
+
+uint32_t
+XtensaMCCodeEmitter::getMachineOpValue(const MCInst &MI, const MCOperand &MO,
+                                       SmallVectorImpl<MCFixup> &Fixups,
+                                       const MCSubtargetInfo &STI) const {
+  if (MO.isReg())
+    return Ctx.getRegisterInfo()->getEncodingValue(MO.getReg());
+  if (MO.isImm()) {
+    uint32_t Res = static_cast<uint32_t>(MO.getImm());
+    return Res;
+  }
+
+  llvm_unreachable("Unhandled expression!");
+  return 0;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getJumpTargetEncoding(const MCInst &MI, unsigned int OpNum,
+                                           SmallVectorImpl<MCFixup> &Fixups,
+                                           const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNum);
+
+  if (MO.isImm())
+    return MO.getImm();
+
+  const MCExpr *Expr = MO.getExpr();
+  Fixups.push_back(MCFixup::create(
+      0, Expr, MCFixupKind(Xtensa::fixup_xtensa_jump_18), MI.getLoc()));
+  return 0;
+}
+
+uint32_t XtensaMCCodeEmitter::getBranchTargetEncoding(
+    const MCInst &MI, unsigned int OpNum, SmallVectorImpl<MCFixup> &Fixups,
+    const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNum);
+  if (MO.isImm())
+    return static_cast<uint32_t>(MO.getImm());
+
+  const MCExpr *Expr = MO.getExpr();
+  switch (MI.getOpcode()) {
+  case Xtensa::BEQZ:
+  case Xtensa::BGEZ:
+  case Xtensa::BLTZ:
+  case Xtensa::BNEZ:
+    Fixups.push_back(MCFixup::create(
+        0, Expr, MCFixupKind(Xtensa::fixup_xtensa_branch_12), MI.getLoc()));
+    return 0;
+  default:
+    Fixups.push_back(MCFixup::create(
+        0, Expr, MCFixupKind(Xtensa::fixup_xtensa_branch_8), MI.getLoc()));
+    return 0;
+  }
+}
+
+uint32_t
+XtensaMCCodeEmitter::getCallEncoding(const MCInst &MI, unsigned int OpNum,
+                                     SmallVectorImpl<MCFixup> &Fixups,
+                                     const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNum);
+  if (MO.isImm()) {
+    int32_t Res = MO.getImm();
+    if (Res & 0x3) {
+      llvm_unreachable("Unexpected operand value!");
+    }
+    Res >>= 2;
+    return Res;
+  }
+
+  assert((MO.isExpr()) && "Unexpected operand value!");
+  const MCExpr *Expr = MO.getExpr();
+  Fixups.push_back(MCFixup::create(
+      0, Expr, MCFixupKind(Xtensa::fixup_xtensa_call_18), MI.getLoc()));
+  return 0;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getL32RTargetEncoding(const MCInst &MI, unsigned OpNum,
+                                           SmallVectorImpl<MCFixup> &Fixups,
+                                           const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNum);
+  if (MO.isImm()) {
+    int32_t Res = MO.getImm();
+    // We don't check first 2 bits, because in these bits we could store first 2
+    // bits of instruction address
+    Res >>= 2;
+    return Res;
+  }
+
+  assert((MO.isExpr()) && "Unexpected operand value!");
+
+  Fixups.push_back(MCFixup::create(
+      0, MO.getExpr(), MCFixupKind(Xtensa::fixup_xtensa_l32r_16), MI.getLoc()));
+  return 0;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getMemRegEncoding(const MCInst &MI, unsigned OpNo,
+                                       SmallVectorImpl<MCFixup> &Fixups,
+                                       const MCSubtargetInfo &STI) const {
+  assert(MI.getOperand(OpNo + 1).isImm());
+
+  uint32_t Res = static_cast<uint32_t>(MI.getOperand(OpNo + 1).getImm());
+
+  switch (MI.getOpcode()) {
+  case Xtensa::S16I:
+  case Xtensa::L16SI:
+  case Xtensa::L16UI:
+    if (Res & 0x1) {
+      llvm_unreachable("Unexpected operand value!");
+    }
+    Res >>= 1;
+    break;
+  case Xtensa::S32I:
+  case Xtensa::L32I:
+  case Xtensa::S32I_N:
+  case Xtensa::L32I_N:
+  case Xtensa::S32F:
+  case Xtensa::L32F:
+  case Xtensa::S32C1I:
+    if (Res & 0x3) {
+      llvm_unreachable("Unexpected operand value!");
+    }
+    Res >>= 2;
+    break;
+  }
+
+  switch (MI.getOpcode()) {
+  case Xtensa::S32I_N:
+  case Xtensa::L32I_N:
+    assert((isUInt<4>(Res)) && "Unexpected operand value!");
+    break;
+  default:
+    assert((isUInt<8>(Res)) && "Unexpected operand value!");
+    break;
+  }
+
+  uint32_t OffBits = Res << 4;
+  uint32_t RegBits = getMachineOpValue(MI, MI.getOperand(OpNo), Fixups, STI);
+
+  return ((OffBits & 0xFF0) | RegBits);
+}
+
+uint32_t XtensaMCCodeEmitter::getImm8OpValue(const MCInst &MI, unsigned OpNo,
+                                             SmallVectorImpl<MCFixup> &Fixups,
+                                             const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  int32_t Res = MO.getImm();
+
+  assert(((Res >= -128) && (Res <= 127)) && "Unexpected operand value!");
+
+  return (Res & 0xff);
+}
+
+uint32_t
+XtensaMCCodeEmitter::getImm8_sh8OpValue(const MCInst &MI, unsigned OpNo,
+                                        SmallVectorImpl<MCFixup> &Fixups,
+                                        const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  int32_t Res = MO.getImm();
+
+  assert(((Res >= -32768) && (Res <= 32512) && ((Res & 0xff) == 0)) &&
+         "Unexpected operand value!");
+
+  return (Res & 0xffff);
+}
+
+uint32_t
+XtensaMCCodeEmitter::getImm12OpValue(const MCInst &MI, unsigned OpNo,
+                                     SmallVectorImpl<MCFixup> &Fixups,
+                                     const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  int32_t Res = MO.getImm();
+
+  assert(((Res >= -2048) && (Res <= 2047)) && "Unexpected operand value!");
+
+  return (Res & 0xfff);
+}
+
+uint32_t
+XtensaMCCodeEmitter::getUimm4OpValue(const MCInst &MI, unsigned OpNo,
+                                     SmallVectorImpl<MCFixup> &Fixups,
+                                     const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  uint32_t Res = static_cast<uint32_t>(MO.getImm());
+
+  assert((Res <= 15) && "Unexpected operand value!");
+
+  return Res & 0xf;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getUimm5OpValue(const MCInst &MI, unsigned OpNo,
+                                     SmallVectorImpl<MCFixup> &Fixups,
+                                     const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  uint32_t Res = static_cast<uint32_t>(MO.getImm());
+
+  assert((Res <= 31) && "Unexpected operand value!");
+
+  return (Res & 0x1f);
+}
+
+uint32_t
+XtensaMCCodeEmitter::getShimm1_31OpValue(const MCInst &MI, unsigned OpNo,
+                                         SmallVectorImpl<MCFixup> &Fixups,
+                                         const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  uint32_t Res = static_cast<uint32_t>(MO.getImm());
+
+  assert(((Res >= 1) && (Res <= 31)) && "Unexpected operand value!");
+
+  return ((32 - Res) & 0x1f);
+}
+
+uint32_t
+XtensaMCCodeEmitter::getImm1_16OpValue(const MCInst &MI, unsigned OpNo,
+                                       SmallVectorImpl<MCFixup> &Fixups,
+                                       const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  uint32_t Res = static_cast<uint32_t>(MO.getImm());
+
+  assert(((Res >= 1) && (Res <= 16)) && "Unexpected operand value!");
+
+  return (Res - 1);
+}
+
+uint32_t
+XtensaMCCodeEmitter::getImm1n_15OpValue(const MCInst &MI, unsigned OpNo,
+                                        SmallVectorImpl<MCFixup> &Fixups,
+                                        const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  int32_t Res = static_cast<int32_t>(MO.getImm());
+
+  assert(((Res >= -1) && (Res <= 15) && (Res != 0)) &&
+         "Unexpected operand value!");
+
+  if (Res < 0)
+    Res = 0;
+
+  return Res;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getImm32n_95OpValue(const MCInst &MI, unsigned OpNo,
+                                         SmallVectorImpl<MCFixup> &Fixups,
+                                         const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  int32_t Res = static_cast<int32_t>(MO.getImm());
+
+  assert(((Res >= -32) && (Res <= 95)) && "Unexpected operand value!");
+
+  return Res;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getImm8n_7OpValue(const MCInst &MI, unsigned OpNo,
+                                       SmallVectorImpl<MCFixup> &Fixups,
+                                       const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  int32_t Res = static_cast<int32_t>(MO.getImm());
+
+  assert(((Res >= -8) && (Res <= 7)) && "Unexpected operand value!");
+
+  if (Res < 0)
+    return Res + 16;
+
+  return Res;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getImm64n_4nOpValue(const MCInst &MI, unsigned OpNo,
+                                         SmallVectorImpl<MCFixup> &Fixups,
+                                         const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  int32_t Res = static_cast<int32_t>(MO.getImm());
+
+  assert(((Res >= -64) && (Res <= -4) && ((Res & 0x3) == 0)) &&
+         "Unexpected operand value!");
+
+  return Res & 0x3f;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getEntry_Imm12OpValue(const MCInst &MI, unsigned OpNo,
+                                           SmallVectorImpl<MCFixup> &Fixups,
+                                           const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  uint32_t res = static_cast<uint32_t>(MO.getImm());
+
+  assert(((res & 0x7) == 0) && "Unexpected operand value!");
+
+  return res;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getB4constOpValue(const MCInst &MI, unsigned OpNo,
+                                       SmallVectorImpl<MCFixup> &Fixups,
+                                       const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  uint32_t Res = static_cast<uint32_t>(MO.getImm());
+
+  switch (Res) {
+  case 0xffffffff:
+    Res = 0;
+    break;
+  case 1:
+  case 2:
+  case 3:
+  case 4:
+  case 5:
+  case 6:
+  case 7:
+  case 8:
+    break;
+  case 10:
+    Res = 9;
+    break;
+  case 12:
+    Res = 10;
+    break;
+  case 16:
+    Res = 11;
+    break;
+  case 32:
+    Res = 12;
+    break;
+  case 64:
+    Res = 13;
+    break;
+  case 128:
+    Res = 14;
+    break;
+  case 256:
+    Res = 15;
+    break;
+  default:
+    llvm_unreachable("Unexpected operand value!");
+  }
+
+  return Res;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getB4constuOpValue(const MCInst &MI, unsigned OpNo,
+                                        SmallVectorImpl<MCFixup> &Fixups,
+                                        const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  uint32_t Res = static_cast<uint32_t>(MO.getImm());
+
+  switch (Res) {
+  case 32768:
+    Res = 0;
+    break;
+  case 65536:
+    Res = 1;
+    break;
+  case 2:
+  case 3:
+  case 4:
+  case 5:
+  case 6:
+  case 7:
+  case 8:
+    break;
+  case 10:
+    Res = 9;
+    break;
+  case 12:
+    Res = 10;
+    break;
+  case 16:
+    Res = 11;
+    break;
+  case 32:
+    Res = 12;
+    break;
+  case 64:
+    Res = 13;
+    break;
+  case 128:
+    Res = 14;
+    break;
+  case 256:
+    Res = 15;
+    break;
+  default:
+    llvm_unreachable("Unexpected operand value!");
+  }
+
+  return Res;
+}
+
+uint32_t
+XtensaMCCodeEmitter::getSeimm7_22OpValue(const MCInst &MI, unsigned OpNo,
+                                         SmallVectorImpl<MCFixup> &Fixups,
+                                         const MCSubtargetInfo &STI) const {
+  const MCOperand &MO = MI.getOperand(OpNo);
+  uint32_t res = static_cast<uint32_t>(MO.getImm());
+
+  res -= 7;
+  assert(((res & 0xf) == res) && "Unexpected operand value!");
+
+  return res;
+}
+
+#include "XtensaGenMCCodeEmitter.inc"
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaMCExpr.cpp
@@ -0,0 +1,63 @@
+//===-- XtensaMCExpr.cpp - Xtensa specific MC expression classes ----------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains the implementation of the assembly expression modifiers
+// accepted by the Xtensa architecture
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaMCExpr.h"
+#include "llvm/MC/MCAssembler.h"
+#include "llvm/MC/MCContext.h"
+#include "llvm/MC/MCStreamer.h"
+#include "llvm/MC/MCSymbolELF.h"
+#include "llvm/MC/MCValue.h"
+#include "llvm/Object/ELF.h"
+#include "llvm/Support/ErrorHandling.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "xtensamcexpr"
+
+const XtensaMCExpr *XtensaMCExpr::create(const MCExpr *Expr, VariantKind Kind,
+                                         MCContext &Ctx) {
+  return new (Ctx) XtensaMCExpr(Expr, Kind);
+}
+
+void XtensaMCExpr::printImpl(raw_ostream &OS, const MCAsmInfo *MAI) const {
+  bool HasVariant = getKind() != VK_Xtensa_None;
+  if (HasVariant)
+    OS << '%' << getVariantKindName(getKind()) << '(';
+  Expr->print(OS, MAI);
+  if (HasVariant)
+    OS << ')';
+}
+
+bool XtensaMCExpr::evaluateAsRelocatableImpl(MCValue &Res,
+                                             const MCAsmLayout *Layout,
+                                             const MCFixup *Fixup) const {
+  return getSubExpr()->evaluateAsRelocatable(Res, Layout, Fixup);
+}
+
+void XtensaMCExpr::visitUsedExpr(MCStreamer &Streamer) const {
+  Streamer.visitUsedExpr(*getSubExpr());
+}
+
+XtensaMCExpr::VariantKind XtensaMCExpr::getVariantKindForName(StringRef name) {
+  return StringSwitch<XtensaMCExpr::VariantKind>(name).Default(
+      VK_Xtensa_Invalid);
+}
+
+StringRef XtensaMCExpr::getVariantKindName(VariantKind Kind) {
+  switch (Kind) {
+  default:
+    llvm_unreachable("Invalid ELF symbol kind");
+  }
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaMCExpr.h
@@ -0,0 +1,58 @@
+//===-- XtensaMCExpr.h - Xtensa specific MC expression classes --*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file describes Xtensa-specific MCExprs
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_Xtensa_MCTARGETDESC_XtensaMCEXPR_H
+#define LLVM_LIB_TARGET_Xtensa_MCTARGETDESC_XtensaMCEXPR_H
+
+#include "llvm/MC/MCExpr.h"
+
+namespace llvm {
+
+class StringRef;
+class XtensaMCExpr : public MCTargetExpr {
+public:
+  enum VariantKind { VK_Xtensa_None, VK_Xtensa_Invalid };
+
+private:
+  const MCExpr *Expr;
+  const VariantKind Kind;
+
+  explicit XtensaMCExpr(const MCExpr *Expr, VariantKind Kind)
+      : Expr(Expr), Kind(Kind) {}
+
+public:
+  static const XtensaMCExpr *create(const MCExpr *Expr, VariantKind Kind,
+                                    MCContext &Ctx);
+
+  VariantKind getKind() const { return Kind; }
+
+  const MCExpr *getSubExpr() const { return Expr; }
+
+  void printImpl(raw_ostream &OS, const MCAsmInfo *MAI) const override;
+  bool evaluateAsRelocatableImpl(MCValue &Res, const MCAsmLayout *Layout,
+                                 const MCFixup *Fixup) const override;
+  void visitUsedExpr(MCStreamer &Streamer) const override;
+  MCFragment *findAssociatedFragment() const override {
+    return getSubExpr()->findAssociatedFragment();
+  }
+
+  void fixELFSymbolsInTLSFixups(MCAssembler &Asm) const override {}
+
+  static VariantKind getVariantKindForName(StringRef name);
+  static StringRef getVariantKindName(VariantKind Kind);
+};
+
+} // end namespace llvm.
+
+#endif
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaMCTargetDesc.cpp
@@ -0,0 +1,115 @@
+//===-- XtensaMCTargetDesc.cpp - Xtebsa target descriptions ---------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+#include "XtensaMCTargetDesc.h"
+#include "XtensaInstPrinter.h"
+#include "XtensaMCAsmInfo.h"
+#include "llvm/MC/MCDwarf.h"
+#include "XtensaTargetStreamer.h"
+#include "llvm/ADT/STLExtras.h"
+#include "llvm/MC/MCAsmInfo.h"
+#include "llvm/MC/MCInstrInfo.h"
+#include "llvm/MC/MCRegisterInfo.h"
+#include "llvm/MC/MCStreamer.h"
+#include "llvm/MC/MCSubtargetInfo.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/TargetRegistry.h"
+
+#define GET_INSTRINFO_MC_DESC
+#include "XtensaGenInstrInfo.inc"
+
+#define GET_REGINFO_MC_DESC
+#include "XtensaGenRegisterInfo.inc"
+
+#define GET_SUBTARGETINFO_MC_DESC
+#include "XtensaGenSubtargetInfo.inc"
+
+using namespace llvm;
+
+static MCAsmInfo *createXtensaMCAsmInfo(const MCRegisterInfo &MRI,
+                                        const Triple &TT,
+                                        const MCTargetOptions &Options) {
+  MCAsmInfo *MAI = new XtensaMCAsmInfo(TT);
+  MCCFIInstruction Inst = MCCFIInstruction::createDefCfa(
+      nullptr, MRI.getDwarfRegNum(Xtensa::SP, true), 0);
+  MAI->addInitialFrameState(Inst);
+  return MAI;
+}
+
+static MCInstrInfo *createXtensaMCInstrInfo() {
+  MCInstrInfo *X = new MCInstrInfo();
+  InitXtensaMCInstrInfo(X);
+  return X;
+}
+
+static MCInstPrinter *createXtensaMCInstPrinter(const Triple &TT,
+                                                unsigned SyntaxVariant,
+                                                const MCAsmInfo &MAI,
+                                                const MCInstrInfo &MII,
+                                                const MCRegisterInfo &MRI) {
+  return new XtensaInstPrinter(MAI, MII, MRI);
+}
+
+static MCRegisterInfo *createXtensaMCRegisterInfo(const Triple &TT) {
+  MCRegisterInfo *X = new MCRegisterInfo();
+  InitXtensaMCRegisterInfo(X, Xtensa::SP);
+  return X;
+}
+
+static MCSubtargetInfo *
+createXtensaMCSubtargetInfo(const Triple &TT, StringRef CPU, StringRef FS) {
+  return createXtensaMCSubtargetInfoImpl(TT, CPU, FS);
+}
+
+static MCTargetStreamer *
+createXtensaAsmTargetStreamer(MCStreamer &S, formatted_raw_ostream &OS,
+                              MCInstPrinter *InstPrint, bool isVerboseAsm) {
+  return new XtensaTargetAsmStreamer(S, OS);
+}
+
+static MCTargetStreamer *
+createXtensaObjectTargetStreamer(MCStreamer &S, const MCSubtargetInfo &STI) {
+  return new XtensaTargetELFStreamer(S);
+}
+
+extern "C" LLVM_EXTERNAL_VISIBILITY void LLVMInitializeXtensaTargetMC() {
+  // Register the MCAsmInfo.
+  TargetRegistry::RegisterMCAsmInfo(TheXtensaTarget, createXtensaMCAsmInfo);
+
+  // Register the MCCodeEmitter.
+  TargetRegistry::RegisterMCCodeEmitter(TheXtensaTarget,
+                                        createXtensaMCCodeEmitter);
+
+  // Register the MCInstrInfo.
+  TargetRegistry::RegisterMCInstrInfo(TheXtensaTarget, createXtensaMCInstrInfo);
+
+  // Register the MCInstPrinter.
+  TargetRegistry::RegisterMCInstPrinter(TheXtensaTarget,
+                                        createXtensaMCInstPrinter);
+
+  // Register the MCRegisterInfo.
+  TargetRegistry::RegisterMCRegInfo(TheXtensaTarget,
+                                    createXtensaMCRegisterInfo);
+
+  // Register the MCSubtargetInfo.
+  TargetRegistry::RegisterMCSubtargetInfo(TheXtensaTarget,
+                                          createXtensaMCSubtargetInfo);
+
+  // Register the MCAsmBackend.
+  TargetRegistry::RegisterMCAsmBackend(TheXtensaTarget,
+                                       createXtensaMCAsmBackend);
+
+  // Register the asm target streamer.
+  TargetRegistry::RegisterAsmTargetStreamer(TheXtensaTarget,
+                                            createXtensaAsmTargetStreamer);
+
+  // Register the ELF target streamer.
+  TargetRegistry::RegisterObjectTargetStreamer(
+      TheXtensaTarget, createXtensaObjectTargetStreamer);
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaMCTargetDesc.h
@@ -0,0 +1,60 @@
+//===-- XtensaMCTargetDesc.h - Xtensa Target Descriptions -------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file provides Xtensa specific target descriptions.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSAMCTARGETDESC_H
+#define LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSAMCTARGETDESC_H
+#include "llvm/Support/DataTypes.h"
+#include "llvm/Support/TargetRegistry.h"
+
+namespace llvm {
+
+class MCAsmBackend;
+class MCCodeEmitter;
+class MCContext;
+class MCInstrInfo;
+class MCObjectTargetWriter;
+class MCObjectWriter;
+class MCRegisterInfo;
+class MCSubtargetInfo;
+class StringRef;
+class Target;
+class raw_ostream;
+
+extern Target TheXtensaTarget;
+
+MCCodeEmitter *createXtensaMCCodeEmitter(const MCInstrInfo &MCII,
+                                         const MCRegisterInfo &MRI,
+                                         MCContext &Ctx);
+
+MCAsmBackend *createXtensaMCAsmBackend(const Target &T,
+                                       const MCSubtargetInfo &STI,
+                                       const MCRegisterInfo &MRI,
+                                       const MCTargetOptions &Options);
+std::unique_ptr<MCObjectTargetWriter>
+createXtensaObjectWriter(uint8_t OSABI, bool IsLittleEndian);
+} // end namespace llvm
+
+// Defines symbolic names for Xtensa registers.
+// This defines a mapping from register name to register number.
+#define GET_REGINFO_ENUM
+#include "XtensaGenRegisterInfo.inc"
+
+// Defines symbolic names for the Xtensa instructions.
+#define GET_INSTRINFO_ENUM
+#include "XtensaGenInstrInfo.inc"
+
+#define GET_SUBTARGETINFO_ENUM
+#include "XtensaGenSubtargetInfo.inc"
+
+#endif /* LLVM_LIB_TARGET_XTENSA_MCTARGETDESC_XTENSAMCTARGETDESC_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaTargetStreamer.cpp
@@ -0,0 +1,97 @@
+//===-- XtensaTargetStreamer.cpp - Xtensa Target Streamer Methods ---------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file provides Xtensa specific target streamer methods.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaTargetStreamer.h"
+#include "XtensaInstPrinter.h"
+#include "llvm/BinaryFormat/ELF.h"
+#include "llvm/MC/MCAssembler.h"
+#include "llvm/MC/MCContext.h"
+#include "llvm/MC/MCObjectFileInfo.h"
+#include "llvm/MC/MCSectionELF.h"
+#include "llvm/Support/FormattedStream.h"
+
+using namespace llvm;
+
+XtensaTargetStreamer::XtensaTargetStreamer(MCStreamer &S)
+    : MCTargetStreamer(S) {}
+
+XtensaTargetAsmStreamer::XtensaTargetAsmStreamer(MCStreamer &S,
+                                                 formatted_raw_ostream &OS)
+    : XtensaTargetStreamer(S), OS(OS) {}
+
+void XtensaTargetAsmStreamer::emitLiteral(std::string str) { OS << str; }
+
+XtensaTargetELFStreamer::XtensaTargetELFStreamer(MCStreamer &S)
+    : XtensaTargetStreamer(S) {}
+
+void XtensaTargetELFStreamer::emitLiteralLabel(MCSymbol *LblSym, SMLoc L) {
+  MCContext &Context = getStreamer().getContext();
+  MCStreamer &OutStreamer = getStreamer();
+  MCSectionELF *CS = (MCSectionELF *)OutStreamer.getCurrentSectionOnly();
+  std::string CSectionName = CS->getSectionName();
+  std::size_t Pos = CSectionName.find(".text");
+  std::string SectionName;
+  if (Pos != std::string::npos) {
+    SectionName = ".literal";
+    SectionName += CSectionName.substr(Pos);
+  } else {
+    SectionName = CSectionName;
+    SectionName += ".literal";
+  }
+
+  MCSection *ConstSection = Context.getELFSection(
+      SectionName, ELF::SHT_PROGBITS, ELF::SHF_EXECINSTR | ELF::SHF_ALLOC);
+  ConstSection->setAlignment(Align(4));
+
+  OutStreamer.PushSection();
+  OutStreamer.SwitchSection(ConstSection);
+  OutStreamer.EmitLabel(LblSym, L);
+  OutStreamer.PopSection();
+}
+
+void XtensaTargetELFStreamer::emitLiteral(MCSymbol *LblSym, const MCExpr *Value,
+                                          SMLoc L) {
+  MCStreamer &OutStreamer = getStreamer();
+
+  OutStreamer.EmitLabel(LblSym, L);
+  OutStreamer.EmitValue(Value, 4, L);
+}
+
+void XtensaTargetELFStreamer::emitLiteral(const MCExpr *Value, SMLoc L) {
+  MCContext &Context = getStreamer().getContext();
+  MCStreamer &OutStreamer = getStreamer();
+  MCSectionELF *CS = (MCSectionELF *)OutStreamer.getCurrentSectionOnly();
+  std::string CSectionName = CS->getSectionName();
+  std::size_t Pos = CSectionName.find(".text");
+  std::string SectionName;
+  if (Pos != std::string::npos) {
+    SectionName = ".literal";
+    SectionName += CSectionName.substr(Pos);
+  } else {
+    SectionName = CSectionName;
+    SectionName += ".literal";
+  }
+
+  MCSection *ConstSection = Context.getELFSection(
+      SectionName, ELF::SHT_PROGBITS, ELF::SHF_EXECINSTR | ELF::SHF_ALLOC);
+
+  OutStreamer.PushSection();
+  OutStreamer.SwitchSection(ConstSection);
+  OutStreamer.EmitValue(Value, 4, L);
+  OutStreamer.PopSection();
+}
+
+MCELFStreamer &XtensaTargetELFStreamer::getStreamer() {
+  return static_cast<MCELFStreamer &>(Streamer);
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/MCTargetDesc/XtensaTargetStreamer.h
@@ -0,0 +1,51 @@
+//===-- XtensaTargetStreamer.h - Xtensa Target Streamer --------*- C++ -*--===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSATARGETSTREAMER_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSATARGETSTREAMER_H
+
+#include "XtensaConstantPoolValue.h"
+#include "llvm/MC/MCELFStreamer.h"
+#include "llvm/MC/MCStreamer.h"
+#include "llvm/Support/SMLoc.h"
+
+namespace llvm {
+class XtensaTargetStreamer : public MCTargetStreamer {
+public:
+  XtensaTargetStreamer(MCStreamer &S);
+  virtual void emitLiteral(MCSymbol *LblSym, const MCExpr *Value, SMLoc L) = 0;
+  virtual void emitLiteralLabel(MCSymbol *LblSym, SMLoc L) = 0;
+  virtual void emitLiteral(const MCExpr *Value, SMLoc L) = 0;
+  virtual void emitLiteral(std::string str) = 0;
+};
+
+class XtensaTargetAsmStreamer : public XtensaTargetStreamer {
+  formatted_raw_ostream &OS;
+
+public:
+  XtensaTargetAsmStreamer(MCStreamer &S, formatted_raw_ostream &OS);
+  void emitLiteral(MCSymbol *LblSym, const MCExpr *Value, SMLoc L) override {}
+  void emitLiteralLabel(MCSymbol *LblSym, SMLoc L) override {}
+  void emitLiteral(const MCExpr *Value, SMLoc L) override {}
+  void emitLiteral(std::string str) override;
+};
+
+class XtensaTargetELFStreamer : public XtensaTargetStreamer {
+public:
+  XtensaTargetELFStreamer(MCStreamer &S);
+  MCELFStreamer &getStreamer();
+  void emitLiteral(MCSymbol *LblSym, const MCExpr *Value, SMLoc L) override;
+  void emitLiteralLabel(MCSymbol *LblSym, SMLoc L) override;
+  void emitLiteral(const MCExpr *Value, SMLoc L) override;
+  void emitLiteral(std::string str) override {}
+};
+} // end namespace llvm
+
+#endif
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/TargetInfo/CMakeLists.txt
@@ -0,0 +1,5 @@
+include_directories( ${CMAKE_CURRENT_BINARY_DIR}/.. ${CMAKE_CURRENT_SOURCE_DIR}/.. )
+
+add_llvm_component_library(LLVMXtensaInfo
+  XtensaTargetInfo.cpp
+  )
--- /dev/null
+++ llvm/lib/Target/Xtensa/TargetInfo/LLVMBuild.txt
@@ -0,0 +1,22 @@
+;===- ./lib/Target/TargetInfo/LLVMBuild.txt --------------------*- Conf -*--===;
+;
+; Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+; See https://llvm.org/LICENSE.txt for license information.
+; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+;
+;===------------------------------------------------------------------------===;
+;
+; This is an LLVMBuild description file for the components in this subdirectory.
+;
+; For more information on the LLVMBuild system, please see:
+;
+;   http://llvm.org/docs/LLVMBuild.html
+;
+;===------------------------------------------------------------------------===;
+
+[component_0]
+type = Library
+name = XtensaInfo
+parent = Xtensa
+required_libraries = Support
+add_to_library_groups = Xtensa
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/TargetInfo/XtensaTargetInfo.cpp
@@ -0,0 +1,20 @@
+//===-- XtensaTargetInfo.cpp - Xtensa Target Implementation ---------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#include "llvm/Support/TargetRegistry.h"
+
+using namespace llvm;
+namespace llvm {
+Target TheXtensaTarget;
+}
+extern "C" LLVM_EXTERNAL_VISIBILITY void LLVMInitializeXtensaTargetInfo() {
+  RegisterTarget<Triple::xtensa> X(TheXtensaTarget, "xtensa", "Xtensa 32",
+                                   "XTENSA");
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/Xtensa.h
@@ -0,0 +1,30 @@
+//===- Xtensa.h - Top-level interface for Xtensa representation -*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains the entry points for global functions defined in
+// the LLVM Xtensa back-end.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSA_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSA_H
+
+#include "MCTargetDesc/XtensaMCTargetDesc.h"
+#include "llvm/PassRegistry.h"
+
+namespace llvm {
+class XtensaTargetMachine;
+class FunctionPass;
+
+FunctionPass *createXtensaISelDag(XtensaTargetMachine &TM,
+                                  CodeGenOpt::Level OptLevel);
+FunctionPass *createXtensaSizeReductionPass();
+} // namespace llvm
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSA_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/Xtensa.td
@@ -0,0 +1,216 @@
+//===- Xtensa.td - Describe the Xtensa Target Machine -----------*- tablegen -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===---------------------------------------------------------------------------===//
+
+//===----------------------------------------------------------------------===//
+// Target-independent interfaces
+//===----------------------------------------------------------------------===//
+
+include "llvm/Target/Target.td"
+
+//===----------------------------------------------------------------------===//
+// Subtarget Features.
+//===----------------------------------------------------------------------===//
+def FeatureDensity : SubtargetFeature<"density", "HasDensity", "true",
+                    "Enable Density instructions">;
+def HasDensity : Predicate<"Subtarget->hasDensity()">,
+                     AssemblerPredicate<"FeatureDensity">;
+
+def FeatureSingleFloat      : SubtargetFeature<"fp", "HasSingleFloat", "true",
+                                               "Enable Xtensa Single FP instructions">;
+def HasSingleFloat          : Predicate<"Subtarget->hasSingleFloat()">,
+                                        AssemblerPredicate<"FeatureSingleFloat">;
+
+def FeatureWindowed         : SubtargetFeature<"windowed", "HasWindowed", "true",
+                                               "Enable Xtensa Windowed Register option">;
+def HasWindowed             : Predicate<"Subtarget->hasWindowed()">,
+                                         AssemblerPredicate<"FeatureWindowed">; 
+
+def FeatureBoolean          : SubtargetFeature<"bool", "HasBoolean", "true",
+                                               "Enable Xtensa Boolean extension">;
+def HasBoolean              : Predicate<"Subtarget->hasBoolean()">,
+                                         AssemblerPredicate<"FeatureBoolean">;
+
+def FeatureLoop             : SubtargetFeature<"loop", "HasLoop", "true",
+                                               "Enable Xtensa Loop extension">;
+def HasLoop                 : Predicate<"Subtarget->hasLoop()">,
+                                         AssemblerPredicate<"FeatureLoop">;
+
+def FeatureSEXT             : SubtargetFeature<"sext", "HasSEXT", "true",
+                                              "Enable Xtensa Sign Extend option">;
+def HasSEXT                 : Predicate<"Subtarget->hasSEXT()">,
+                                         AssemblerPredicate<"FeatureSEXT">;
+
+def FeatureNSA              : SubtargetFeature<"nsa", "HasNSA", "true",
+                                               "Enable Xtensa NSA option">;
+def HasNSA                  : Predicate<"Subtarget->hasNSA()">,
+                                         AssemblerPredicate<"FeatureNSA">;
+
+def FeatureMul32            : SubtargetFeature<"mul32", "HasMul32", "true",
+                                               "Enable Xtensa Mul32 option">;
+def HasMul32                : Predicate<"Subtarget->hasMul32()">,
+                                         AssemblerPredicate<"FeatureMul32">;
+
+def FeatureMul32High        : SubtargetFeature<"mul32high", "HasMul32High", "true",
+                                               "Enable Xtensa Mul32High option">;
+def HasMul32High            : Predicate<"Subtarget->hasMul32High()">,
+                                         AssemblerPredicate<"FeatureMul32High">;
+
+def FeatureDiv32            : SubtargetFeature<"div32", "HasDiv32", "true",
+                                               "Enable Xtensa Div32 option">;
+def HasDiv32                : Predicate<"Subtarget->hasDiv32()">,
+                                         AssemblerPredicate<"FeatureDiv32">;
+
+def FeatureMAC16            : SubtargetFeature<"mac16", "HasMAC16", "true",
+                                               "Enable Xtensa MAC16 instructions">;
+def HasMAC16                : Predicate<"Subtarget->hasMAC16()">,
+                                         AssemblerPredicate<"FeatureMAC16">;
+
+def FeatureDFPAccel         : SubtargetFeature<"dfpaccel", "HasDFPAccel", "true",
+                                               "Enable Xtensa Double Precision FP acceleration">;
+def HasDFPAccel             : Predicate<"Subtarget->hasDFPAccel()">,
+                                        AssemblerPredicate<"FeatureDFPAccel">;
+
+def FeatureS32C1I           : SubtargetFeature<"s32c1i", "HasS32C1I", "true",
+                                               "Enable Xtensa S32C1I option">;
+def HasS32C1I               : Predicate<"Subtarget->hasS32C1I()">,
+                                         AssemblerPredicate<"FeatureS32C1I">;
+
+def FeatureTHREADPTR         : SubtargetFeature<"threadptr", "HasTHREADPTR", "true",
+                                                "Enable Xtensa THREADPTR option">;
+def HasTHREADPTR             : Predicate<"Subtarget->hasTHREADPTR()">,
+                                          AssemblerPredicate<"FeatureTHREADPTR">;
+
+def FeatureExtendedL32R      : SubtargetFeature<"extendedl32r", "HasExtendedL32R", "true",
+                                                "Enable Xtensa Extended L32R option">;
+def HasExtendedL32R          : Predicate<"Subtarget->hasExtendedL32R()">,
+                                          AssemblerPredicate<"FeatureExtendedL32R">;
+
+def FeatureATOMCTL           : SubtargetFeature<"atomctl", "HasATOMCTL", "true",
+                                                "Enable Xtensa ATOMCTL option">;
+def HasATOMCTL               : Predicate<"Subtarget->hasATOMCTL()">,
+                                          AssemblerPredicate<"FeatureATOMCTL">;
+
+def FeatureMEMCTL           : SubtargetFeature<"atomctl", "HasMEMCTL", "true",
+                                                "Enable Xtensa MEMCTL option">;
+def HasMEMCTL               : Predicate<"Subtarget->hasMEMCTL()">,
+                                          AssemblerPredicate<"FeatureMEMCTL">;
+
+def FeatureDebug             : SubtargetFeature<"debug", "HasDebug", "true",
+                                                "Enable Xtensa Debug option">;
+def HasDebug                 : Predicate<"Subtarget->hasDebug()">,
+                                          AssemblerPredicate<"FeatureDebug">;
+
+def FeatureException         : SubtargetFeature<"exception", "HasException", "true",
+                                                "Enable Xtensa Exception option">;
+def HasException             : Predicate<"Subtarget->hasException()">,
+                                          AssemblerPredicate<"FeatureException">;
+
+def FeatureHighPriInterrupts : SubtargetFeature<"exception",
+                                                "HasHighPriInterrupts", "true",
+                                                "Enable Xtensa HighPriInterrupts option">;
+def HasHighPriInterrupts     : Predicate<"Subtarget->hasHighPriInterrupts()">,
+                                          AssemblerPredicate<"FeatureHighPriInterrupts">;
+
+def FeatureCoprocessor       : SubtargetFeature<"coprocessor", "HasCoprocessor", "true",
+                                                "Enable Xtensa Coprocessor option">;
+def HasCoprocessor           : Predicate<"Subtarget->hasCoprocessor()">,
+                                          AssemblerPredicate<"FeatureCoprocessor">;
+
+def FeatureInterrupt         : SubtargetFeature<"interrupt", "HasInterrupt", "true",
+                                                "Enable Xtensa Interrupt option">;
+def HasInterrupt             : Predicate<"Subtarget->hasInterrupt()">,
+                                          AssemblerPredicate<"FeatureInterrupt">;
+
+def FeatureRelocatableVector : SubtargetFeature<"rvector", "HasRelocatableVector", "true",
+                                                "Enable Xtensa Relocatable Vector option">;
+def HasRelocatableVector     : Predicate<"Subtarget->hasRelocatableVector()">,
+                                          AssemblerPredicate<"FeatureRelocatableVector">;
+
+def FeatureTimerInt          : SubtargetFeature<"timerint", "HasTimerInt", "true",
+                                                "Enable Xtensa Timer Interrupt option">;
+def HasTimerInt              : Predicate<"Subtarget->hasTimerInt()">,
+                                          AssemblerPredicate<"FeatureTimerInt">;
+
+def FeaturePRID              : SubtargetFeature<"prid", "HasPRID", "true",
+                                                "Enable Xtensa Processor ID option">;
+def HasPRID                  : Predicate<"Subtarget->hasPRID()">,
+                                          AssemblerPredicate<"FeaturePRID">;
+
+def FeatureRegionProtection  : SubtargetFeature<"regprotect", "HasRegionProtection", "true",
+                                                "Enable Xtensa Region Protection option">;
+def HasRegionProtection      : Predicate<"Subtarget->hasRegionProtection()">,
+                                          AssemblerPredicate<"FeatureRegionProtection">;
+
+def FeatureMiscSR            : SubtargetFeature<"miscsr", "HasMiscSR", "true",
+                                                "Enable Xtensa Miscellaneous SR option">;
+def HasMiscSR                : Predicate<"Subtarget->hasMiscSR()">,
+                                          AssemblerPredicate<"FeatureMiscSR">;
+
+//===----------------------------------------------------------------------===//
+// Xtensa supported processors.
+//===----------------------------------------------------------------------===//
+class Proc<string Name, list<SubtargetFeature> Features>
+    : Processor<Name, NoItineraries, Features>;
+
+def : Proc<"generic", []>;
+
+def : Proc<"esp32", [FeatureDensity, FeatureSingleFloat, FeatureLoop, FeatureMAC16, FeatureWindowed, FeatureBoolean, 
+                     FeatureSEXT, FeatureNSA, FeatureMul32, FeatureMul32High, FeatureDFPAccel, FeatureS32C1I, FeatureTHREADPTR, FeatureDiv32,
+                     FeatureATOMCTL, FeatureMEMCTL, FeatureDebug, FeatureException, FeatureHighPriInterrupts, FeatureCoprocessor,
+                     FeatureInterrupt, FeatureRelocatableVector, FeatureTimerInt, FeaturePRID, FeatureRegionProtection, FeatureMiscSR]>;
+
+def : Proc<"esp8266", [FeatureDensity, FeatureNSA, FeatureMul32, FeatureExtendedL32R, FeatureDebug, FeatureException, FeatureHighPriInterrupts,
+                       FeatureInterrupt, FeatureRelocatableVector, FeatureTimerInt, FeatureRegionProtection, FeaturePRID]>;
+
+def : Proc<"esp32-s2", [FeatureDensity, FeatureWindowed, FeatureSEXT, FeatureNSA, FeatureMul32, FeatureMul32High, FeatureTHREADPTR, FeatureDiv32,
+                        FeatureDebug, FeatureException, FeatureHighPriInterrupts, FeatureCoprocessor, FeatureInterrupt, FeatureRelocatableVector,
+						FeatureTimerInt, FeaturePRID, FeatureRegionProtection, FeatureMiscSR]>;
+
+//===----------------------------------------------------------------------===//
+// Register File Description
+//===----------------------------------------------------------------------===//
+
+include "XtensaRegisterInfo.td"
+
+//===----------------------------------------------------------------------===//
+// Calling Convention Description
+//===----------------------------------------------------------------------===//
+
+include "XtensaCallingConv.td"
+
+//===----------------------------------------------------------------------===//
+// Instruction Descriptions
+//===----------------------------------------------------------------------===//
+
+include "XtensaInstrInfo.td"
+
+def XtensaInstrInfo : InstrInfo;
+
+//===----------------------------------------------------------------------===//
+// Target Declaration
+//===----------------------------------------------------------------------===//
+
+def XtensaAsmParser : AsmParser {
+  let ShouldEmitMatchRegisterAltName = 1;
+}
+
+def XtensaInstPrinter : AsmWriter
+{
+  string AsmWriterClassName  = "InstPrinter";
+  bit isMCAsmWriter = 1;
+}
+
+def Xtensa : Target
+{
+  let InstructionSet = XtensaInstrInfo;
+  let AssemblyWriters = [XtensaInstPrinter];
+  let AssemblyParsers = [XtensaAsmParser];
+}
+
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaAsmPrinter.cpp
@@ -0,0 +1,276 @@
+//===- XtensaAsmPrinter.cpp Xtensa LLVM Assembly Printer ------------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains a printer that converts from our internal representation
+// of machine-dependent LLVM code to GAS-format Xtensa assembly language.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaAsmPrinter.h"
+#include "MCTargetDesc/XtensaInstPrinter.h"
+#include "XtensaConstantPoolValue.h"
+#include "XtensaMCInstLower.h"
+#include "llvm/BinaryFormat/ELF.h"
+#include "llvm/CodeGen/MachineModuleInfoImpls.h"
+#include "llvm/CodeGen/TargetLoweringObjectFileImpl.h"
+#include "llvm/MC/MCExpr.h"
+#include "llvm/MC/MCInstBuilder.h"
+#include "llvm/MC/MCSectionELF.h"
+#include "llvm/MC/MCStreamer.h"
+#include "llvm/MC/MCSymbol.h"
+#include "llvm/MC/MCSymbolELF.h"
+#include "llvm/Support/TargetRegistry.h"
+
+using namespace llvm;
+
+static MCSymbolRefExpr::VariantKind
+getModifierVariantKind(XtensaCP::XtensaCPModifier Modifier) {
+  switch (Modifier) {
+  case XtensaCP::no_modifier:
+    return MCSymbolRefExpr::VK_None;
+  case XtensaCP::TPOFF:
+    return MCSymbolRefExpr::VK_TPOFF;
+  }
+  llvm_unreachable("Invalid XtensaCPModifier!");
+}
+
+void XtensaAsmPrinter::EmitInstruction(const MachineInstr *MI) {
+  XtensaMCInstLower Lower(MF->getContext(), *this);
+  MCInst LoweredMI;
+  unsigned Opc = MI->getOpcode();
+
+  switch (Opc) {
+  case Xtensa::BR_JT: {
+    EmitToStreamer(
+        *OutStreamer,
+        MCInstBuilder(Xtensa::JX).addReg(MI->getOperand(0).getReg()));
+    return;
+  }
+  }
+  Lower.lower(MI, LoweredMI);
+  EmitToStreamer(*OutStreamer, LoweredMI);
+}
+
+/// EmitConstantPool - Print to the current output stream assembly
+/// representations of the constants in the constant pool MCP. This is
+/// used to print out constants which have been "spilled to memory" by
+/// the code generator.
+void XtensaAsmPrinter::EmitConstantPool() {
+  const Function &F = MF->getFunction();
+  const MachineConstantPool *MCP = MF->getConstantPool();
+  const std::vector<MachineConstantPoolEntry> &CP = MCP->getConstants();
+  if (CP.empty())
+    return;
+
+  for (unsigned i = 0, e = CP.size(); i != e; ++i) {
+    const MachineConstantPoolEntry &CPE = CP[i];
+
+    if (i == 0) {
+      if (OutStreamer->hasRawTextSupport()) {
+        OutStreamer->SwitchSection(
+            getObjFileLowering().SectionForGlobal(&F, TM));
+        OutStreamer->EmitRawText("\t.literal_position\n");
+      } else {
+        MCSectionELF *CS =
+            (MCSectionELF *)getObjFileLowering().SectionForGlobal(&F, TM);
+        std::string CSectionName = CS->getSectionName();
+        std::size_t Pos = CSectionName.find(".text");
+        std::string SectionName;
+        if (Pos != std::string::npos) {
+          if (Pos > 0)
+            SectionName = CSectionName.substr(0, Pos + 5);
+          else
+            SectionName = "";
+          SectionName += ".literal";
+          SectionName += CSectionName.substr(Pos + 5);
+        } else {
+          SectionName = CSectionName;
+          SectionName += ".literal";
+        }
+
+        MCSectionELF *S =
+            OutContext.getELFSection(SectionName, ELF::SHT_PROGBITS,
+                                     ELF::SHF_EXECINSTR | ELF::SHF_ALLOC);
+        S->setAlignment(Align(4));
+        OutStreamer->SwitchSection(S);
+      }
+    }
+
+    if (CPE.isMachineConstantPoolEntry()) {
+      XtensaConstantPoolValue *ACPV =
+          static_cast<XtensaConstantPoolValue *>(CPE.Val.MachineCPVal);
+      ACPV->setLabelId(i);
+      EmitMachineConstantPoolValue(CPE.Val.MachineCPVal);
+    } else {
+      MCSymbol *LblSym = GetCPISymbol(i);
+      // TODO find a better way to check whether we emit data to .s file
+      if (OutStreamer->hasRawTextSupport()) {
+        std::string str("\t.literal ");
+        str += LblSym->getName();
+        str += ", ";
+        const Constant *C = CPE.Val.ConstVal;
+
+        Type *Ty = C->getType();
+        if (const auto *CFP = dyn_cast<ConstantFP>(C)) {
+          str += CFP->getValueAPF().bitcastToAPInt().toString(10, true);
+        } else if (const auto *CI = dyn_cast<ConstantInt>(C)) {
+          str += CI->getValue().toString(10, true);
+        } else if (isa<PointerType>(Ty)) {
+          const MCExpr *ME = lowerConstant(C);
+          const MCSymbolRefExpr &SRE = cast<MCSymbolRefExpr>(*ME);
+          const MCSymbol &Sym = SRE.getSymbol();
+          str += Sym.getName();
+        } else {
+          unsigned NumElements;
+          if (isa<VectorType>(Ty))
+            NumElements = Ty->getVectorNumElements();
+          else
+            NumElements = Ty->getArrayNumElements();
+
+          for (unsigned I = 0; I < NumElements; I++) {
+            const Constant *CAE = C->getAggregateElement(I);
+            if (I > 0)
+              str += ", ";
+            if (const auto *CFP = dyn_cast<ConstantFP>(CAE)) {
+              str += CFP->getValueAPF().bitcastToAPInt().toString(10, true);
+            } else if (const auto *CI = dyn_cast<ConstantInt>(CAE)) {
+              str += CI->getValue().toString(10, true);
+            }
+          }
+        }
+
+        OutStreamer->EmitRawText(str);
+      } else {
+        OutStreamer->EmitLabel(LblSym);
+        EmitGlobalConstant(getDataLayout(), CPE.Val.ConstVal);
+      }
+    }
+  }
+}
+
+void XtensaAsmPrinter::EmitMachineConstantPoolValue(
+    MachineConstantPoolValue *MCPV) {
+  XtensaConstantPoolValue *ACPV = static_cast<XtensaConstantPoolValue *>(MCPV);
+
+  MCSymbol *MCSym;
+  if (ACPV->isBlockAddress()) {
+    const BlockAddress *BA =
+        cast<XtensaConstantPoolConstant>(ACPV)->getBlockAddress();
+    MCSym = GetBlockAddressSymbol(BA);
+  } else if (ACPV->isGlobalValue()) {
+    const GlobalValue *GV = cast<XtensaConstantPoolConstant>(ACPV)->getGV();
+    // TODO some modifiers
+    MCSym = getSymbol(GV);
+  } else if (ACPV->isMachineBasicBlock()) {
+    const MachineBasicBlock *MBB = cast<XtensaConstantPoolMBB>(ACPV)->getMBB();
+    MCSym = MBB->getSymbol();
+  } else if (ACPV->isJumpTable()) {
+    unsigned idx = cast<XtensaConstantPoolJumpTable>(ACPV)->getIndex();
+    MCSym = this->GetJTISymbol(idx, false);
+  } else {
+    assert(ACPV->isExtSymbol() && "unrecognized constant pool value");
+    XtensaConstantPoolSymbol *XtensaSym = cast<XtensaConstantPoolSymbol>(ACPV);
+    const char *Sym = XtensaSym->getSymbol();
+    // TODO it's a trick to distinguish static references and generated rodata
+    // references Some clear method required
+    {
+      std::string SymName(Sym);
+      if (XtensaSym->isPrivateLinkage())
+        SymName = ".L" + SymName;
+      MCSym = GetExternalSymbolSymbol(StringRef(SymName));
+    }
+  }
+
+  MCSymbol *LblSym = GetCPISymbol(ACPV->getLabelId());
+  // TODO find a better way to check whether we emit data to .s file
+  if (OutStreamer->hasRawTextSupport()) {
+    std::string SymName("\t.literal ");
+    SymName += LblSym->getName();
+    SymName += ", ";
+    SymName += MCSym->getName();
+
+    StringRef Modifier = ACPV->getModifierText();
+    SymName += Modifier;
+
+    OutStreamer->EmitRawText(SymName);
+  } else {
+    MCSymbolRefExpr::VariantKind VK =
+        getModifierVariantKind(ACPV->getModifier());
+
+    if (ACPV->getModifier() != XtensaCP::no_modifier) {
+      std::string SymName(MCSym->getName());
+      MCSym = GetExternalSymbolSymbol(StringRef(SymName));
+    }
+
+    const MCExpr *Expr = MCSymbolRefExpr::create(MCSym, VK, OutContext);
+    uint64_t Size = getDataLayout().getTypeAllocSize(ACPV->getType());
+    OutStreamer->EmitLabel(LblSym);
+    OutStreamer->EmitValue(Expr, Size);
+  }
+}
+
+void XtensaAsmPrinter::printOperand(const MachineInstr *MI, int OpNo,
+                                    raw_ostream &O) {
+  const MachineOperand &MO = MI->getOperand(OpNo);
+
+  switch (MO.getType()) {
+  case MachineOperand::MO_Register:
+  case MachineOperand::MO_Immediate: {
+    XtensaMCInstLower Lower(MF->getContext(), *this);
+    MCOperand MC(Lower.lowerOperand(MI->getOperand(OpNo)));
+    XtensaInstPrinter::printOperand(MC, O);
+    break;
+  }
+  case MachineOperand::MO_GlobalAddress:
+    O << *getSymbol(MO.getGlobal());
+    break;
+  default:
+    llvm_unreachable("<unknown operand type>");
+  }
+
+  if (MO.getTargetFlags()) {
+    O << ")";
+  }
+}
+
+bool XtensaAsmPrinter::PrintAsmOperand(const MachineInstr *MI, unsigned OpNo,
+                                       const char *ExtraCode, raw_ostream &O) {
+  if (ExtraCode && *ExtraCode == 'n') {
+    if (!MI->getOperand(OpNo).isImm())
+      return true;
+    O << -int64_t(MI->getOperand(OpNo).getImm());
+  } else {
+    printOperand(MI, OpNo, O);
+  }
+  return false;
+}
+
+bool XtensaAsmPrinter::PrintAsmMemoryOperand(const MachineInstr *MI,
+                                             unsigned OpNo,
+                                             const char *ExtraCode,
+                                             raw_ostream &OS) {
+  XtensaInstPrinter::printAddress(MI->getOperand(OpNo).getReg(),
+                                  MI->getOperand(OpNo + 1).getImm(), OS);
+  return false;
+}
+
+void XtensaAsmPrinter::printMemOperand(const MachineInstr *MI, int opNum,
+                                       raw_ostream &OS) {
+  OS << '%'
+     << XtensaInstPrinter::getRegisterName(MI->getOperand(opNum).getReg());
+  OS << "(";
+  OS << MI->getOperand(opNum + 1).getImm();
+  OS << ")";
+}
+
+// Force static initialization.
+extern "C" LLVM_EXTERNAL_VISIBILITY void LLVMInitializeXtensaAsmPrinter() {
+  RegisterAsmPrinter<XtensaAsmPrinter> A(TheXtensaTarget);
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaAsmPrinter.h
@@ -0,0 +1,49 @@
+//===- XtensaAsmPrinter.h - Xtensa LLVM Assembly Printer --------*- C++-*--===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// Xtensa Assembly printer class.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSAASMPRINTER_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSAASMPRINTER_H
+
+#include "XtensaTargetMachine.h"
+#include "llvm/CodeGen/AsmPrinter.h"
+#include "llvm/Support/Compiler.h"
+
+namespace llvm {
+class MCStreamer;
+class MachineBasicBlock;
+class MachineInstr;
+class Module;
+class raw_ostream;
+
+class LLVM_LIBRARY_VISIBILITY XtensaAsmPrinter : public AsmPrinter {
+private:
+public:
+  XtensaAsmPrinter(TargetMachine &TM, std::unique_ptr<MCStreamer> Streamer)
+      : AsmPrinter(TM, std::move(Streamer)) {}
+
+  // Override AsmPrinter.
+  StringRef getPassName() const override { return "Xtensa Assembly Printer"; }
+  void EmitInstruction(const MachineInstr *MI) override;
+  void EmitConstantPool() override;
+  void EmitMachineConstantPoolValue(MachineConstantPoolValue *MCPV) override;
+  void printOperand(const MachineInstr *MI, int opNum, raw_ostream &O);
+  bool PrintAsmOperand(const MachineInstr *MI, unsigned OpNo,
+                       const char *ExtraCode, raw_ostream &O) override;
+  bool PrintAsmMemoryOperand(const MachineInstr *MI, unsigned OpNo,
+                             const char *ExtraCode, raw_ostream &OS) override;
+  void printMemOperand(const MachineInstr *MI, int opNum, raw_ostream &OS);
+};
+} // end namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSAASMPRINTER_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaCallingConv.td
@@ -0,0 +1,48 @@
+//===- XtensaCallingConv.td - Xtensa Calling Conventions -*- tablegen ---*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+// This describes the calling conventions for the Xtensa ABI.
+//===----------------------------------------------------------------------===//
+
+/// CCIfAlign - Match of the original alignment of the arg
+class CCIfAlign<string Align, CCAction A>:
+  CCIf<!strconcat("ArgFlags.getOrigAlign() == ", Align), A>;
+
+//===----------------------------------------------------------------------===//
+// Xtensa return value calling convention
+//===----------------------------------------------------------------------===//
+def RetCC_Xtensa: CallingConv<[
+  CCIfType<[i1, i8, i16], CCPromoteToType<i32>>,
+  CCIfType<[f32], CCBitConvertToType<i32>>,
+
+  //First two return values go in a2, a3, a4, a5
+  CCIfType<[i32], CCAssignToReg<[A2, A3, A4, A5]>>,
+  CCIfType<[f32], CCAssignToReg<[A2, A3, A4, A5]>>,
+  CCIfType<[i64], CCAssignToRegWithShadow<[A2, A4], [A3, A5]>>
+]>;
+
+//===----------------------------------------------------------------------===//
+// Callee-saved register lists.
+//===----------------------------------------------------------------------===//
+
+def CSR_Xtensa: CalleeSavedRegs<(add A0, A12, A13, A14, A15)>;
+def CSRWE_Xtensa : CalleeSavedRegs<(add)> {
+  let OtherPreserved = (add A0, SP, A2, A3, A4, A5, A6, A7);
+}
+//===----------------------------------------------------------------------===//
+
+def RetCCW_Xtensa: CallingConv<[
+  CCIfType<[i1, i8, i16], CCPromoteToType<i32>>,
+  CCIfType<[f32], CCBitConvertToType<i32>>,
+
+  //First two return values go in a10, a11, a12, a13
+  CCIfType<[i32], CCAssignToReg<[A10, A11, A12, A13]>>,
+  CCIfType<[f32], CCAssignToReg<[A10, A11, A12, A13]>>,
+  CCIfType<[i64], CCAssignToRegWithShadow<[A10, A12], [A11, A13]>>
+]>;
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaConstantPoolValue.cpp
@@ -0,0 +1,234 @@
+//===- XtensaConstantPoolValue.cpp - Xtensa constantpool value ------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements the Xtensa specific constantpool value class.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaConstantPoolValue.h"
+#include "llvm/ADT/FoldingSet.h"
+#include "llvm/CodeGen/MachineBasicBlock.h"
+#include "llvm/IR/Constant.h"
+#include "llvm/IR/Constants.h"
+#include "llvm/IR/GlobalValue.h"
+#include "llvm/IR/Type.h"
+#include "llvm/Support/raw_ostream.h"
+#include <cstdlib>
+using namespace llvm;
+
+XtensaConstantPoolValue::XtensaConstantPoolValue(
+    Type *Ty, unsigned id, XtensaCP::XtensaCPKind kind, bool addCurrentAddress,
+    XtensaCP::XtensaCPModifier modifier)
+    : MachineConstantPoolValue(Ty), LabelId(id), Kind(kind), Modifier(modifier),
+      AddCurrentAddress(addCurrentAddress) {}
+
+XtensaConstantPoolValue::XtensaConstantPoolValue(
+    LLVMContext &C, unsigned id, XtensaCP::XtensaCPKind kind,
+    bool addCurrentAddress, XtensaCP::XtensaCPModifier modifier)
+    : MachineConstantPoolValue((Type *)Type::getInt32Ty(C)), LabelId(id),
+      Kind(kind), Modifier(modifier), AddCurrentAddress(addCurrentAddress) {}
+
+XtensaConstantPoolValue::~XtensaConstantPoolValue() {}
+
+StringRef XtensaConstantPoolValue::getModifierText() const {
+  switch (Modifier) {
+  case XtensaCP::no_modifier:
+    return "";
+  case XtensaCP::TPOFF:
+    return "@TPOFF";
+  }
+  llvm_unreachable("Unknown modifier!");
+}
+
+int XtensaConstantPoolValue::getExistingMachineCPValue(MachineConstantPool *CP,
+                                                       unsigned Alignment) {
+  llvm_unreachable("Shouldn't be calling this directly!");
+}
+
+void XtensaConstantPoolValue::addSelectionDAGCSEId(FoldingSetNodeID &ID) {
+  ID.AddInteger(LabelId);
+}
+
+bool XtensaConstantPoolValue::hasSameValue(XtensaConstantPoolValue *ACPV) {
+  if (ACPV->Kind == Kind) {
+    if (ACPV->LabelId == LabelId)
+      return true;
+    // Two PC relative constpool entries containing the same GV address or
+    // external symbols. FIXME: What about blockaddress?
+    if (Kind == XtensaCP::CPValue || Kind == XtensaCP::CPExtSymbol)
+      return true;
+  }
+  return false;
+}
+
+void XtensaConstantPoolValue::dump() const { errs() << "  " << *this; }
+
+void XtensaConstantPoolValue::print(raw_ostream &O) const {}
+
+//===----------------------------------------------------------------------===//
+// XtensaConstantPoolConstant
+//===----------------------------------------------------------------------===//
+
+XtensaConstantPoolConstant::XtensaConstantPoolConstant(
+    Type *Ty, const Constant *C, unsigned ID, XtensaCP::XtensaCPKind Kind,
+    bool AddCurrentAddress)
+    : XtensaConstantPoolValue((Type *)C->getType(), ID, Kind,
+                              AddCurrentAddress),
+      CVal(C) {}
+
+XtensaConstantPoolConstant::XtensaConstantPoolConstant(
+    const Constant *C, unsigned ID, XtensaCP::XtensaCPKind Kind,
+    bool AddCurrentAddress)
+    : XtensaConstantPoolValue((Type *)C->getType(), ID, Kind,
+                              AddCurrentAddress),
+      CVal(C) {}
+
+XtensaConstantPoolConstant *
+XtensaConstantPoolConstant::Create(const Constant *C, unsigned ID,
+                                   XtensaCP::XtensaCPKind Kind) {
+  return new XtensaConstantPoolConstant(C, ID, Kind, false);
+}
+
+XtensaConstantPoolConstant *
+XtensaConstantPoolConstant::Create(const Constant *C, unsigned ID,
+                                   XtensaCP::XtensaCPKind Kind,
+                                   bool AddCurrentAddress) {
+  return new XtensaConstantPoolConstant(C, ID, Kind, AddCurrentAddress);
+}
+
+const GlobalValue *XtensaConstantPoolConstant::getGV() const {
+  return dyn_cast_or_null<GlobalValue>(CVal);
+}
+
+const BlockAddress *XtensaConstantPoolConstant::getBlockAddress() const {
+  return dyn_cast_or_null<BlockAddress>(CVal);
+}
+
+int XtensaConstantPoolConstant::getExistingMachineCPValue(
+    MachineConstantPool *CP, unsigned Alignment) {
+  return getExistingMachineCPValueImpl<XtensaConstantPoolConstant>(CP,
+                                                                   Alignment);
+}
+
+bool XtensaConstantPoolConstant::hasSameValue(XtensaConstantPoolValue *ACPV) {
+  const XtensaConstantPoolConstant *ACPC =
+      dyn_cast<XtensaConstantPoolConstant>(ACPV);
+  return ACPC && ACPC->CVal == CVal &&
+         XtensaConstantPoolValue::hasSameValue(ACPV);
+}
+
+void XtensaConstantPoolConstant::addSelectionDAGCSEId(FoldingSetNodeID &ID) {
+  ID.AddPointer(CVal);
+  XtensaConstantPoolValue::addSelectionDAGCSEId(ID);
+}
+
+void XtensaConstantPoolConstant::print(raw_ostream &O) const {
+  O << CVal->getName();
+  XtensaConstantPoolValue::print(O);
+}
+
+XtensaConstantPoolSymbol::XtensaConstantPoolSymbol(
+    LLVMContext &C, const char *s, unsigned id, bool AddCurrentAddress,
+    bool PrivLinkage, XtensaCP::XtensaCPModifier Modifier)
+    : XtensaConstantPoolValue(C, id, XtensaCP::CPExtSymbol, AddCurrentAddress,
+                              Modifier),
+      S(s), PrivateLinkage(PrivLinkage) {}
+
+XtensaConstantPoolSymbol *
+XtensaConstantPoolSymbol::Create(LLVMContext &C, const char *s, unsigned ID,
+                                 bool PrivLinkage,
+                                 XtensaCP::XtensaCPModifier Modifier)
+
+{
+  return new XtensaConstantPoolSymbol(C, s, ID, false, PrivLinkage, Modifier);
+}
+
+int XtensaConstantPoolSymbol::getExistingMachineCPValue(MachineConstantPool *CP,
+                                                        unsigned Alignment) {
+  return getExistingMachineCPValueImpl<XtensaConstantPoolSymbol>(CP, Alignment);
+}
+
+bool XtensaConstantPoolSymbol::hasSameValue(XtensaConstantPoolValue *ACPV) {
+  const XtensaConstantPoolSymbol *ACPS =
+      dyn_cast<XtensaConstantPoolSymbol>(ACPV);
+  return ACPS && ACPS->S == S && XtensaConstantPoolValue::hasSameValue(ACPV);
+}
+
+void XtensaConstantPoolSymbol::addSelectionDAGCSEId(FoldingSetNodeID &ID) {
+  ID.AddString(S);
+  XtensaConstantPoolValue::addSelectionDAGCSEId(ID);
+}
+
+void XtensaConstantPoolSymbol::print(raw_ostream &O) const {
+  O << S;
+  XtensaConstantPoolValue::print(O);
+}
+
+XtensaConstantPoolMBB::XtensaConstantPoolMBB(LLVMContext &C,
+                                             const MachineBasicBlock *mbb,
+                                             unsigned id)
+    : XtensaConstantPoolValue(C, 0, XtensaCP::CPMachineBasicBlock, false),
+      MBB(mbb) {}
+
+XtensaConstantPoolMBB *
+XtensaConstantPoolMBB::Create(LLVMContext &C, const MachineBasicBlock *mbb,
+                              unsigned idx) {
+  return new XtensaConstantPoolMBB(C, mbb, idx);
+}
+
+int XtensaConstantPoolMBB::getExistingMachineCPValue(MachineConstantPool *CP,
+                                                     unsigned Alignment) {
+  return getExistingMachineCPValueImpl<XtensaConstantPoolMBB>(CP, Alignment);
+}
+
+bool XtensaConstantPoolMBB::hasSameValue(XtensaConstantPoolValue *ACPV) {
+  const XtensaConstantPoolMBB *ACPMBB = dyn_cast<XtensaConstantPoolMBB>(ACPV);
+  return ACPMBB && ACPMBB->MBB == MBB &&
+         XtensaConstantPoolValue::hasSameValue(ACPV);
+}
+
+void XtensaConstantPoolMBB::addSelectionDAGCSEId(FoldingSetNodeID &ID) {
+  ID.AddPointer(MBB);
+  XtensaConstantPoolValue::addSelectionDAGCSEId(ID);
+}
+
+void XtensaConstantPoolMBB::print(raw_ostream &O) const {
+  O << "BB#" << MBB->getNumber();
+  XtensaConstantPoolValue::print(O);
+}
+
+XtensaConstantPoolJumpTable::XtensaConstantPoolJumpTable(LLVMContext &C,
+                                                         unsigned idx)
+    : XtensaConstantPoolValue(C, 0, XtensaCP::CPJumpTable, false), IDX(idx) {}
+
+XtensaConstantPoolJumpTable *XtensaConstantPoolJumpTable::Create(LLVMContext &C,
+                                                                 unsigned idx) {
+  return new XtensaConstantPoolJumpTable(C, idx);
+}
+
+int XtensaConstantPoolJumpTable::getExistingMachineCPValue(
+    MachineConstantPool *CP, unsigned Alignment) {
+  return getExistingMachineCPValueImpl<XtensaConstantPoolJumpTable>(CP,
+                                                                    Alignment);
+}
+
+bool XtensaConstantPoolJumpTable::hasSameValue(XtensaConstantPoolValue *ACPV) {
+  const XtensaConstantPoolJumpTable *ACPJT =
+      dyn_cast<XtensaConstantPoolJumpTable>(ACPV);
+  return ACPJT && ACPJT->IDX == IDX &&
+         XtensaConstantPoolValue::hasSameValue(ACPV);
+}
+
+void XtensaConstantPoolJumpTable::addSelectionDAGCSEId(FoldingSetNodeID &ID) {}
+
+void XtensaConstantPoolJumpTable::print(raw_ostream &O) const {
+  O << "JT" << IDX;
+  XtensaConstantPoolValue::print(O);
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaConstantPoolValue.h
@@ -0,0 +1,281 @@
+//===- XtensaConstantPoolValue.h - Xtensa constantpool value ----*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements the Xtensa specific constantpool value class.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSACONSTANTPOOLVALUE_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSACONSTANTPOOLVALUE_H
+
+#include "llvm/CodeGen/MachineConstantPool.h"
+#include "llvm/Support/Casting.h"
+#include "llvm/Support/ErrorHandling.h"
+#include <cstddef>
+
+namespace llvm {
+
+class BlockAddress;
+class Constant;
+class GlobalValue;
+class LLVMContext;
+class MachineBasicBlock;
+
+namespace XtensaCP {
+enum XtensaCPKind {
+  CPValue,
+  CPExtSymbol,
+  CPBlockAddress,
+  CPMachineBasicBlock,
+  CPJumpTable
+};
+
+enum XtensaCPModifier {
+  no_modifier, // None
+  TPOFF        // Thread Pointer Offset
+};
+} // namespace XtensaCP
+
+/// XtensaConstantPoolValue - Xtensa specific constantpool value. This is used
+/// to represent PC-relative displacement between the address of the load
+/// instruction and the constant being loaded, i.e. (&GV-(LPIC+8)).
+class XtensaConstantPoolValue : public MachineConstantPoolValue {
+  unsigned LabelId;                    // Label id of the load.
+  XtensaCP::XtensaCPKind Kind;         // Kind of constant.
+  XtensaCP::XtensaCPModifier Modifier; // GV modifier
+  bool AddCurrentAddress;
+
+protected:
+  XtensaConstantPoolValue(
+      Type *Ty, unsigned id, XtensaCP::XtensaCPKind Kind,
+      bool AddCurrentAddress,
+      XtensaCP::XtensaCPModifier Modifier = XtensaCP::no_modifier);
+
+  XtensaConstantPoolValue(
+      LLVMContext &C, unsigned id, XtensaCP::XtensaCPKind Kind,
+      bool AddCurrentAddress,
+      XtensaCP::XtensaCPModifier Modifier = XtensaCP::no_modifier);
+
+  template <typename Derived>
+  int getExistingMachineCPValueImpl(MachineConstantPool *CP,
+                                    unsigned Alignment) {
+    unsigned AlignMask = Alignment - 1;
+    const std::vector<MachineConstantPoolEntry> &Constants = CP->getConstants();
+    for (unsigned i = 0, e = Constants.size(); i != e; ++i) {
+      if (Constants[i].isMachineConstantPoolEntry() &&
+          (Constants[i].getAlignment() & AlignMask) == 0) {
+        XtensaConstantPoolValue *CPV =
+            (XtensaConstantPoolValue *)Constants[i].Val.MachineCPVal;
+        if (Derived *APC = dyn_cast<Derived>(CPV))
+          if (cast<Derived>(this)->equals(APC))
+            return i;
+      }
+    }
+
+    return -1;
+  }
+
+public:
+  ~XtensaConstantPoolValue() override;
+
+  XtensaCP::XtensaCPModifier getModifier() const { return Modifier; }
+  bool hasModifier() const { return Modifier != XtensaCP::no_modifier; }
+  StringRef getModifierText() const;
+
+  bool mustAddCurrentAddress() const { return AddCurrentAddress; }
+
+  unsigned getLabelId() const { return LabelId; }
+  void setLabelId(unsigned id) { LabelId = id; }
+
+  bool isGlobalValue() const { return Kind == XtensaCP::CPValue; }
+  bool isExtSymbol() const { return Kind == XtensaCP::CPExtSymbol; }
+  bool isBlockAddress() const { return Kind == XtensaCP::CPBlockAddress; }
+  bool isMachineBasicBlock() const {
+    return Kind == XtensaCP::CPMachineBasicBlock;
+  }
+  bool isJumpTable() const { return Kind == XtensaCP::CPJumpTable; }
+
+  int getExistingMachineCPValue(MachineConstantPool *CP,
+                                unsigned Alignment) override;
+
+  void addSelectionDAGCSEId(FoldingSetNodeID &ID) override;
+
+  /// hasSameValue - Return true if this Xtensa constpool value can share the
+  /// same constantpool entry as another Xtensa constpool value.
+  virtual bool hasSameValue(XtensaConstantPoolValue *ACPV);
+
+  bool equals(const XtensaConstantPoolValue *A) const {
+    return this->LabelId == A->LabelId && this->Modifier == A->Modifier;
+  }
+
+  void print(raw_ostream &O) const override;
+  void print(raw_ostream *O) const {
+    if (O)
+      print(*O);
+  }
+  void dump() const;
+};
+
+inline raw_ostream &operator<<(raw_ostream &O,
+                               const XtensaConstantPoolValue &V) {
+  V.print(O);
+  return O;
+}
+
+/// XtensaConstantPoolConstant - Xtensa-specific constant pool values for
+/// Constants, Functions, and BlockAddresses.
+class XtensaConstantPoolConstant : public XtensaConstantPoolValue {
+  const Constant *CVal; // Constant being loaded.
+
+  XtensaConstantPoolConstant(const Constant *C, unsigned ID,
+                             XtensaCP::XtensaCPKind Kind,
+                             bool AddCurrentAddress);
+  XtensaConstantPoolConstant(Type *Ty, const Constant *C, unsigned ID,
+                             XtensaCP::XtensaCPKind Kind,
+                             bool AddCurrentAddress);
+
+public:
+  static XtensaConstantPoolConstant *Create(const Constant *C, unsigned ID,
+                                            XtensaCP::XtensaCPKind Kind);
+  static XtensaConstantPoolConstant *Create(const Constant *C, unsigned ID,
+                                            XtensaCP::XtensaCPKind Kind,
+                                            bool AddCurrentAddress);
+
+  const GlobalValue *getGV() const;
+  const BlockAddress *getBlockAddress() const;
+
+  int getExistingMachineCPValue(MachineConstantPool *CP,
+                                unsigned Alignment) override;
+
+  /// hasSameValue - Return true if this Xtensa constpool value can share the
+  /// same constantpool entry as another Xtensa constpool value.
+  bool hasSameValue(XtensaConstantPoolValue *ACPV) override;
+
+  void addSelectionDAGCSEId(FoldingSetNodeID &ID) override;
+
+  void print(raw_ostream &O) const override;
+  static bool classof(const XtensaConstantPoolValue *APV) {
+    return APV->isGlobalValue() || APV->isBlockAddress();
+  }
+
+  bool equals(const XtensaConstantPoolConstant *A) const {
+    return CVal == A->CVal && XtensaConstantPoolValue::equals(A);
+  }
+};
+
+/// XtensaConstantPoolSymbol - Xtensa-specific constantpool values for external
+/// symbols.
+class XtensaConstantPoolSymbol : public XtensaConstantPoolValue {
+  const std::string S; // ExtSymbol being loaded.
+  bool PrivateLinkage;
+
+  XtensaConstantPoolSymbol(
+      LLVMContext &C, const char *s, unsigned id, bool AddCurrentAddress,
+      bool PrivLinkage,
+      XtensaCP::XtensaCPModifier Modifier = XtensaCP::no_modifier);
+
+public:
+  static XtensaConstantPoolSymbol *
+  Create(LLVMContext &C, const char *s, unsigned ID, bool PrivLinkage,
+         XtensaCP::XtensaCPModifier Modifier = XtensaCP::no_modifier);
+
+  const char *getSymbol() const { return S.c_str(); }
+
+  int getExistingMachineCPValue(MachineConstantPool *CP,
+                                unsigned Alignment) override;
+
+  void addSelectionDAGCSEId(FoldingSetNodeID &ID) override;
+
+  /// hasSameValue - Return true if this Xtensa constpool value can share the
+  /// same constantpool entry as another Xtensa constpool value.
+  bool hasSameValue(XtensaConstantPoolValue *ACPV) override;
+
+  bool isPrivateLinkage() { return PrivateLinkage; }
+
+  void print(raw_ostream &O) const override;
+
+  static bool classof(const XtensaConstantPoolValue *ACPV) {
+    return ACPV->isExtSymbol();
+  }
+
+  bool equals(const XtensaConstantPoolSymbol *A) const {
+    return S == A->S && XtensaConstantPoolValue::equals(A);
+  }
+};
+
+/// XtensaConstantPoolMBB - Xtensa-specific constantpool value of a machine
+/// basic block.
+class XtensaConstantPoolMBB : public XtensaConstantPoolValue {
+  const MachineBasicBlock *MBB; // Machine basic block.
+
+  XtensaConstantPoolMBB(LLVMContext &C, const MachineBasicBlock *mbb,
+                        unsigned id);
+
+public:
+  static XtensaConstantPoolMBB *
+  Create(LLVMContext &C, const MachineBasicBlock *mbb, unsigned ID);
+
+  const MachineBasicBlock *getMBB() const { return MBB; }
+
+  int getExistingMachineCPValue(MachineConstantPool *CP,
+                                unsigned Alignment) override;
+
+  void addSelectionDAGCSEId(FoldingSetNodeID &ID) override;
+
+  /// hasSameValue - Return true if this Xtensa constpool value can share the
+  /// same constantpool entry as another Xtensa constpool value.
+  bool hasSameValue(XtensaConstantPoolValue *ACPV) override;
+
+  void print(raw_ostream &O) const override;
+
+  static bool classof(const XtensaConstantPoolValue *ACPV) {
+    return ACPV->isMachineBasicBlock();
+  }
+
+  bool equals(const XtensaConstantPoolMBB *A) const {
+    return MBB == A->MBB && XtensaConstantPoolValue::equals(A);
+  }
+};
+
+/// XtensaConstantPoolJumpTable - Xtensa-specific constantpool values for Jump
+/// Table symbols.
+class XtensaConstantPoolJumpTable : public XtensaConstantPoolValue {
+  unsigned IDX; // Jump Table Index.
+
+  XtensaConstantPoolJumpTable(LLVMContext &C, unsigned idx);
+
+public:
+  static XtensaConstantPoolJumpTable *Create(LLVMContext &C, unsigned idx);
+
+  unsigned getIndex() const { return IDX; }
+
+  int getExistingMachineCPValue(MachineConstantPool *CP,
+                                unsigned Alignment) override;
+
+  void addSelectionDAGCSEId(FoldingSetNodeID &ID) override;
+
+  /// hasSameValue - Return true if this Xtensa constpool value can share the
+  /// same constantpool entry as another Xtensa constpool value.
+  bool hasSameValue(XtensaConstantPoolValue *ACPV) override;
+
+  void print(raw_ostream &O) const override;
+
+  static bool classof(const XtensaConstantPoolValue *ACPV) {
+    return ACPV->isJumpTable();
+  }
+
+  bool equals(const XtensaConstantPoolJumpTable *A) const {
+    return IDX == A->IDX && XtensaConstantPoolValue::equals(A);
+  }
+};
+
+} // namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSACONSTANTPOOLVALUE_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaDSPInstrInfo.td
@@ -0,0 +1,497 @@
+//===- XtensaDSPInstrInfo.td - Xtensa Target Description ---*- tablegen -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file describes the Xtensa DSP instructions in TableGen format.
+//
+//===----------------------------------------------------------------------===//
+
+// Multiply
+class UMUL_AA<bits<4> oper1, string instrAsm, SDPatternOperator opNode, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x07, (outs), (ins AR:$s, AR:$t),
+               instrAsm#"\t$s, $t",
+             [(opNode AR:$s, AR:$t)]>, Requires<[HasMAC16]>
+{
+  let r = 0;
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def UMUL_AA_LL: UMUL_AA<0x00, "umul.aa.ll", int_xtensa_umul_aa_ll>;
+def UMUL_AA_HL: UMUL_AA<0x01, "umul.aa.hl", int_xtensa_umul_aa_hl>;
+def UMUL_AA_LH: UMUL_AA<0x02, "umul.aa.lh", int_xtensa_umul_aa_lh>;
+def UMUL_AA_HH: UMUL_AA<0x03, "umul.aa.hh", int_xtensa_umul_aa_hh>;
+
+class MUL_AA<bits<4> oper1, string instrAsm, SDPatternOperator opNode, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x07, (outs), (ins AR:$s, AR:$t),
+               instrAsm#"\t$s, $t",
+              [(opNode AR:$s, AR:$t)]>, Requires<[HasMAC16]>
+{
+  let r = 0;
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MUL_AA_LL: MUL_AA<0x04, "mul.aa.ll", int_xtensa_mul_aa_ll>;
+def MUL_AA_HL: MUL_AA<0x05, "mul.aa.hl", int_xtensa_mul_aa_hl>;
+def MUL_AA_LH: MUL_AA<0x06, "mul.aa.lh", int_xtensa_mul_aa_lh>;
+def MUL_AA_HH: MUL_AA<0x07, "mul.aa.hh", int_xtensa_mul_aa_hh>;
+
+class MUL_AD<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x03, (outs), (ins AR:$s, MR23:$y),
+               instrAsm#"\t$s, $y", []>, Requires<[HasMAC16]>
+{
+  bits<2> y;
+
+  let r = 0;
+  let t{3} = 0;
+  let t{2} = y{0};
+  let t{1-0} = 0;
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MUL_AD_LL: MUL_AD<0x04, "mul.ad.ll">;
+def MUL_AD_HL: MUL_AD<0x05, "mul.ad.hl">;
+def MUL_AD_LH: MUL_AD<0x06, "mul.ad.lh">;
+def MUL_AD_HH: MUL_AD<0x07, "mul.ad.hh">;
+
+class MUL_DA<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x06, (outs), (ins MR01:$x, AR:$t),
+               instrAsm#"\t$x, $t", []>, Requires<[HasMAC16]>
+{
+  bits<2> x;
+
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = 0;
+  let s = 0;
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MUL_DA_LL: MUL_DA<0x04, "mul.da.ll">;
+def MUL_DA_HL: MUL_DA<0x05, "mul.da.hl">;
+def MUL_DA_LH: MUL_DA<0x06, "mul.da.lh">;
+def MUL_DA_HH: MUL_DA<0x07, "mul.da.hh">;
+
+class MUL_DD<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x02, (outs), (ins MR01:$x, MR23:$y),
+               instrAsm#"\t$x, $y", []>, Requires<[HasMAC16]>
+{
+  bits<2> x;
+  bits<2> y;
+
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = 0;
+  let s = 0;
+  let t{3} = 0;
+  let t{2} = y{0};
+  let t{1-0} = 0;
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MUL_DD_LL: MUL_DD<0x04, "mul.dd.ll">;
+def MUL_DD_HL: MUL_DD<0x05, "mul.dd.hl">;
+def MUL_DD_LH: MUL_DD<0x06, "mul.dd.lh">;
+def MUL_DD_HH: MUL_DD<0x07, "mul.dd.hh">;
+
+class MULA_AA<bits<4> oper1, string instrAsm, SDPatternOperator opNode, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x07, (outs), (ins AR:$s, AR:$t),
+               instrAsm#"\t$s, $t",
+              [(opNode AR:$s, AR:$t)]>, Requires<[HasMAC16]> 
+{
+  let r = 0;
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULA_AA_LL: MULA_AA<0x08, "mula.aa.ll", int_xtensa_mula_aa_ll>;
+def MULA_AA_HL: MULA_AA<0x09, "mula.aa.hl", int_xtensa_mula_aa_hl>;
+def MULA_AA_LH: MULA_AA<0x0A, "mula.aa.lh", int_xtensa_mula_aa_lh>;
+def MULA_AA_HH: MULA_AA<0x0B, "mula.aa.hh", int_xtensa_mula_aa_hh>;
+
+class MULA_AD<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x03, (outs), (ins AR:$s, MR23:$y),
+               instrAsm#"\t$s, $y", []>, Requires<[HasMAC16]> 
+{
+  bits<2> y;
+
+  let r = 0;
+  let t{3} = 0;
+  let t{2} = y{0};
+  let t{1-0} = 0;
+
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULA_AD_LL: MULA_AD<0x08, "mula.ad.ll">;
+def MULA_AD_HL: MULA_AD<0x09, "mula.ad.hl">;
+def MULA_AD_LH: MULA_AD<0x0A, "mula.ad.lh">;
+def MULA_AD_HH: MULA_AD<0x0B, "mula.ad.hh">;
+
+class MULA_DA<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x06, (outs), (ins MR01:$x, AR:$t),
+               instrAsm#"\t$x, $t", []>, Requires<[HasMAC16]> 
+{
+  bits<2> x;
+
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = 0;
+  let s = 0;
+
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULA_DA_LL: MULA_DA<0x08, "mula.da.ll">;
+def MULA_DA_HL: MULA_DA<0x09, "mula.da.hl">;
+def MULA_DA_LH: MULA_DA<0x0A, "mula.da.lh">;
+def MULA_DA_HH: MULA_DA<0x0B, "mula.da.hh">;
+
+class MULA_DD<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x02, (outs), (ins MR01:$x, MR23:$y),
+               instrAsm#"\t$x, $y", []>, Requires<[HasMAC16]> 
+{
+  bits<2> x;
+  bits<2> y;
+
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = 0;
+  let s = 0;
+  let t{3} = 0;
+  let t{2} = y{0};
+  let t{1-0} = 0;
+
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULA_DD_LL: MULA_DD<0x08, "mula.dd.ll">;
+def MULA_DD_HL: MULA_DD<0x09, "mula.dd.hl">;
+def MULA_DD_LH: MULA_DD<0x0A, "mula.dd.lh">;
+def MULA_DD_HH: MULA_DD<0x0B, "mula.dd.hh">;
+
+class MULS_AA<bits<4> oper1, string instrAsm, SDPatternOperator opNode, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x07, (outs), (ins AR:$s, AR:$t),
+               instrAsm#"\t$s, $t",
+              [(opNode AR:$s, AR:$t)]>, Requires<[HasMAC16]> 
+{
+  let r = 0;
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULS_AA_LL: MULS_AA<0x0C, "muls.aa.ll", int_xtensa_muls_aa_ll>;
+def MULS_AA_HL: MULS_AA<0x0D, "muls.aa.hl", int_xtensa_muls_aa_hl>;
+def MULS_AA_LH: MULS_AA<0x0E, "muls.aa.lh", int_xtensa_muls_aa_lh>;
+def MULS_AA_HH: MULS_AA<0x0F, "muls.aa.hh", int_xtensa_muls_aa_hh>;
+
+class MULS_AD<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x03, (outs), (ins AR:$s, MR23:$y),
+               instrAsm#"\t$s, $y", []>, Requires<[HasMAC16]> 
+{
+  bits<2> y;
+
+  let r = 0;
+  let t{3} = 0;
+  let t{2} = y{0};
+  let t{1-0} = 0;
+
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULS_AD_LL: MULS_AD<0x0C, "muls.ad.ll">;
+def MULS_AD_HL: MULS_AD<0x0D, "muls.ad.hl">;
+def MULS_AD_LH: MULS_AD<0x0E, "muls.ad.lh">;
+def MULS_AD_HH: MULS_AD<0x0F, "muls.ad.hh">;
+
+class MULS_DA<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x06, (outs), (ins MR01:$x, AR:$t),
+               instrAsm#"\t$x, $t", []>, Requires<[HasMAC16]> 
+{
+  bits<2> x;
+
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = 0;
+  let s = 0;
+
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULS_DA_LL: MULS_DA<0x0C, "muls.da.ll">;
+def MULS_DA_HL: MULS_DA<0x0D, "muls.da.hl">;
+def MULS_DA_LH: MULS_DA<0x0E, "muls.da.lh">;
+def MULS_DA_HH: MULS_DA<0x0F, "muls.da.hh">;
+
+class MULS_DD<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x02, (outs), (ins MR01:$x, MR23:$y),
+               instrAsm#"\t$x, $y", []>, Requires<[HasMAC16]> 
+{
+  bits<2> x;
+  bits<2> y;
+
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = 0;
+  let s = 0;
+  let t{3} = 0;
+  let t{2} = y{0};
+  let t{1-0} = 0;
+
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULS_DD_LL: MULS_DD<0x0C, "muls.dd.ll">;
+def MULS_DD_HL: MULS_DD<0x0D, "muls.dd.hl">;
+def MULS_DD_LH: MULS_DD<0x0E, "muls.dd.lh">;
+def MULS_DD_HH: MULS_DD<0x0F, "muls.dd.hh">;
+
+//===----------------------------------------------------------------------===//
+// Multiply-accumulate with load
+
+class MULA_DA_LDDEC<bits<4> oper1, string instrAsm, bit isComm = 0>
+  : RRR_Inst<0x04, oper1, 0x05, (outs MR:$w, AR:$d), (ins AR:$s, MR01:$x, AR:$t),
+             instrAsm#"\t $w, $s, $x, $t", []>, Requires<[HasMAC16]>
+{
+  bits<2> x;
+  bits<2> w;
+
+  let Constraints = "$s = $d";
+  let mayLoad = 1;
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = w{1-0};
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULA_DA_LL_LDDEC: MULA_DA_LDDEC<0x08, "mula.da.ll.lddec">;
+def MULA_DA_HL_LDDEC: MULA_DA_LDDEC<0x09, "mula.da.hl.lddec">;
+def MULA_DA_LH_LDDEC: MULA_DA_LDDEC<0x0A, "mula.da.lh.lddec">;
+def MULA_DA_HH_LDDEC: MULA_DA_LDDEC<0x0B, "mula.da.hh.lddec">;
+
+let usesCustomInserter = 1, Predicates = [HasMAC16] in
+{
+	def MULA_DA_LL_LDDEC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, AR:$t),
+                                  "!xtensa_mula_da_ll_lddec_p, $mw, $s, $mx, $t",
+                                  [(int_xtensa_mula_da_ll_lddec timm:$mw, AR:$s, timm:$mx, AR:$t)]>;
+	def MULA_DA_HL_LDDEC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, AR:$t),
+                                  "!xtensa_mula_da_hl_lddec_p, $mw, $s, $mx, $t",
+                                  [(int_xtensa_mula_da_hl_lddec timm:$mw, AR:$s, timm:$mx, AR:$t)]>;
+	def MULA_DA_LH_LDDEC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, AR:$t),
+                                  "!xtensa_mula_da_lh_lddec_p, $mw, $s, $mx, $t",
+                                  [(int_xtensa_mula_da_lh_lddec timm:$mw, AR:$s, timm:$mx, AR:$t)]>;
+	def MULA_DA_HH_LDDEC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, AR:$t),
+                                  "!xtensa_mula_da_hh_lddec_p, $mw, $s, $mx, $t",
+                                  [(int_xtensa_mula_da_hh_lddec timm:$mw, AR:$s, timm:$mx, AR:$t)]>;
+}
+
+class MULA_DA_LDINC<bits<4> oper1, string instrAsm, bit isComm = 0>
+  : RRR_Inst<0x04, oper1, 0x04, (outs MR:$w, AR:$d), (ins AR:$s, MR:$x, AR:$t),
+             instrAsm#"\t $w, $s, $x, $t", []>, Requires<[HasMAC16]>
+{
+  bits<1> x;
+  bits<2> w;
+
+  let Constraints = "$s = $d";
+  let mayLoad = 1;
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = w{1-0};
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULA_DA_LL_LDINC: MULA_DA_LDINC<0x08, "mula.da.ll.ldinc">;
+def MULA_DA_HL_LDINC: MULA_DA_LDINC<0x09, "mula.da.hl.ldinc">;
+def MULA_DA_LH_LDINC: MULA_DA_LDINC<0x0A, "mula.da.lh.ldinc">;
+def MULA_DA_HH_LDINC: MULA_DA_LDINC<0x0B, "mula.da.hh.ldinc">;
+
+let usesCustomInserter = 1, Predicates = [HasMAC16] in
+{
+	def MULA_DA_LL_LDINC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, AR:$t),
+                                  "!xtensa_mula_da_ll_ldinc_p, $mw, $s, $mx, $t",
+                                  [(int_xtensa_mula_da_ll_ldinc timm:$mw, AR:$s, timm:$mx, AR:$t)]>;
+	def MULA_DA_HL_LDINC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, AR:$t),
+                                  "!xtensa_mula_da_hl_ldinc_p, $mw, $s, $mx, $t",
+                                  [(int_xtensa_mula_da_hl_ldinc timm:$mw, AR:$s, timm:$mx, AR:$t)]>;
+	def MULA_DA_LH_LDINC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, AR:$t),
+                                  "!xtensa_mula_da_lh_ldinc_p, $mw, $s, $mx, $t",
+                                  [(int_xtensa_mula_da_lh_ldinc timm:$mw, AR:$s, timm:$mx, AR:$t)]>;
+	def MULA_DA_HH_LDINC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, AR:$t),
+                                  "!xtensa_mula_da_hh_ldinc_p, $mw, $s, $mx, $t",
+                                  [(int_xtensa_mula_da_hh_ldinc timm:$mw, AR:$s, timm:$mx, AR:$t)]>;
+}
+
+class MULA_DD_LDDEC<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x01, (outs MR:$w, AR:$d), (ins AR:$s, MR01:$x, MR23:$y),
+               instrAsm#"\t $w, $s, $x, $y", []>, Requires<[HasMAC16]>
+{
+  bits<2> x;
+  bits<2> y;
+  bits<2> w;
+
+  let Constraints = "$s = $d";
+  let mayLoad = 1;
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = w{1-0};
+  let t{3} = 0;
+  let t{2} = y{0};
+  let t{1-0} = 0;
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULA_DD_LL_LDDEC: MULA_DD_LDDEC<0x08, "mula.dd.ll.lddec">;
+def MULA_DD_HL_LDDEC: MULA_DD_LDDEC<0x09, "mula.dd.hl.lddec">;
+def MULA_DD_LH_LDDEC: MULA_DD_LDDEC<0x0A, "mula.dd.lh.lddec">;
+def MULA_DD_HH_LDDEC: MULA_DD_LDDEC<0x0B, "mula.dd.hh.lddec">;
+
+let usesCustomInserter = 1, Predicates = [HasMAC16] in
+{
+	def MULA_DD_LL_LDDEC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, imm8:$my),
+                                  "!xtensa_mula_dd_ll_lddec_p, $mw, $s, $mx, $my",
+                                  [(int_xtensa_mula_dd_ll_lddec timm:$mw, AR:$s, timm:$mx, timm:$my)]>;
+	def MULA_DD_HL_LDDEC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, imm8:$my),
+                                  "!xtensa_mula_dd_hl_lddec_p, $mw, $s, $mx, $my",
+                                  [(int_xtensa_mula_dd_hl_lddec timm:$mw, AR:$s, timm:$mx, timm:$my)]>;
+	def MULA_DD_LH_LDDEC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, imm8:$my),
+                                  "!xtensa_mula_dd_lh_lddec_p, $mw, $s, $mx, $my",
+                                  [(int_xtensa_mula_dd_lh_lddec timm:$mw, AR:$s, timm:$mx, timm:$my)]>;
+	def MULA_DD_HH_LDDEC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, imm8:$my),
+                                  "!xtensa_mula_dd_hh_lddec_p, $mw, $s, $mx, $my",
+                                  [(int_xtensa_mula_dd_hh_lddec timm:$mw, AR:$s, timm:$mx, timm:$my)]>;
+}
+
+class MULA_DD_LDINC<bits<4> oper1, string instrAsm, bit isComm = 0>
+    : RRR_Inst<0x04, oper1, 0x00, (outs MR:$w, AR:$d), (ins AR:$s, MR01:$x, MR23:$y),
+               instrAsm#"\t $w, $s, $x, $y", []>, Requires<[HasMAC16]>
+{
+  bits<2> x;
+  bits<2> y;
+  bits<2> w;
+
+  let Constraints = "$s = $d";
+  let mayLoad = 1;
+  let r{3} = 0;
+  let r{2} = x{0};
+  let r{1-0} = w{1-0};
+  let t{3} = 0;
+  let t{2} = y{0};
+  let t{1-0} = 0;
+  let Uses = [ACCLO, ACCHI];
+  let Defs = [M1, M2, ACCLO, ACCHI];
+}
+
+def MULA_DD_LL_LDINC: MULA_DD_LDINC<0x08, "mula.dd.ll.ldinc">;
+def MULA_DD_HL_LDINC: MULA_DD_LDINC<0x09, "mula.dd.hl.ldinc">;
+def MULA_DD_LH_LDINC: MULA_DD_LDINC<0x0A, "mula.dd.lh.ldinc">;
+def MULA_DD_HH_LDINC: MULA_DD_LDINC<0x0B, "mula.dd.hh.ldinc">;
+
+let usesCustomInserter = 1, Predicates = [HasMAC16] in
+{
+	def MULA_DD_LL_LDINC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, imm8:$my),
+                                  "!xtensa_mula_dd_ll_ldinc_p, $mw, $s, $mx, $my",
+                                  [(int_xtensa_mula_dd_ll_ldinc timm:$mw, AR:$s, timm:$mx, timm:$my)]>;
+	def MULA_DD_HL_LDINC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, imm8:$my),
+                                  "!xtensa_mula_dd_hl_ldinc_p, $mw, $s, $mx, $my",
+                                  [(int_xtensa_mula_dd_hl_ldinc timm:$mw, AR:$s, timm:$mx, timm:$my)]>;
+	def MULA_DD_LH_LDINC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, imm8:$my),
+                                  "!xtensa_mula_dd_lh_ldinc_p, $mw, $s, $mx, $my",
+                                  [(int_xtensa_mula_dd_lh_ldinc timm:$mw, AR:$s, timm:$mx, timm:$my)]>;
+	def MULA_DD_HH_LDINC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s, imm8:$mx, imm8:$my),
+                                  "!xtensa_mula_dd_hh_ldinc_p, $mw, $s, $mx, $my",
+                                  [(int_xtensa_mula_dd_hh_ldinc timm:$mw, AR:$s, timm:$mx, timm:$my)]>;
+}
+
+def LDDEC:  RRR_Inst<0x04, 0x00, 0x09, (outs MR:$w, AR:$d), (ins AR:$s),
+                    "lddec\t $w, $s", []>, Requires<[HasMAC16]>
+{
+  bits<2> w;
+
+  let Constraints = "$s = $d";
+  let mayLoad = 1;
+  let r{3-2} = 0;
+  let r{1-0} = w{1-0};
+  let t = 0x00;
+}
+
+def LDINC:  RRR_Inst<0x04, 0x00, 0x08, (outs MR:$w, AR:$d), (ins AR:$s),
+                    "ldinc\t $w, $s", []>, Requires<[HasMAC16]>
+{
+  bits<2> w;
+
+  let Constraints = "$s = $d";
+  let mayLoad = 1;
+  let r{3-2} = 0;
+  let r{1-0} = w{1-0};
+  let t = 0;
+}
+
+let usesCustomInserter = 1, Predicates = [HasMAC16] in
+{
+	def LDDEC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s),
+                       "!xtensa_lddec_p, $mw, $s",
+                       [(int_xtensa_lddec timm:$mw, AR:$s)]>;
+	def LDINC_P: Pseudo<(outs), (ins imm8:$mw, AR:$s),
+                       "!xtensa_ldinc_p, $mw, $s",
+                       [(int_xtensa_ldinc timm:$mw, AR:$s)]>;
+}
+
+def : Pat<(i32 (int_xtensa_rsr_acclo)), (RSR ACCLO)>;
+def : Pat<(i32 (int_xtensa_rsr_acchi)), (RSR ACCHI)>;
+def : Pat<(i32 (int_xtensa_rsr_m0)), (RSR M0)>;
+def : Pat<(i32 (int_xtensa_rsr_m1)), (RSR M1)>;
+def : Pat<(i32 (int_xtensa_rsr_m2)), (RSR M2)>;
+def : Pat<(i32 (int_xtensa_rsr_m3)), (RSR M3)>;
+
+let usesCustomInserter = 1, Predicates = [HasMAC16] in
+{
+	def XSR_ACCLO_P: Pseudo<(outs), (ins AR:$s),
+                           "!xtensa_xsr_acclo_p, $s",
+                           [(int_xtensa_xsr_acclo AR:$s)]>;
+	def XSR_ACCHI_P: Pseudo<(outs), (ins AR:$s),
+                           "!xtensa_xsr_acchi_p, $s",
+                           [(int_xtensa_xsr_acchi AR:$s)]>;
+	def XSR_M0_P: Pseudo<(outs), (ins AR:$s),
+                        "!xtensa_xsr_m0_p, $s",
+                        [(int_xtensa_xsr_m0 AR:$s)]>;
+	def XSR_M1_P: Pseudo<(outs), (ins AR:$s),
+                        "!xtensa_xsr_m1_p, $s",
+                        [(int_xtensa_xsr_m1 AR:$s)]>;
+	def XSR_M2_P: Pseudo<(outs), (ins AR:$s),
+                        "!xtensa_xsr_m2_p, $s",
+                        [(int_xtensa_xsr_m2 AR:$s)]>;
+	def XSR_M3_P: Pseudo<(outs), (ins AR:$s),
+                        "!xtensa_xsr_m3_p, $s",
+                        [(int_xtensa_xsr_m3 AR:$s)]>;
+	def WSR_ACCLO_P: Pseudo<(outs), (ins AR:$s),
+                           "!xtensa_wsr_acclo_p, $s",
+                           [(int_xtensa_wsr_acclo AR:$s)]>;
+	def WSR_ACCHI_P: Pseudo<(outs), (ins AR:$s),
+                           "!xtensa_wsr_acchi_p, $s",
+                           [(int_xtensa_wsr_acchi AR:$s)]>;
+	def WSR_M0_P: Pseudo<(outs), (ins AR:$s),
+                        "!xtensa_wsr_m0_p, $s",
+                        [(int_xtensa_wsr_m0 AR:$s)]>;
+	def WSR_M1_P: Pseudo<(outs), (ins AR:$s),
+                        "!xtensa_wsr_m1_p, $s",
+                        [(int_xtensa_wsr_m1 AR:$s)]>;
+	def WSR_M2_P: Pseudo<(outs), (ins AR:$s),
+                        "!xtensa_wsr_m2_p, $s",
+                        [(int_xtensa_wsr_m2 AR:$s)]>;
+	def WSR_M3_P: Pseudo<(outs), (ins AR:$s),
+                        "!xtensa_wsr_m3_p, $s",
+                        [(int_xtensa_wsr_m3 AR:$s)]>;
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaFrameLowering.cpp
@@ -0,0 +1,376 @@
+//===- XtensaFrameLowering.cpp - Xtensa Frame Information -----------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains the Xtensa implementation of TargetFrameLowering class.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaFrameLowering.h"
+#include "XtensaInstrInfo.h"
+#include "XtensaSubtarget.h"
+#include "llvm/CodeGen/MachineInstrBuilder.h"
+#include "llvm/CodeGen/MachineModuleInfo.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/CodeGen/RegisterScavenging.h"
+#include "llvm/IR/Function.h"
+
+using namespace llvm;
+
+XtensaFrameLowering::XtensaFrameLowering()
+    : TargetFrameLowering(TargetFrameLowering::StackGrowsDown, Align(4), 0,
+                          Align(4)) {}
+
+/*   Xtensa stack frames look like:
+
+    +-------------------------------+
+    |  incoming stack arguments     |
+    +-------------------------------+
+  A |  caller-allocated save area   |
+    |  for register arguments       |
+    +-------------------------------+ <-- incoming stack pointer
+  B | CALL0 ABI:                    |
+    |  callee-allocated save area   |
+    |  for arguments that are       |
+    |  split between registers and  |
+    |  the stack (Register-Spill    |
+    |  Area)                        |
+    |                               |
+    | Win ABI:                      |
+    |  Register-Spill Overflow      |
+    |  8 words for CALL8/CALLX8     |
+    +-------------------------------+ <-- arg_pointer_rtx
+  C |  callee-allocated save area   |
+    |  for register varargs         |
+    +-------------------------------+ <-- hard_frame_pointer_rtx;
+    |                               |     stack_pointer_rtx + gp_sp_offset
+    |  GPR save area                |       + UNITS_PER_WORD
+    +-------------------------------+ <-- stack_pointer_rtx + fp_sp_offset
+    |                               |       + UNITS_PER_HWVALUE
+    |  FPR save area                |
+    +-------------------------------+ <-- frame_pointer_rtx (virtual)
+    |  local variables              |
+  P +-------------------------------+
+    |  outgoing stack arguments     |
+    +-------------------------------+
+    |  caller-allocated save area   |
+    |  for register arguments       |
+    +-------------------------------+ <-- stack_pointer_rtx
+
+   At least two of A, B and C will be empty.
+
+   Dynamic stack allocations such as alloca insert data at point P.
+   They decrease stack_pointer_rtx but leave frame_pointer_rtx and
+   hard_frame_pointer_rtx unchanged.  */
+
+// hasFP - Return true if the specified function should have a dedicated frame
+// pointer register.  This is true if the function has variable sized allocas or
+// if frame pointer elimination is disabled.
+bool XtensaFrameLowering::hasFP(const MachineFunction &MF) const {
+  const MachineFrameInfo &MFI = MF.getFrameInfo();
+  return MF.getTarget().Options.DisableFramePointerElim(MF) ||
+         MFI.hasVarSizedObjects();
+}
+
+/* minimum frame = reg save area (4 words) plus static chain (1 word)
+   and the total number of words must be a multiple of 128 bits.  */
+/* Width of a word, in units (bytes).  */
+#define UNITS_PER_WORD 4
+#define MIN_FRAME_SIZE (8 * UNITS_PER_WORD)
+
+void XtensaFrameLowering::emitPrologue(MachineFunction &MF,
+                                       MachineBasicBlock &MBB) const {
+  assert(&MBB == &MF.front() && "Shrink-wrapping not yet implemented");
+  MachineFrameInfo &MFI = MF.getFrameInfo();
+  const XtensaRegisterInfo *RegInfo = static_cast<const XtensaRegisterInfo *>(
+      MF.getSubtarget().getRegisterInfo());
+  const XtensaInstrInfo &TII =
+      *static_cast<const XtensaInstrInfo *>(MF.getSubtarget().getInstrInfo());
+  MachineBasicBlock::iterator MBBI = MBB.begin();
+  const XtensaSubtarget &STI = MF.getSubtarget<XtensaSubtarget>();
+  DebugLoc dl = MBBI != MBB.end() ? MBBI->getDebugLoc() : DebugLoc();
+  unsigned SP = Xtensa::SP;
+  unsigned FP = RegInfo->getFrameRegister(MF);
+  MachineModuleInfo &MMI = MF.getMMI();
+  const MCRegisterInfo *MRI = MMI.getContext().getRegisterInfo();
+
+  // First, compute final stack size.
+  uint64_t StackSize = MFI.getStackSize();
+  uint64_t PrevStackSize = StackSize;
+
+  if (STI.isWinABI()) {
+    StackSize += 32;
+    // Round up StackSize to 8*N
+    StackSize += (8 - StackSize) & 0x7;
+    if (StackSize <= 32760) {
+      BuildMI(MBB, MBBI, dl, TII.get(Xtensa::ENTRY))
+          .addReg(SP)
+          .addImm(StackSize);
+    } else {
+      /* Use a8 as a temporary since a0-a7 may be live.  */
+      unsigned TmpReg = Xtensa::A8;
+
+      const XtensaInstrInfo &TII = *static_cast<const XtensaInstrInfo *>(
+          MBB.getParent()->getSubtarget().getInstrInfo());
+      BuildMI(MBB, MBBI, dl, TII.get(Xtensa::ENTRY))
+          .addReg(SP)
+          .addImm(MIN_FRAME_SIZE);
+      TII.loadImmediate(MBB, MBBI, &TmpReg, StackSize - MIN_FRAME_SIZE);
+      BuildMI(MBB, MBBI, dl, TII.get(Xtensa::SUB), TmpReg)
+          .addReg(SP)
+          .addReg(TmpReg);
+      BuildMI(MBB, MBBI, dl, TII.get(Xtensa::MOVSP), SP).addReg(TmpReg);
+    }
+
+    // Store FP register in A8, because FP may be used to pass function
+    // arguments
+    BuildMI(MBB, MBBI, dl, TII.get(Xtensa::OR), Xtensa::A8)
+        .addReg(FP)
+        .addReg(FP);
+
+    // if framepointer enabled, set it to point to the stack pointer.
+    if (hasFP(MF)) {
+      // Insert instruction "move $fp, $sp" at this location.
+      BuildMI(MBB, MBBI, dl, TII.get(Xtensa::OR), FP)
+          .addReg(SP)
+          .addReg(SP)
+          .setMIFlag(MachineInstr::FrameSetup);
+
+      MCCFIInstruction Inst = MCCFIInstruction::createDefCfa(
+          nullptr, MRI->getDwarfRegNum(FP, true), -StackSize);
+      unsigned CFIIndex = MF.addFrameInst(Inst);
+      BuildMI(MBB, MBBI, dl, TII.get(TargetOpcode::CFI_INSTRUCTION))
+          .addCFIIndex(CFIIndex);
+    } else {
+      // emit ".cfi_def_cfa_offset StackSize"
+      unsigned CFIIndex = MF.addFrameInst(
+          MCCFIInstruction::createDefCfaOffset(nullptr, -StackSize));
+      BuildMI(MBB, MBBI, dl, TII.get(TargetOpcode::CFI_INSTRUCTION))
+          .addCFIIndex(CFIIndex);
+    }
+  } else {
+    // No need to allocate space on the stack.
+    if (StackSize == 0 && !MFI.adjustsStack())
+      return;
+
+    // Adjust stack.
+    TII.adjustStackPtr(SP, -StackSize, MBB, MBBI);
+
+    // emit ".cfi_def_cfa_offset StackSize"
+    unsigned CFIIndex = MF.addFrameInst(
+        MCCFIInstruction::createDefCfaOffset(nullptr, -StackSize));
+    BuildMI(MBB, MBBI, dl, TII.get(TargetOpcode::CFI_INSTRUCTION))
+        .addCFIIndex(CFIIndex);
+
+    const std::vector<CalleeSavedInfo> &CSI = MFI.getCalleeSavedInfo();
+
+    if (CSI.size()) {
+      // Find the instruction past the last instruction that saves a
+      // callee-saved register to the stack.
+      for (unsigned i = 0; i < CSI.size(); ++i)
+        ++MBBI;
+
+      // Iterate over list of callee-saved registers and emit .cfi_offset
+      // directives.
+      for (const auto &I : CSI) {
+        int64_t Offset = MFI.getObjectOffset(I.getFrameIdx());
+        unsigned Reg = I.getReg();
+
+        unsigned CFIIndex = MF.addFrameInst(MCCFIInstruction::createOffset(
+            nullptr, MRI->getDwarfRegNum(Reg, 1), Offset));
+        BuildMI(MBB, MBBI, dl, TII.get(TargetOpcode::CFI_INSTRUCTION))
+            .addCFIIndex(CFIIndex);
+      }
+    }
+
+    // if framepointer enabled, set it to point to the stack pointer.
+    if (hasFP(MF)) {
+      // Insert instruction "move $fp, $sp" at this location.
+      BuildMI(MBB, MBBI, dl, TII.get(Xtensa::OR), FP)
+          .addReg(SP)
+          .addReg(SP)
+          .setMIFlag(MachineInstr::FrameSetup);
+
+      // emit ".cfi_def_cfa_register $fp"
+      unsigned CFIIndex =
+          MF.addFrameInst(MCCFIInstruction::createDefCfaRegister(
+              nullptr, MRI->getDwarfRegNum(FP, true)));
+      BuildMI(MBB, MBBI, dl, TII.get(TargetOpcode::CFI_INSTRUCTION))
+          .addCFIIndex(CFIIndex);
+    }
+  }
+
+  if (StackSize != PrevStackSize) {
+    MFI.setStackSize(StackSize);
+
+    for (int i = MFI.getObjectIndexBegin(); i < MFI.getObjectIndexEnd(); i++) {
+      if (!MFI.isDeadObjectIndex(i)) {
+        int64_t SPOffset = MFI.getObjectOffset(i);
+        //        errs() << "SPOffset = " + SPOffset << "\n";
+        if (SPOffset < 0)
+          MFI.setObjectOffset(i, SPOffset - StackSize + PrevStackSize);
+      }
+    }
+  }
+}
+
+void XtensaFrameLowering::emitEpilogue(MachineFunction &MF,
+                                       MachineBasicBlock &MBB) const {
+  MachineBasicBlock::iterator MBBI = MBB.getLastNonDebugInstr();
+  MachineFrameInfo &MFI = MF.getFrameInfo();
+  const XtensaRegisterInfo *RegInfo = static_cast<const XtensaRegisterInfo *>(
+      MF.getSubtarget().getRegisterInfo());
+  const XtensaInstrInfo &TII =
+      *static_cast<const XtensaInstrInfo *>(MF.getSubtarget().getInstrInfo());
+  const XtensaSubtarget &STI = MF.getSubtarget<XtensaSubtarget>();
+  DebugLoc dl = MBBI->getDebugLoc();
+  unsigned SP = Xtensa::SP;
+  unsigned FP = RegInfo->getFrameRegister(MF);
+
+  // if framepointer enabled, restore the stack pointer.
+  if (hasFP(MF)) {
+    // Find the first instruction that restores a callee-saved register.
+    MachineBasicBlock::iterator I = MBBI;
+
+    for (unsigned i = 0; i < MFI.getCalleeSavedInfo().size(); ++i)
+      --I;
+    if (STI.isWinABI()) {
+      // Insert instruction "movsp $sp, $fp" at this location.
+      BuildMI(MBB, I, dl, TII.get(Xtensa::MOVSP), SP).addReg(FP);
+    } else {
+      BuildMI(MBB, I, dl, TII.get(Xtensa::OR), SP).addReg(FP).addReg(FP);
+    }
+  }
+
+  if (STI.isWinABI())
+    return;
+
+  // Get the number of bytes from FrameInfo
+  uint64_t StackSize = MFI.getStackSize();
+
+  if (!StackSize)
+    return;
+
+  // Adjust stack.
+  TII.adjustStackPtr(SP, StackSize, MBB, MBBI);
+}
+
+bool XtensaFrameLowering::spillCalleeSavedRegisters(
+    MachineBasicBlock &MBB, MachineBasicBlock::iterator MI,
+    const std::vector<CalleeSavedInfo> &CSI,
+    const TargetRegisterInfo *TRI) const {
+  MachineFunction *MF = MBB.getParent();
+  const XtensaSubtarget &STI = MF->getSubtarget<XtensaSubtarget>();
+
+  if (STI.isWinABI())
+    return true;
+
+  MachineBasicBlock &EntryBlock = *(MF->begin());
+  const TargetInstrInfo &TII = *MF->getSubtarget().getInstrInfo();
+
+  for (unsigned i = 0, e = CSI.size(); i != e; ++i) {
+    // Add the callee-saved register as live-in. Do not add if the register is
+    // A0 and return address is taken, because it will be implemented in
+    // method XtensaTargetLowering::LowerRETURNADDR.
+    // It's killed at the spill, unless the register is RA and return address
+    // is taken.
+    unsigned Reg = CSI[i].getReg();
+    bool IsA0AndRetAddrIsTaken =
+        (Reg == Xtensa::A0) && MF->getFrameInfo().isReturnAddressTaken();
+    if (!IsA0AndRetAddrIsTaken)
+      EntryBlock.addLiveIn(Reg);
+
+    // Insert the spill to the stack frame.
+    bool IsKill = !IsA0AndRetAddrIsTaken;
+    const TargetRegisterClass *RC = TRI->getMinimalPhysRegClass(Reg);
+    TII.storeRegToStackSlot(EntryBlock, MI, Reg, IsKill, CSI[i].getFrameIdx(),
+                            RC, TRI);
+  }
+
+  return true;
+}
+
+bool XtensaFrameLowering::restoreCalleeSavedRegisters(
+    MachineBasicBlock &MBB, MachineBasicBlock::iterator MI,
+    std::vector<CalleeSavedInfo> &CSI, const TargetRegisterInfo *TRI) const {
+  MachineFunction *MF = MBB.getParent();
+  const XtensaSubtarget &STI = MF->getSubtarget<XtensaSubtarget>();
+  if (STI.isWinABI())
+    return true;
+  return TargetFrameLowering::restoreCalleeSavedRegisters(MBB, MI, CSI, TRI);
+}
+
+// Eliminate ADJCALLSTACKDOWN, ADJCALLSTACKUP pseudo instructions
+MachineBasicBlock::iterator XtensaFrameLowering::eliminateCallFramePseudoInstr(
+    MachineFunction &MF, MachineBasicBlock &MBB,
+    MachineBasicBlock::iterator I) const {
+  const XtensaInstrInfo &TII =
+      *static_cast<const XtensaInstrInfo *>(MF.getSubtarget().getInstrInfo());
+
+  if (!hasReservedCallFrame(MF)) {
+    int64_t Amount = I->getOperand(0).getImm();
+
+    if (I->getOpcode() == Xtensa::ADJCALLSTACKDOWN)
+      Amount = -Amount;
+
+    unsigned SP = Xtensa::SP;
+    TII.adjustStackPtr(SP, Amount, MBB, I);
+  }
+
+  return MBB.erase(I);
+}
+
+void XtensaFrameLowering::determineCalleeSaves(MachineFunction &MF,
+                                               BitVector &SavedRegs,
+                                               RegScavenger *RS) const {
+  const XtensaSubtarget &STI = MF.getSubtarget<XtensaSubtarget>();
+  MachineFrameInfo &MFI = MF.getFrameInfo();
+  const XtensaRegisterInfo *RegInfo = static_cast<const XtensaRegisterInfo *>(
+      MF.getSubtarget().getRegisterInfo());
+  unsigned FP = RegInfo->getFrameRegister(MF);
+
+  if (STI.isWinABI()) {
+    return;
+  }
+
+  TargetFrameLowering::determineCalleeSaves(MF, SavedRegs, RS);
+
+  // Mark $fp as used if function has dedicated frame pointer.
+  if (hasFP(MF))
+    SavedRegs.set(FP);
+
+  // Set scavenging frame index if necessary.
+  uint64_t MaxSPOffset = MFI.estimateStackSize(MF);
+
+  if (isInt<12>(MaxSPOffset))
+    return;
+
+  const TargetRegisterClass &RC = Xtensa::ARRegClass;
+  const TargetRegisterInfo *TRI = MF.getSubtarget().getRegisterInfo();
+  unsigned Size = TRI->getSpillSize(RC);
+  unsigned Align = TRI->getSpillAlignment(RC);
+  int FI = MF.getFrameInfo().CreateStackObject(Size, Align, false);
+  RS->addScavengingFrameIndex(FI);
+}
+
+void XtensaFrameLowering::processFunctionBeforeFrameFinalized(
+    MachineFunction &MF, RegScavenger *RS) const {
+  const XtensaSubtarget &STI = MF.getSubtarget<XtensaSubtarget>();
+
+  // In WinABI mode add register scavenging slot
+  // FIXME: It may be posssible to add spill slot by more optimal way
+  if (STI.isWinABI() && (MF.getFrameInfo().estimateStackSize(MF) > 256)) {
+    MachineFrameInfo &MFI = MF.getFrameInfo();
+    const TargetRegisterClass &RC = Xtensa::ARRegClass;
+    const TargetRegisterInfo &TRI = *MF.getSubtarget().getRegisterInfo();
+    unsigned Size = TRI.getSpillSize(RC);
+    unsigned Align = TRI.getSpillAlignment(RC);
+    RS->addScavengingFrameIndex(MFI.CreateStackObject(Size, Align, false));
+  }
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaFrameLowering.h
@@ -0,0 +1,54 @@
+//===- XtensaFrameLowering.h - Define frame lowering for Xtensa --*- C++ -*-==//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===-----------------------------------------------------------------------==//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSAFRAMELOWERING_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSAFRAMELOWERING_H
+
+#include "llvm/CodeGen/TargetFrameLowering.h"
+
+namespace llvm {
+class XtensaTargetMachine;
+class XtensaSubtarget;
+
+class XtensaFrameLowering : public TargetFrameLowering {
+public:
+  XtensaFrameLowering();
+
+  bool hasFP(const MachineFunction &MF) const override;
+
+  /// emitProlog/emitEpilog - These methods insert prolog and epilog code into
+  /// the function.
+  void emitPrologue(MachineFunction &, MachineBasicBlock &) const override;
+  void emitEpilogue(MachineFunction &MF, MachineBasicBlock &MBB) const override;
+
+  MachineBasicBlock::iterator
+  eliminateCallFramePseudoInstr(MachineFunction &MF, MachineBasicBlock &MBB,
+                                MachineBasicBlock::iterator I) const override;
+
+  bool spillCalleeSavedRegisters(MachineBasicBlock &MBB,
+                                 MachineBasicBlock::iterator MI,
+                                 const std::vector<CalleeSavedInfo> &CSI,
+                                 const TargetRegisterInfo *TRI) const override;
+  bool
+  restoreCalleeSavedRegisters(MachineBasicBlock &MBB,
+                              MachineBasicBlock::iterator MI,
+                              std::vector<CalleeSavedInfo> &CSI,
+                              const TargetRegisterInfo *TRI) const override;
+
+  void determineCalleeSaves(MachineFunction &MF, BitVector &SavedRegs,
+                            RegScavenger *RS) const override;
+
+  void processFunctionBeforeFrameFinalized(MachineFunction &MF,
+                                           RegScavenger *RS) const override;
+};
+
+} // namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSAFRAMELOWERING_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaISelDAGToDAG.cpp
@@ -0,0 +1,409 @@
+//===- XtensaISelDAGToDAG.cpp - A dag to dag inst selector for Xtensa -----===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file defines an instruction selector for the Xtensa target.
+//
+//===----------------------------------------------------------------------===//
+
+#include "Xtensa.h"
+#include "XtensaTargetMachine.h"
+#include "llvm/IR/IntrinsicsXtensa.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/CodeGen/SelectionDAGISel.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/raw_ostream.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "xtensa-isel"
+
+namespace {
+
+class XtensaDAGToDAGISel : public SelectionDAGISel {
+  const XtensaSubtarget *Subtarget;
+
+public:
+  XtensaDAGToDAGISel(XtensaTargetMachine &TM, CodeGenOpt::Level OptLevel)
+      : SelectionDAGISel(TM, OptLevel), Subtarget(TM.getSubtargetImpl()) {}
+
+  // Override MachineFunctionPass.
+  StringRef getPassName() const override {
+    return "Xtensa DAG->DAG Pattern Instruction Selection";
+  }
+
+  // Override SelectionDAGISel.
+  void Select(SDNode *Node) override;
+
+  bool SelectInlineAsmMemoryOperand(const SDValue &Op, unsigned ConstraintID,
+                                    std::vector<SDValue> &OutOps) override;
+
+  bool selectMemRegAddr(SDValue Addr, SDValue &Base, SDValue &Offset,
+                        int Scale) {
+    EVT ValTy = Addr.getValueType();
+
+    // if Address is FI, get the TargetFrameIndex.
+    if (FrameIndexSDNode *FIN = dyn_cast<FrameIndexSDNode>(Addr)) {
+      Base = CurDAG->getTargetFrameIndex(FIN->getIndex(), ValTy);
+      Offset = CurDAG->getTargetConstant(0, SDLoc(Addr), ValTy);
+
+      return true;
+    }
+
+    if (TM.isPositionIndependent())
+      report_fatal_error("PIC relocations is not supported");
+
+    if ((Addr.getOpcode() == ISD::TargetExternalSymbol ||
+         Addr.getOpcode() == ISD::TargetGlobalAddress))
+      return false;
+
+    // Addresses of the form FI+const or FI|const
+    bool Valid = false;
+    if (CurDAG->isBaseWithConstantOffset(Addr)) {
+      ConstantSDNode *CN = dyn_cast<ConstantSDNode>(Addr.getOperand(1));
+      int64_t OffsetVal = CN->getSExtValue();
+
+      switch (Scale) {
+      case 1:
+        Valid = (OffsetVal >= 0 && OffsetVal <= 255);
+        break;
+      case 2:
+        Valid =
+            (OffsetVal >= 0 && OffsetVal <= 510) && ((OffsetVal & 0x1) == 0);
+        break;
+      case 4:
+        Valid =
+            (OffsetVal >= 0 && OffsetVal <= 1020) && ((OffsetVal & 0x3) == 0);
+        break;
+      default:
+        break;
+      }
+
+      if (Valid) {
+        // If the first operand is a FI, get the TargetFI Node
+        if (FrameIndexSDNode *FIN =
+                dyn_cast<FrameIndexSDNode>(Addr.getOperand(0)))
+          Base = CurDAG->getTargetFrameIndex(FIN->getIndex(), ValTy);
+        else
+          Base = Addr.getOperand(0);
+
+        Offset =
+            CurDAG->getTargetConstant(CN->getZExtValue(), SDLoc(Addr), ValTy);
+        return true;
+      }
+    }
+
+    // Last case
+    Base = Addr;
+    Offset = CurDAG->getTargetConstant(0, SDLoc(Addr), Addr.getValueType());
+    return true;
+  }
+
+  bool selectMemRegAddrISH1(SDValue Addr, SDValue &Base, SDValue &Offset) {
+    return selectMemRegAddr(Addr, Base, Offset, 1);
+  }
+
+  bool selectMemRegAddrISH2(SDValue Addr, SDValue &Base, SDValue &Offset) {
+    return selectMemRegAddr(Addr, Base, Offset, 2);
+  }
+
+  bool selectMemRegAddrISH4(SDValue Addr, SDValue &Base, SDValue &Offset) {
+    return selectMemRegAddr(Addr, Base, Offset, 4);
+  }
+
+// Include the pieces autogenerated from the target description.
+#include "XtensaGenDAGISel.inc"
+}; // namespace
+} // end anonymous namespace
+
+FunctionPass *llvm::createXtensaISelDag(XtensaTargetMachine &TM,
+                                        CodeGenOpt::Level OptLevel) {
+  return new XtensaDAGToDAGISel(TM, OptLevel);
+}
+
+void XtensaDAGToDAGISel::Select(SDNode *Node) {
+  unsigned Opcode = Node->getOpcode();
+  SDLoc DL(Node);
+  const unsigned MRTable[] = {Xtensa::M0, Xtensa::M1, Xtensa::M2, Xtensa::M3};
+
+  switch (Opcode) {
+  case ISD::INTRINSIC_VOID: {
+    unsigned IntNo = cast<ConstantSDNode>(Node->getOperand(1))->getZExtValue();
+    switch (IntNo) {
+    default:
+      break;
+    case Intrinsic::xtensa_mul_da_ll:
+    case Intrinsic::xtensa_mul_da_lh:
+    case Intrinsic::xtensa_mul_da_hl:
+    case Intrinsic::xtensa_mul_da_hh:
+    case Intrinsic::xtensa_mula_da_ll:
+    case Intrinsic::xtensa_mula_da_lh:
+    case Intrinsic::xtensa_mula_da_hl:
+    case Intrinsic::xtensa_mula_da_hh:
+    case Intrinsic::xtensa_muls_da_ll:
+    case Intrinsic::xtensa_muls_da_lh:
+    case Intrinsic::xtensa_muls_da_hl:
+    case Intrinsic::xtensa_muls_da_hh: {
+      SDValue ChainIn = Node->getOperand(0);
+      SDValue ValueMX = Node->getOperand(2);
+      SDValue ValueT = Node->getOperand(3);
+      unsigned OpCode;
+
+      switch (IntNo) {
+      case Intrinsic::xtensa_mul_da_ll:
+        OpCode = Xtensa::MUL_DA_LL;
+        break;
+      case Intrinsic::xtensa_mul_da_lh:
+        OpCode = Xtensa::MUL_DA_LH;
+        break;
+      case Intrinsic::xtensa_mul_da_hl:
+        OpCode = Xtensa::MUL_DA_HL;
+        break;
+      case Intrinsic::xtensa_mul_da_hh:
+        OpCode = Xtensa::MUL_DA_HH;
+        break;
+      case Intrinsic::xtensa_mula_da_ll:
+        OpCode = Xtensa::MULA_DA_LL;
+        break;
+      case Intrinsic::xtensa_mula_da_lh:
+        OpCode = Xtensa::MULA_DA_LH;
+        break;
+      case Intrinsic::xtensa_mula_da_hl:
+        OpCode = Xtensa::MULA_DA_HL;
+        break;
+      case Intrinsic::xtensa_mula_da_hh:
+        OpCode = Xtensa::MULA_DA_HH;
+        break;
+      case Intrinsic::xtensa_muls_da_ll:
+        OpCode = Xtensa::MULS_DA_LL;
+        break;
+      case Intrinsic::xtensa_muls_da_lh:
+        OpCode = Xtensa::MULS_DA_LH;
+        break;
+      case Intrinsic::xtensa_muls_da_hl:
+        OpCode = Xtensa::MULS_DA_HL;
+        break;
+      case Intrinsic::xtensa_muls_da_hh:
+        OpCode = Xtensa::MULS_DA_HH;
+        break;
+      }
+
+      uint64_t MXVal = 4;
+      if (ValueMX.getOpcode() == ISD::TargetConstant) {
+        MXVal = cast<ConstantSDNode>(ValueMX)->getZExtValue();
+      }
+
+      assert(
+          (MXVal < 2) &&
+          "Unexpected value of mul*_da* first argument, it must be m0 or m1");
+      unsigned MXReg = MRTable[MXVal];
+
+      const EVT MULAResTys[] = {MVT::Other};
+      SmallVector<SDValue, 2> MULAOps;
+      MULAOps.push_back(CurDAG->getRegister(MXReg, MVT::i32));
+      MULAOps.push_back(ValueT);
+      MULAOps.push_back(ChainIn);
+
+      SDNode *MULA = CurDAG->getMachineNode(OpCode, DL, MULAResTys, MULAOps);
+      ReplaceNode(Node, MULA);
+      return;
+    }
+    case Intrinsic::xtensa_mul_ad_ll:
+    case Intrinsic::xtensa_mul_ad_lh:
+    case Intrinsic::xtensa_mul_ad_hl:
+    case Intrinsic::xtensa_mul_ad_hh:
+    case Intrinsic::xtensa_mula_ad_ll:
+    case Intrinsic::xtensa_mula_ad_lh:
+    case Intrinsic::xtensa_mula_ad_hl:
+    case Intrinsic::xtensa_mula_ad_hh:
+    case Intrinsic::xtensa_muls_ad_ll:
+    case Intrinsic::xtensa_muls_ad_lh:
+    case Intrinsic::xtensa_muls_ad_hl:
+    case Intrinsic::xtensa_muls_ad_hh: {
+      SDValue ChainIn = Node->getOperand(0);
+      SDValue ValueS = Node->getOperand(2);
+      SDValue ValueMY = Node->getOperand(3);
+      unsigned OpCode;
+
+      switch (IntNo) {
+      case Intrinsic::xtensa_mul_ad_ll:
+        OpCode = Xtensa::MUL_AD_LL;
+        break;
+      case Intrinsic::xtensa_mul_ad_lh:
+        OpCode = Xtensa::MUL_AD_LH;
+        break;
+      case Intrinsic::xtensa_mul_ad_hl:
+        OpCode = Xtensa::MUL_AD_HL;
+        break;
+      case Intrinsic::xtensa_mul_ad_hh:
+        OpCode = Xtensa::MUL_AD_HH;
+        break;
+      case Intrinsic::xtensa_mula_ad_ll:
+        OpCode = Xtensa::MULA_AD_LL;
+        break;
+      case Intrinsic::xtensa_mula_ad_lh:
+        OpCode = Xtensa::MULA_AD_LH;
+        break;
+      case Intrinsic::xtensa_mula_ad_hl:
+        OpCode = Xtensa::MULA_AD_HL;
+        break;
+      case Intrinsic::xtensa_mula_ad_hh:
+        OpCode = Xtensa::MULA_AD_HH;
+        break;
+      case Intrinsic::xtensa_muls_ad_ll:
+        OpCode = Xtensa::MULS_AD_LL;
+        break;
+      case Intrinsic::xtensa_muls_ad_lh:
+        OpCode = Xtensa::MULS_AD_LH;
+        break;
+      case Intrinsic::xtensa_muls_ad_hl:
+        OpCode = Xtensa::MULS_AD_HL;
+        break;
+      case Intrinsic::xtensa_muls_ad_hh:
+        OpCode = Xtensa::MULS_AD_HH;
+        break;
+      }
+
+      uint64_t MYVal = 4;
+      if (ValueMY.getOpcode() == ISD::TargetConstant) {
+        MYVal = cast<ConstantSDNode>(ValueMY)->getZExtValue();
+      }
+
+      assert(
+          ((MYVal > 1) && (MYVal < 4)) &&
+          "Unexpected value of mul*_ad* second argument, it must be m2 or m3");
+      unsigned MYReg = MRTable[MYVal];
+
+      const EVT MULAResTys[] = {MVT::Other};
+      SmallVector<SDValue, 2> MULAOps;
+      MULAOps.push_back(ValueS);
+      MULAOps.push_back(CurDAG->getRegister(MYReg, MVT::i32));
+      MULAOps.push_back(ChainIn);
+
+      SDNode *MULA = CurDAG->getMachineNode(OpCode, DL, MULAResTys, MULAOps);
+      ReplaceNode(Node, MULA);
+      return;
+    }
+    case Intrinsic::xtensa_mul_dd_ll:
+    case Intrinsic::xtensa_mul_dd_lh:
+    case Intrinsic::xtensa_mul_dd_hl:
+    case Intrinsic::xtensa_mul_dd_hh:
+    case Intrinsic::xtensa_mula_dd_ll:
+    case Intrinsic::xtensa_mula_dd_lh:
+    case Intrinsic::xtensa_mula_dd_hl:
+    case Intrinsic::xtensa_mula_dd_hh:
+    case Intrinsic::xtensa_muls_dd_ll:
+    case Intrinsic::xtensa_muls_dd_lh:
+    case Intrinsic::xtensa_muls_dd_hl:
+    case Intrinsic::xtensa_muls_dd_hh: {
+      SDValue ChainIn = Node->getOperand(0);
+      SDValue ValueMX = Node->getOperand(2);
+      SDValue ValueMY = Node->getOperand(3);
+      unsigned OpCode;
+
+      switch (IntNo) {
+      case Intrinsic::xtensa_mul_dd_ll:
+        OpCode = Xtensa::MUL_DD_LL;
+        break;
+      case Intrinsic::xtensa_mul_dd_lh:
+        OpCode = Xtensa::MUL_DD_LH;
+        break;
+      case Intrinsic::xtensa_mul_dd_hl:
+        OpCode = Xtensa::MUL_DD_HL;
+        break;
+      case Intrinsic::xtensa_mul_dd_hh:
+        OpCode = Xtensa::MUL_DD_HH;
+        break;
+      case Intrinsic::xtensa_mula_dd_ll:
+        OpCode = Xtensa::MULA_DD_LL;
+        break;
+      case Intrinsic::xtensa_mula_dd_lh:
+        OpCode = Xtensa::MULA_DD_LH;
+        break;
+      case Intrinsic::xtensa_mula_dd_hl:
+        OpCode = Xtensa::MULA_DD_HL;
+        break;
+      case Intrinsic::xtensa_mula_dd_hh:
+        OpCode = Xtensa::MULA_DD_HH;
+        break;
+      case Intrinsic::xtensa_muls_dd_ll:
+        OpCode = Xtensa::MULS_DD_LL;
+        break;
+      case Intrinsic::xtensa_muls_dd_lh:
+        OpCode = Xtensa::MULS_DD_LH;
+        break;
+      case Intrinsic::xtensa_muls_dd_hl:
+        OpCode = Xtensa::MULS_DD_HL;
+        break;
+      case Intrinsic::xtensa_muls_dd_hh:
+        OpCode = Xtensa::MULS_DD_HH;
+        break;
+      }
+      uint64_t MXVal = 4;
+      if (ValueMX.getOpcode() == ISD::TargetConstant) {
+        MXVal = cast<ConstantSDNode>(ValueMX)->getZExtValue();
+      }
+
+      assert(
+          (MXVal < 2) &&
+          "Unexpected value of mul*_dd* first argument, it must be m0 or m1");
+      unsigned MXReg = MRTable[MXVal];
+
+      uint64_t MYVal = 4;
+      if (ValueMY.getOpcode() == ISD::TargetConstant) {
+        MYVal = cast<ConstantSDNode>(ValueMY)->getZExtValue();
+      }
+
+      assert(
+          ((MYVal > 1) && (MYVal < 4)) &&
+          "Unexpected value of mul*_dd* second argument, it must be m2 or m3");
+      unsigned MYReg = MRTable[MYVal];
+
+      const EVT MULAResTys[] = {MVT::Other};
+      SmallVector<SDValue, 2> MULAOps;
+      MULAOps.push_back(CurDAG->getRegister(MXReg, MVT::i32));
+      MULAOps.push_back(CurDAG->getRegister(MYReg, MVT::i32));
+      MULAOps.push_back(ChainIn);
+
+      SDNode *MULA = CurDAG->getMachineNode(OpCode, DL, MULAResTys, MULAOps);
+      ReplaceNode(Node, MULA);
+      return;
+    }
+    }
+    break;
+  }
+  default:
+    break;
+  }
+
+  SelectCode(Node);
+}
+
+bool XtensaDAGToDAGISel::SelectInlineAsmMemoryOperand(
+    const SDValue &Op, unsigned ConstraintID, std::vector<SDValue> &OutOps) {
+  switch (ConstraintID) {
+  default:
+    llvm_unreachable("Unexpected asm memory constraint");
+  case InlineAsm::Constraint_m: {
+    SDValue Base, Offset;
+    // TODO
+    selectMemRegAddr(Op, Base, Offset, 4);
+    OutOps.push_back(Base);
+    OutOps.push_back(Offset);
+    return false;
+  }
+  case InlineAsm::Constraint_i:
+  case InlineAsm::Constraint_R:
+  case InlineAsm::Constraint_ZC:
+    OutOps.push_back(Op);
+    return false;
+  }
+  return false;
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaISelLowering.cpp
@@ -0,0 +1,3194 @@
+//===- XtensaISelLowering.cpp - Xtensa DAG Lowering Implementation --------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file defines the interfaces that Xtensa uses to lower LLVM code into a
+// selection DAG.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaISelLowering.h"
+#include "XtensaConstantPoolValue.h"
+#include "XtensaMachineFunctionInfo.h"
+#include "XtensaSubtarget.h"
+#include "XtensaTargetMachine.h"
+#include "llvm/CodeGen/CallingConvLower.h"
+#include "llvm/CodeGen/MachineInstrBuilder.h"
+#include "llvm/CodeGen/MachineJumpTableInfo.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/CodeGen/TargetLoweringObjectFileImpl.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+#include <deque>
+
+using namespace llvm;
+
+#define DEBUG_TYPE "xtensa-lower"
+
+static const MCPhysReg XtensaArgRegs[6] = {Xtensa::A2, Xtensa::A3, Xtensa::A4,
+                                           Xtensa::A5, Xtensa::A6, Xtensa::A7};
+
+// Return true if we must use long (in fact, indirect) function call.
+// It's simplified version, production implimentation must
+// resolve a functions in ROM (usually glibc functions)
+static bool isLongCall(const char *str) {
+  // Currently always use long calls
+  return true;
+}
+
+// The calling conventions in XtensaCallingConv.td are described in terms of the
+// callee's register window. This function translates registers to the
+// corresponding caller window %o register.
+static unsigned toCallerWindow(unsigned Reg) {
+  if (Reg >= Xtensa::A2 && Reg <= Xtensa::A7)
+    return Reg - Xtensa::A2 + Xtensa::A10;
+  return Reg;
+}
+
+XtensaTargetLowering::XtensaTargetLowering(const TargetMachine &tm,
+                                           const XtensaSubtarget &STI)
+    : TargetLowering(tm), Subtarget(STI) {
+  MVT PtrVT = MVT::i32;
+  // Set up the register classes.
+  addRegisterClass(MVT::i32, &Xtensa::ARRegClass);
+
+  if (Subtarget.hasSingleFloat()) {
+    addRegisterClass(MVT::f32, &Xtensa::FPRRegClass);
+  }
+
+  // Set up special registers.
+  setStackPointerRegisterToSaveRestore(Xtensa::SP);
+
+  setSchedulingPreference(Sched::RegPressure);
+
+  setBooleanContents(ZeroOrOneBooleanContent);
+  setBooleanVectorContents(ZeroOrOneBooleanContent);
+
+  setMinFunctionAlignment(Align(4));
+
+  setOperationAction(ISD::Constant, MVT::i32, Custom);
+  setOperationAction(ISD::Constant, MVT::i64, Expand);
+  setOperationAction(ISD::ConstantFP, MVT::f32, Custom);
+  setOperationAction(ISD::ConstantFP, MVT::f64, Expand);
+
+  // No sign extend instructions for i1
+  for (MVT VT : MVT::integer_valuetypes()) {
+    setLoadExtAction(ISD::SEXTLOAD, VT, MVT::i1, Promote);
+    setLoadExtAction(ISD::ZEXTLOAD, VT, MVT::i1, Promote);
+    setLoadExtAction(ISD::EXTLOAD, VT, MVT::i1, Promote);
+  }
+
+  // Handle the various types of symbolic address.
+  setOperationAction(ISD::ConstantPool, PtrVT, Custom);
+  setOperationAction(ISD::GlobalAddress, PtrVT, Custom);
+  setOperationAction(ISD::GlobalTLSAddress, PtrVT, Custom);
+  setOperationAction(ISD::BlockAddress, PtrVT, Custom);
+  setOperationAction(ISD::JumpTable, PtrVT, Custom);
+
+  // Used by legalize types to correctly generate the setcc result.
+  // AddPromotedToType(ISD::SETCC, MVT::i1, MVT::i32);
+  setOperationPromotedToType(ISD::SETCC, MVT::i1, MVT::i32);
+  setOperationPromotedToType(ISD::BR_CC, MVT::i1, MVT::i32);
+
+  setOperationAction(ISD::BR_CC, MVT::i32, Legal);
+  setOperationAction(ISD::BR_CC, MVT::i64, Expand);
+  if (Subtarget.hasSingleFloat())
+    setOperationAction(ISD::BR_CC, MVT::f32, Custom);
+  else
+    setOperationAction(ISD::BR_CC, MVT::f32, Expand);
+
+  setOperationAction(ISD::SELECT, MVT::i32, Expand);
+  setOperationAction(ISD::SELECT, MVT::i64, Expand);
+  setOperationAction(ISD::SELECT, MVT::f32, Expand);
+
+  setOperationAction(ISD::SELECT_CC, MVT::i32, Custom);
+  setOperationAction(ISD::SELECT_CC, MVT::i64, Expand);
+  if (Subtarget.hasSingleFloat())
+    setOperationAction(ISD::SELECT_CC, MVT::f32, Custom);
+  else
+    setOperationAction(ISD::SELECT_CC, MVT::f32, Expand);
+
+  setOperationAction(ISD::SETCC, MVT::i32,
+                     Custom); // folds into brcond
+  setOperationAction(ISD::SETCC, MVT::i64, Expand);
+  if (Subtarget.hasSingleFloat())
+    setOperationAction(ISD::SETCC, MVT::f32, Custom);
+  else
+    setOperationAction(ISD::SETCC, MVT::f32, Expand);
+
+  // Expand jump table branches as address arithmetic followed by an
+  // indirect jump.
+  setOperationAction(ISD::BR_JT, MVT::Other, Custom);
+
+  // make BRCOND legal, its actually only legal for a subset of conds
+  setOperationAction(ISD::BRCOND, MVT::Other, Legal);
+
+  // Handle integer types.
+  for (unsigned I = MVT::FIRST_INTEGER_VALUETYPE;
+       I <= MVT::LAST_INTEGER_VALUETYPE; ++I) {
+    MVT VT = MVT::SimpleValueType(I);
+    if (isTypeLegal(VT)) {
+      // No support at all
+      setOperationAction(ISD::SDIVREM, VT, Expand);
+      setOperationAction(ISD::UDIVREM, VT, Expand);
+    }
+  }
+
+  if (Subtarget.hasMul32())
+    setOperationAction(ISD::MUL, MVT::i32, Legal);
+  else
+    setOperationAction(ISD::MUL, MVT::i32, Expand);
+
+  if (Subtarget.hasMul32High()) {
+    setOperationAction(ISD::MULHU, MVT::i32, Legal);
+    setOperationAction(ISD::MULHS, MVT::i32, Legal);
+  } else {
+    setOperationAction(ISD::MULHU, MVT::i32, Expand);
+    setOperationAction(ISD::MULHS, MVT::i32, Expand);
+  }
+  setOperationAction(ISD::MUL, MVT::i64, Expand);
+  setOperationAction(ISD::MULHS, MVT::i64, Expand);
+  setOperationAction(ISD::MULHU, MVT::i64, Expand);
+
+  if (Subtarget.hasDiv32()) {
+    setOperationAction(ISD::SDIV, MVT::i32, Legal);
+    setOperationAction(ISD::UDIV, MVT::i32, Legal);
+    setOperationAction(ISD::SREM, MVT::i32, Legal);
+    setOperationAction(ISD::UREM, MVT::i32, Legal);
+  } else {
+    setOperationAction(ISD::SDIV, MVT::i32, Expand);
+    setOperationAction(ISD::UDIV, MVT::i32, Expand);
+    setOperationAction(ISD::SREM, MVT::i32, Expand);
+    setOperationAction(ISD::UREM, MVT::i32, Expand);
+  }
+
+  setOperationAction(ISD::SDIV, MVT::i64, Expand);
+  setOperationAction(ISD::UDIV, MVT::i64, Expand);
+  setOperationAction(ISD::SREM, MVT::i64, Expand);
+  setOperationAction(ISD::UREM, MVT::i64, Expand);
+
+  // Xtensa doesn't support  [ADD,SUB][E,C]
+  setOperationAction(ISD::ADDC, MVT::i32, Expand);
+  setOperationAction(ISD::ADDE, MVT::i32, Expand);
+  setOperationAction(ISD::SUBC, MVT::i32, Expand);
+  setOperationAction(ISD::SUBE, MVT::i32, Expand);
+
+  setOperationAction(ISD::ADD, MVT::i64, Expand);
+  setOperationAction(ISD::SUB, MVT::i64, Expand);
+
+  // Xtensa doesn't support s[hl,rl,ra]_parts
+  setOperationAction(ISD::SHL_PARTS, MVT::i32, Custom);
+  setOperationAction(ISD::SRA_PARTS, MVT::i32, Custom);
+  setOperationAction(ISD::SRL_PARTS, MVT::i32, Custom);
+
+  // Funnel shifts
+  setOperationAction(ISD::FSHR, MVT::i32, Custom);
+  setOperationAction(ISD::FSHL, MVT::i32, Custom);
+
+  // Bit Manipulation
+  setOperationAction(ISD::BSWAP, MVT::i32, Expand);
+  setOperationAction(ISD::BSWAP, MVT::i64, Expand);
+  setOperationAction(ISD::ROTL, MVT::i32, Expand);
+  setOperationAction(ISD::ROTR, MVT::i32, Expand);
+  setOperationAction(ISD::CTPOP, MVT::i32, Expand);
+  setOperationAction(ISD::CTTZ, MVT::i32, Expand);
+  setOperationAction(ISD::CTLZ, MVT::i32, Expand);
+  setOperationAction(ISD::CTTZ_ZERO_UNDEF, MVT::i32, Expand);
+  setOperationAction(ISD::CTLZ_ZERO_UNDEF, MVT::i32, Expand);
+
+  setOperationAction(ISD::SMUL_LOHI, MVT::i32, Expand);
+  setOperationAction(ISD::SMUL_LOHI, MVT::i64, Expand);
+  setOperationAction(ISD::UMUL_LOHI, MVT::i32, Expand);
+  setOperationAction(ISD::UMUL_LOHI, MVT::i64, Expand);
+
+  setOperationAction(ISD::SIGN_EXTEND_INREG, MVT::i1, Expand);
+  setOperationAction(ISD::SIGN_EXTEND_INREG, MVT::i8, Expand);
+  setOperationAction(ISD::SIGN_EXTEND_INREG, MVT::i16, Expand);
+  setOperationAction(ISD::SIGN_EXTEND_INREG, MVT::i32, Expand);
+
+  // Handle floating-point types.
+  for (unsigned I = MVT::FIRST_FP_VALUETYPE; I <= MVT::LAST_FP_VALUETYPE; ++I) {
+    MVT VT = MVT::SimpleValueType(I);
+    if (isTypeLegal(VT)) {
+      // We can use FI for FRINT.
+      // setOperationAction(ISD::FRINT, VT, Legal);
+      if (VT.getSizeInBits() == 32 && Subtarget.hasSingleFloat()) {
+        setOperationAction(ISD::FADD, VT, Legal);
+        setOperationAction(ISD::FSUB, VT, Legal);
+        setOperationAction(ISD::FMUL, VT, Legal);
+        setOperationAction(ISD::FDIV, VT, Expand);
+      } else {
+        setOperationAction(ISD::FADD, VT, Expand);
+        setOperationAction(ISD::FSUB, VT, Expand);
+        setOperationAction(ISD::FMUL, VT, Expand);
+        setOperationAction(ISD::FDIV, VT, Expand);
+      }
+
+      // TODO: once implemented in InstrInfo uncomment
+      setOperationAction(ISD::FSQRT, VT, Expand);
+
+      // No special instructions for these.
+      setOperationAction(ISD::FSIN, VT, Expand);
+      setOperationAction(ISD::FCOS, VT, Expand);
+      setOperationAction(ISD::FREM, VT, Expand);
+      setOperationAction(ISD::FABS, VT, Expand);
+    }
+  }
+
+  // Handle floating-point types.
+  if (Subtarget.hasSingleFloat()) {
+    setOperationAction(ISD::FMA, MVT::f32, Legal);
+    setOperationAction(ISD::BITCAST, MVT::i32, Legal);
+    setOperationAction(ISD::BITCAST, MVT::f32, Legal);
+    setOperationAction(ISD::UINT_TO_FP, MVT::i32, Legal);
+    setOperationAction(ISD::SINT_TO_FP, MVT::i32, Legal);
+    setOperationAction(ISD::FP_TO_UINT, MVT::i32, Legal);
+    setOperationAction(ISD::FP_TO_SINT, MVT::i32, Legal);
+    setOperationAction(ISD::FCOPYSIGN, MVT::f32, Expand);
+  } else {
+    setOperationAction(ISD::FMA, MVT::f32, Expand);
+    setOperationAction(ISD::SETCC, MVT::f32, Expand);
+    setOperationAction(ISD::BITCAST, MVT::i32, Expand);
+    setOperationAction(ISD::BITCAST, MVT::f32, Expand);
+    setOperationAction(ISD::UINT_TO_FP, MVT::i32, Expand);
+    setOperationAction(ISD::SINT_TO_FP, MVT::i32, Expand);
+    setOperationAction(ISD::FP_TO_UINT, MVT::i32, Expand);
+    setOperationAction(ISD::FP_TO_SINT, MVT::i32, Expand);
+    setOperationAction(ISD::UINT_TO_FP, MVT::i64, Expand);
+    setOperationAction(ISD::SINT_TO_FP, MVT::i64, Expand);
+    setOperationAction(ISD::FP_TO_UINT, MVT::i64, Expand);
+    setOperationAction(ISD::FP_TO_SINT, MVT::i64, Expand);
+  }
+  setOperationAction(ISD::FMA, MVT::f64, Expand);
+  setOperationAction(ISD::SETCC, MVT::f64, Expand);
+  setOperationAction(ISD::BITCAST, MVT::i64, Expand);
+  setOperationAction(ISD::BITCAST, MVT::f64, Expand);
+
+  if (Subtarget.hasSingleFloat()) {
+    setCondCodeAction(ISD::SETOGT, MVT::f32, Expand);
+    setCondCodeAction(ISD::SETOGE, MVT::f32, Expand);
+    setCondCodeAction(ISD::SETONE, MVT::f32, Expand);
+    setCondCodeAction(ISD::SETUGE, MVT::f32, Expand);
+    setCondCodeAction(ISD::SETUGT, MVT::f32, Expand);
+
+    setTargetDAGCombine(ISD::FADD);
+    setTargetDAGCombine(ISD::FSUB);
+    setTargetDAGCombine(ISD::BRCOND);
+  }
+
+  // Needed so that we don't try to implement f128 constant loads using
+  // a load-and-extend of a f80 constant (in cases where the constant
+  // would fit in an f80).
+  for (MVT VT : MVT::fp_valuetypes())
+    setLoadExtAction(ISD::EXTLOAD, VT, MVT::f80, Expand);
+
+  // Floating-point truncation and stores need to be done separately.
+  setTruncStoreAction(MVT::f64, MVT::f32, Expand);
+
+  // Implement custom stack allocations
+  setOperationAction(ISD::DYNAMIC_STACKALLOC, PtrVT, Custom);
+  // Implement custom stack save and restore
+  setOperationAction(ISD::STACKSAVE, MVT::Other, Custom);
+  setOperationAction(ISD::STACKRESTORE, MVT::Other, Custom);
+
+  // VASTART and VACOPY need to deal with the Xtensa-specific varargs
+  // structure, but VAEND is a no-op.
+  setOperationAction(ISD::VASTART, MVT::Other, Custom);
+  // we use special va_list structure so we have to customize this
+  setOperationAction(ISD::VAARG, MVT::Other, Expand);
+  setOperationAction(ISD::VACOPY, MVT::Other, Custom);
+  setOperationAction(ISD::VAEND, MVT::Other, Expand);
+
+  setOperationAction(ISD::TRAP, MVT::Other, Legal);
+
+  // to have the best chance and doing something good with fences custom lower
+  // them
+  setOperationAction(ISD::ATOMIC_FENCE, MVT::Other, Custom);
+
+  if (!Subtarget.hasS32C1I()) {
+    for (unsigned I = MVT::FIRST_INTEGER_VALUETYPE;
+         I <= MVT::LAST_INTEGER_VALUETYPE; ++I) {
+      MVT VT = MVT::SimpleValueType(I);
+      if (isTypeLegal(VT)) {
+        setOperationAction(ISD::ATOMIC_CMP_SWAP, VT, Expand);
+        setOperationAction(ISD::ATOMIC_SWAP, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_ADD, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_SUB, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_AND, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_OR, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_XOR, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_NAND, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_MIN, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_MAX, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_UMIN, VT, Expand);
+        setOperationAction(ISD::ATOMIC_LOAD_UMAX, VT, Expand);
+      }
+    }
+  }
+
+  // Compute derived properties from the register classes
+  computeRegisterProperties(STI.getRegisterInfo());
+
+  if (Subtarget.hasBoolean()) {
+    addRegisterClass(MVT::i1, &Xtensa::BRRegClass);
+  }
+}
+
+/// If a physical register, this returns the register that receives the
+/// exception address on entry to an EH pad.
+unsigned XtensaTargetLowering::getExceptionPointerRegister(
+    const Constant *PersonalityFn) const {
+  return Xtensa::A2;
+}
+
+/// If a physical register, this returns the register that receives the
+/// exception typeid on entry to a landing pad.
+unsigned XtensaTargetLowering::getExceptionSelectorRegister(
+    const Constant *PersonalityFn) const {
+  return Xtensa::A3;
+}
+
+bool XtensaTargetLowering::isOffsetFoldingLegal(
+    const GlobalAddressSDNode *GA) const {
+  // The Xtensa target isn't yet aware of offsets.
+  return false;
+}
+
+bool XtensaTargetLowering::isFPImmLegal(const APFloat &Imm, EVT VT,
+                                        bool ForCodeSize) const {
+  return false;
+}
+
+unsigned XtensaTargetLowering::getVaListSizeInBits(const DataLayout &DL) const {
+  // 2 * sizeof(int*) + sizeof(int)
+  return 3 * 4;
+}
+
+//===----------------------------------------------------------------------===//
+// Inline asm support
+//===----------------------------------------------------------------------===//
+TargetLowering::ConstraintType
+XtensaTargetLowering::getConstraintType(StringRef Constraint) const {
+  if (Constraint.size() == 1) {
+    switch (Constraint[0]) {
+    case 'a':
+    case 'd':
+    case 'f':
+    case 'r':
+      return C_RegisterClass;
+
+    default:
+      break;
+    }
+  }
+  return TargetLowering::getConstraintType(Constraint);
+}
+
+TargetLowering::ConstraintWeight
+XtensaTargetLowering::getSingleConstraintMatchWeight(
+    AsmOperandInfo &info, const char *constraint) const {
+  ConstraintWeight weight = CW_Invalid;
+  Value *CallOperandVal = info.CallOperandVal;
+  // If we don't have a value, we can't do a match,
+  // but allow it at the lowest weight.
+  if (CallOperandVal == NULL)
+    return CW_Default;
+  Type *type = CallOperandVal->getType();
+  // Look at the constraint type.
+  switch (*constraint) {
+  default:
+    weight = TargetLowering::getSingleConstraintMatchWeight(info, constraint);
+    break;
+
+  case 'a':
+  case 'd':
+  case 'r':
+    if (CallOperandVal->getType()->isIntegerTy())
+      weight = CW_Register;
+    break;
+
+  case 'f':
+    if (type->isFloatingPointTy())
+      weight = CW_Register;
+    break;
+  }
+  return weight;
+}
+
+std::pair<unsigned, const TargetRegisterClass *>
+XtensaTargetLowering::getRegForInlineAsmConstraint(
+    const TargetRegisterInfo *TRI, StringRef Constraint, MVT VT) const {
+  if (Constraint.size() == 1) {
+    // GCC Constraint Letters
+    switch (Constraint[0]) {
+    default:
+      break;
+    case 'a': // Address register
+    case 'd': // Data register (equivalent to 'r')
+    case 'r': // General-purpose register
+      return std::make_pair(0U, &Xtensa::ARRegClass);
+    case 'f': // Floating-point register
+      return std::make_pair(0U, &Xtensa::ARRegClass);
+    }
+  }
+  return TargetLowering::getRegForInlineAsmConstraint(TRI, Constraint, VT);
+}
+
+/// LowerAsmOperandForConstraint - Lower the specified operand into the Ops
+/// vector.  If it is invalid, don't add anything to Ops.
+void XtensaTargetLowering::LowerAsmOperandForConstraint(
+    SDValue Op, std::string &Constraint, std::vector<SDValue> &Ops,
+    SelectionDAG &DAG) const {
+  SDLoc DL(Op);
+
+  // Only support length 1 constraints for now.
+  if (Constraint.length() > 1)
+    return;
+
+  TargetLowering::LowerAsmOperandForConstraint(Op, Constraint, Ops, DAG);
+}
+
+//===----------------------------------------------------------------------===//
+//  DAG Combine functions
+//===----------------------------------------------------------------------===//
+
+static SDValue performMADD_MSUBCombine(SDNode *ROOTNode, SelectionDAG &CurDAG,
+                                       const XtensaSubtarget &Subtarget) {
+  if (ROOTNode->getOperand(0).getValueType() != MVT::f32)
+    return SDValue();
+
+  if (ROOTNode->getOperand(0).getOpcode() != ISD::FMUL &&
+      ROOTNode->getOperand(1).getOpcode() != ISD::FMUL)
+    return SDValue();
+
+  SDValue Mult = ROOTNode->getOperand(0).getOpcode() == ISD::FMUL
+                     ? ROOTNode->getOperand(0)
+                     : ROOTNode->getOperand(1);
+
+  SDValue AddOperand = ROOTNode->getOperand(0).getOpcode() == ISD::FMUL
+                           ? ROOTNode->getOperand(1)
+                           : ROOTNode->getOperand(0);
+
+  if (!Mult.hasOneUse())
+    return SDValue();
+
+  SDLoc DL(ROOTNode);
+
+  bool IsAdd = ROOTNode->getOpcode() == ISD::FADD;
+  unsigned Opcode = IsAdd ? XtensaISD::MADD : XtensaISD::MSUB;
+  SDValue MAddOps[3] = {AddOperand, Mult->getOperand(0), Mult->getOperand(1)};
+  EVT VTs[3] = {MVT::f32, MVT::f32, MVT::f32};
+  SDValue MAdd = CurDAG.getNode(Opcode, DL, VTs, MAddOps);
+
+  return MAdd;
+}
+
+static SDValue performSUBCombine(SDNode *N, SelectionDAG &DAG,
+                                 TargetLowering::DAGCombinerInfo &DCI,
+                                 const XtensaSubtarget &Subtarget) {
+  if (DCI.isBeforeLegalizeOps()) {
+    if (Subtarget.hasSingleFloat() && N->getValueType(0) == MVT::f32)
+      return performMADD_MSUBCombine(N, DAG, Subtarget);
+  }
+  return SDValue();
+}
+
+static SDValue performADDCombine(SDNode *N, SelectionDAG &DAG,
+                                 TargetLowering::DAGCombinerInfo &DCI,
+                                 const XtensaSubtarget &Subtarget) {
+  if (DCI.isBeforeLegalizeOps()) {
+    if (Subtarget.hasSingleFloat() && N->getValueType(0) == MVT::f32)
+      return performMADD_MSUBCombine(N, DAG, Subtarget);
+  }
+  return SDValue();
+}
+
+static SDValue PerformBRCONDCombine(SDNode *N, SelectionDAG &DAG,
+                                    TargetLowering::DAGCombinerInfo &DCI,
+                                    const XtensaSubtarget &Subtarget) {
+  if (DCI.isBeforeLegalizeOps()) {
+    SDValue Chain = N->getOperand(0);
+
+    if (N->getOperand(1).getOpcode() != ISD::SETCC)
+      return SDValue();
+
+    SDLoc DL(N);
+    SDValue SetCC = N->getOperand(1);
+    SDValue Dest = N->getOperand(2);
+    ISD::CondCode CC = cast<CondCodeSDNode>(SetCC->getOperand(2))->get();
+    SDValue LHS = SetCC->getOperand(0);
+    SDValue RHS = SetCC->getOperand(1);
+
+    if (LHS.getValueType() != MVT::i32)
+      return SDValue();
+
+    return DAG.getNode(ISD::BR_CC, DL, MVT::isVoid, Chain, DAG.getCondCode(CC),
+                       LHS, RHS, Dest);
+  }
+  return SDValue();
+}
+
+SDValue XtensaTargetLowering::PerformDAGCombine(SDNode *N,
+                                                DAGCombinerInfo &DCI) const {
+  SelectionDAG &DAG = DCI.DAG;
+  unsigned Opc = N->getOpcode();
+
+  switch (Opc) {
+  default:
+    break;
+  case ISD::FADD:
+    return performADDCombine(N, DAG, DCI, Subtarget);
+  case ISD::FSUB:
+    return performSUBCombine(N, DAG, DCI, Subtarget);
+  case ISD::BRCOND:
+    return PerformBRCONDCombine(N, DAG, DCI, Subtarget);
+  }
+
+  return SDValue();
+}
+
+//===----------------------------------------------------------------------===//
+// Calling conventions
+//===----------------------------------------------------------------------===//
+
+#include "XtensaGenCallingConv.inc"
+
+static bool CC_Xtensa_Custom(unsigned ValNo, MVT ValVT, MVT LocVT,
+                             CCValAssign::LocInfo LocInfo,
+                             ISD::ArgFlagsTy ArgFlags, CCState &State) {
+  static const MCPhysReg IntRegs[] = {Xtensa::A2, Xtensa::A3, Xtensa::A4,
+                                      Xtensa::A5, Xtensa::A6, Xtensa::A7};
+
+  if (ArgFlags.isByVal()) {
+    unsigned ByValAlign = ArgFlags.getByValAlign();
+    unsigned Offset = State.AllocateStack(ArgFlags.getByValSize(), ByValAlign);
+    State.addLoc(CCValAssign::getMem(ValNo, ValVT, Offset, LocVT, LocInfo));
+    // Allocate rest of registers, because rest part is not used to pass
+    // arguments
+    while (State.AllocateReg(IntRegs)) {
+    }
+    return false;
+  }
+
+  // Promote i8 and i16
+  if (LocVT == MVT::i8 || LocVT == MVT::i16) {
+    LocVT = MVT::i32;
+    if (ArgFlags.isSExt())
+      LocInfo = CCValAssign::SExt;
+    else if (ArgFlags.isZExt())
+      LocInfo = CCValAssign::ZExt;
+    else
+      LocInfo = CCValAssign::AExt;
+  }
+
+  unsigned Reg;
+
+  unsigned OrigAlign = ArgFlags.getOrigAlign();
+  bool isI64 = (ValVT == MVT::i32 && OrigAlign == 8);
+
+  if (ValVT == MVT::i32 || ValVT == MVT::f32) {
+    Reg = State.AllocateReg(IntRegs);
+    // If this is the first part of an i64 arg,
+    // the allocated register must be either A2, A4 or A6.
+    if (isI64 && (Reg == Xtensa::A3 || Reg == Xtensa::A5 || Reg == Xtensa::A7))
+      Reg = State.AllocateReg(IntRegs);
+    LocVT = MVT::i32;
+  } else if (ValVT == MVT::f64) {
+    // Allocate int register and shadow next int register.
+    Reg = State.AllocateReg(IntRegs);
+    if (Reg == Xtensa::A3 || Reg == Xtensa::A5 || Reg == Xtensa::A7)
+      Reg = State.AllocateReg(IntRegs);
+    State.AllocateReg(IntRegs);
+    LocVT = MVT::i32;
+  } else
+    llvm_unreachable("Cannot handle this ValVT.");
+
+  if (!Reg) {
+    unsigned Offset = State.AllocateStack(ValVT.getStoreSize(), OrigAlign);
+    State.addLoc(CCValAssign::getMem(ValNo, ValVT, Offset, LocVT, LocInfo));
+  } else
+    State.addLoc(CCValAssign::getReg(ValNo, ValVT, Reg, LocVT, LocInfo));
+
+  return false;
+}
+
+CCAssignFn *XtensaTargetLowering::CCAssignFnForCall(CallingConv::ID CC,
+                                                    bool IsVarArg) const {
+  return CC_Xtensa_Custom;
+}
+
+// Value is a value that has been passed to us in the location described by VA
+// (and so has type VA.getLocVT()).  Convert Value to VA.getValVT(), chaining
+// any loads onto Chain.
+static SDValue convertLocVTToValVT(SelectionDAG &DAG, const SDLoc &DL,
+                                   CCValAssign &VA, SDValue Chain,
+                                   SDValue Value) {
+  // If the argument has been promoted from a smaller type, insert an
+  // assertion to capture this.
+  if (VA.getLocInfo() == CCValAssign::SExt)
+    Value = DAG.getNode(ISD::AssertSext, DL, VA.getLocVT(), Value,
+                        DAG.getValueType(VA.getValVT()));
+  else if (VA.getLocInfo() == CCValAssign::ZExt)
+    Value = DAG.getNode(ISD::AssertZext, DL, VA.getLocVT(), Value,
+                        DAG.getValueType(VA.getValVT()));
+
+  if (VA.isExtInLoc())
+    Value = DAG.getNode(ISD::TRUNCATE, DL, VA.getValVT(), Value);
+  else if (VA.getLocInfo() == CCValAssign::Indirect)
+    Value = DAG.getLoad(VA.getValVT(), DL, Chain, Value, MachinePointerInfo());
+  else if (VA.getValVT() == MVT::f32)
+    Value = DAG.getNode(ISD::BITCAST, DL, VA.getValVT(), Value);
+  else
+    assert(VA.getLocInfo() == CCValAssign::Full && "Unsupported getLocInfo");
+  return Value;
+}
+
+// Value is a value of type VA.getValVT() that we need to copy into
+// the location described by VA.  Return a copy of Value converted to
+// VA.getValVT().  The caller is responsible for handling indirect values.
+static SDValue convertValVTToLocVT(SelectionDAG &DAG, SDLoc DL, CCValAssign &VA,
+                                   SDValue Value) {
+  switch (VA.getLocInfo()) {
+  case CCValAssign::SExt:
+    return DAG.getNode(ISD::SIGN_EXTEND, DL, VA.getLocVT(), Value);
+  case CCValAssign::ZExt:
+    return DAG.getNode(ISD::ZERO_EXTEND, DL, VA.getLocVT(), Value);
+  case CCValAssign::AExt:
+    return DAG.getNode(ISD::ANY_EXTEND, DL, VA.getLocVT(), Value);
+  case CCValAssign::BCvt:
+    return DAG.getNode(ISD::BITCAST, DL, VA.getLocVT(), Value);
+  case CCValAssign::Full:
+    return Value;
+  default:
+    llvm_unreachable("Unhandled getLocInfo()");
+  }
+}
+
+SDValue XtensaTargetLowering::LowerFormalArguments(
+    SDValue Chain, CallingConv::ID CallConv, bool IsVarArg,
+    const SmallVectorImpl<ISD::InputArg> &Ins, const SDLoc &DL,
+    SelectionDAG &DAG, SmallVectorImpl<SDValue> &InVals) const {
+  MachineFunction &MF = DAG.getMachineFunction();
+  MachineFrameInfo &MFI = MF.getFrameInfo();
+  XtensaFunctionInfo *XtensaFI = MF.getInfo<XtensaFunctionInfo>();
+  EVT PtrVT = getPointerTy(MF.getDataLayout());
+
+  XtensaFI->setVarArgsFrameIndex(0);
+
+  // Used with vargs to acumulate store chains.
+  std::vector<SDValue> OutChains;
+
+  // Assign locations to all of the incoming arguments.
+  SmallVector<CCValAssign, 16> ArgLocs;
+  CCState CCInfo(CallConv, IsVarArg, DAG.getMachineFunction(), ArgLocs,
+                 *DAG.getContext());
+
+  CCInfo.AnalyzeFormalArguments(Ins, CCAssignFnForCall(CallConv, IsVarArg));
+
+  for (unsigned i = 0, e = ArgLocs.size(); i != e; ++i) {
+    CCValAssign &VA = ArgLocs[i];
+    // Arguments stored on registers
+    if (VA.isRegLoc()) {
+      EVT RegVT = VA.getLocVT();
+      const TargetRegisterClass *RC;
+
+      if (RegVT == MVT::i32) {
+        RC = &Xtensa::ARRegClass;
+      } else
+        llvm_unreachable("RegVT not supported by FormalArguments Lowering");
+
+      // Transform the arguments stored on
+      // physical registers into virtual ones
+      unsigned Reg = 0;
+      unsigned FrameReg = Subtarget.getRegisterInfo()->getFrameRegister(MF);
+
+      // Argument passed in FrameReg in WinABI we save in A8 (in emitPrologue),
+      // so load argument from A8
+      if (Subtarget.isWinABI() && (VA.getLocReg() == FrameReg)) {
+        Reg = MF.addLiveIn(Xtensa::A8, RC);
+      } else {
+        Reg = MF.addLiveIn(VA.getLocReg(), RC);
+      }
+
+      SDValue ArgValue = DAG.getCopyFromReg(Chain, DL, Reg, RegVT);
+
+      // If this is an 8 or 16-bit value, it has been passed promoted
+      // to 32 bits.  Insert an assert[sz]ext to capture this, then
+      // truncate to the right size.
+      if (VA.getLocInfo() != CCValAssign::Full) {
+        unsigned Opcode = 0;
+        if (VA.getLocInfo() == CCValAssign::SExt)
+          Opcode = ISD::AssertSext;
+        else if (VA.getLocInfo() == CCValAssign::ZExt)
+          Opcode = ISD::AssertZext;
+        if (Opcode)
+          ArgValue = DAG.getNode(Opcode, DL, RegVT, ArgValue,
+                                 DAG.getValueType(VA.getValVT()));
+        if (VA.getValVT() == MVT::f32)
+          ArgValue = DAG.getNode(ISD::BITCAST, DL, VA.getValVT(), ArgValue);
+        else
+          ArgValue = DAG.getNode(ISD::TRUNCATE, DL, VA.getValVT(), ArgValue);
+      }
+
+      InVals.push_back(ArgValue);
+
+    } else { // !VA.isRegLoc()
+      // sanity check
+      assert(VA.isMemLoc());
+
+      EVT ValVT = VA.getValVT();
+
+      // The stack pointer offset is relative to the caller stack frame.
+      int FI = MFI.CreateFixedObject(ValVT.getSizeInBits() / 8,
+                                     VA.getLocMemOffset(), true);
+
+      if (Ins[VA.getValNo()].Flags.isByVal()) {
+        // Assume that in this case load operation is created
+        SDValue FIN = DAG.getFrameIndex(FI, MVT::i32);
+        InVals.push_back(FIN);
+      } else {
+        // Create load nodes to retrieve arguments from the stack
+        SDValue FIN = DAG.getFrameIndex(FI, getPointerTy(DAG.getDataLayout()));
+        InVals.push_back(DAG.getLoad(
+            ValVT, DL, Chain, FIN,
+            MachinePointerInfo::getFixedStack(DAG.getMachineFunction(), FI)));
+      }
+    }
+  }
+
+  if (IsVarArg) {
+    ArrayRef<MCPhysReg> ArgRegs = makeArrayRef(XtensaArgRegs);
+    unsigned Idx = CCInfo.getFirstUnallocated(ArgRegs);
+    const TargetRegisterClass *RC = &Xtensa::ARRegClass;
+    MachineFrameInfo &MFI = MF.getFrameInfo();
+    MachineRegisterInfo &RegInfo = MF.getRegInfo();
+    unsigned RegSize = 4;
+    MVT RegTy = MVT::getIntegerVT(RegSize * 8);
+
+    XtensaFI->setVarArgsFirstGPR(Idx + 2); // 2 - number of a2 register
+
+    XtensaFI->setVarArgsStackOffset(MFI.CreateFixedObject(
+        PtrVT.getSizeInBits() / 8, CCInfo.getNextStackOffset(), true));
+
+    // Offset of the first variable argument from stack pointer, and size of
+    // the vararg save area. For now, the varargs save area is either zero or
+    // large enough to hold a0-a7.
+    int VaArgOffset, VarArgsSaveSize;
+
+    // If all registers are allocated, then all varargs must be passed on the
+    // stack and we don't need to save any argregs.
+    if (ArgRegs.size() == Idx) {
+      VaArgOffset = CCInfo.getNextStackOffset();
+      VarArgsSaveSize = 0;
+    } else {
+      VarArgsSaveSize = RegSize * (ArgRegs.size() - Idx);
+      VaArgOffset = -VarArgsSaveSize;
+    }
+
+    // Record the frame index of the first variable argument
+    // which is a value necessary to VASTART.
+    int FI = MFI.CreateFixedObject(RegSize, VaArgOffset, true);
+    XtensaFI->setVarArgsFrameIndex(FI);
+
+    // Copy the integer registers that may have been used for passing varargs
+    // to the vararg save area.
+    for (unsigned I = Idx; I < ArgRegs.size(); ++I, VaArgOffset += RegSize) {
+      const unsigned Reg = RegInfo.createVirtualRegister(RC);
+      unsigned FrameReg = Subtarget.getRegisterInfo()->getFrameRegister(MF);
+
+      // Argument passed in FrameReg we save in A8 (in emitPrologue),
+      // so load argument from A8
+      if (ArgRegs[I] == FrameReg) {
+        RegInfo.addLiveIn(Xtensa::A8, Reg);
+      } else {
+        RegInfo.addLiveIn(ArgRegs[I], Reg);
+      }
+
+      SDValue ArgValue = DAG.getCopyFromReg(Chain, DL, Reg, RegTy);
+      FI = MFI.CreateFixedObject(RegSize, VaArgOffset, true);
+      SDValue PtrOff = DAG.getFrameIndex(FI, getPointerTy(DAG.getDataLayout()));
+      SDValue Store = DAG.getStore(Chain, DL, ArgValue, PtrOff,
+                                   MachinePointerInfo::getFixedStack(MF, FI));
+      cast<StoreSDNode>(Store.getNode())
+          ->getMemOperand()
+          ->setValue((Value *)nullptr);
+      OutChains.push_back(Store);
+    }
+  }
+
+  // All stores are grouped in one node to allow the matching between
+  // the size of Ins and InVals. This only happens when on varg functions
+  if (!OutChains.empty()) {
+    OutChains.push_back(Chain);
+    Chain = DAG.getNode(ISD::TokenFactor, DL, MVT::Other, OutChains);
+  }
+
+  return Chain;
+}
+
+SDValue XtensaTargetLowering::getAddrPCRel(SDValue Op,
+                                           SelectionDAG &DAG) const {
+  SDLoc DL(Op);
+  EVT Ty = Op.getValueType();
+  return DAG.getNode(XtensaISD::PCREL_WRAPPER, DL, Ty, Op);
+}
+
+SDValue
+XtensaTargetLowering::LowerCall(CallLoweringInfo &CLI,
+                                SmallVectorImpl<SDValue> &InVals) const {
+  SelectionDAG &DAG = CLI.DAG;
+  SDLoc &DL = CLI.DL;
+  SmallVector<ISD::OutputArg, 32> &Outs = CLI.Outs;
+  SmallVector<SDValue, 32> &OutVals = CLI.OutVals;
+  SmallVector<ISD::InputArg, 32> &Ins = CLI.Ins;
+  SDValue Chain = CLI.Chain;
+  SDValue Callee = CLI.Callee;
+  bool &IsTailCall = CLI.IsTailCall;
+  CallingConv::ID CallConv = CLI.CallConv;
+  bool IsVarArg = CLI.IsVarArg;
+
+  MachineFunction &MF = DAG.getMachineFunction();
+  EVT PtrVT = getPointerTy(DAG.getDataLayout());
+  const TargetFrameLowering *TFL = Subtarget.getFrameLowering();
+
+  // TODO: Support tail call optimization.
+  IsTailCall = false;
+
+  // Analyze the operands of the call, assigning locations to each operand.
+  SmallVector<CCValAssign, 16> ArgLocs;
+  CCState CCInfo(CallConv, IsVarArg, MF, ArgLocs, *DAG.getContext());
+
+  CCAssignFn *CC = CCAssignFnForCall(CallConv, IsVarArg);
+
+  CCInfo.AnalyzeCallOperands(Outs, CC);
+
+  // Get a count of how many bytes are to be pushed on the stack.
+  unsigned NumBytes = CCInfo.getNextStackOffset();
+
+  unsigned StackAlignment = TFL->getStackAlignment();
+  unsigned NextStackOffset = alignTo(NumBytes, StackAlignment);
+
+  Chain = DAG.getCALLSEQ_START(Chain, NextStackOffset, 0, DL);
+
+  // Copy argument values to their designated locations.
+  std::deque<std::pair<unsigned, SDValue>> RegsToPass;
+  SmallVector<SDValue, 8> MemOpChains;
+  SDValue StackPtr;
+  for (unsigned I = 0, E = ArgLocs.size(); I != E; ++I) {
+    CCValAssign &VA = ArgLocs[I];
+    SDValue ArgValue = OutVals[I];
+    ISD::ArgFlagsTy Flags = Outs[I].Flags;
+
+    ArgValue = convertValVTToLocVT(DAG, DL, VA, ArgValue);
+
+    if (VA.isRegLoc())
+      // Queue up the argument copies and emit them at the end.
+      RegsToPass.push_back(std::make_pair(VA.getLocReg(), ArgValue));
+    else if (Flags.isByVal()) {
+      assert(VA.isMemLoc());
+      assert(Flags.getByValSize() &&
+             "ByVal args of size 0 should have been ignored by front-end.");
+      assert(!IsTailCall &&
+             "Do not tail-call optimize if there is a byval argument.");
+
+      if (!StackPtr.getNode())
+        StackPtr = DAG.getCopyFromReg(Chain, DL, Xtensa::SP, PtrVT);
+      unsigned Offset = VA.getLocMemOffset();
+      SDValue Address = DAG.getNode(ISD::ADD, DL, PtrVT, StackPtr,
+                                    DAG.getIntPtrConstant(Offset, DL));
+      SDValue SizeNode = DAG.getConstant(Flags.getByValSize(), DL, MVT::i32);
+      SDValue Memcpy = DAG.getMemcpy(
+          Chain, DL, Address, ArgValue, SizeNode, Flags.getByValAlign(),
+          /*isVolatile=*/false, /*AlwaysInline=*/false,
+          /*isTailCall=*/false, MachinePointerInfo(), MachinePointerInfo());
+      MemOpChains.push_back(Memcpy);
+    } else {
+      assert(VA.isMemLoc() && "Argument not register or memory");
+
+      // Work out the address of the stack slot.  Unpromoted ints and
+      // floats are passed as right-justified 8-byte values.
+      if (!StackPtr.getNode())
+        StackPtr = DAG.getCopyFromReg(Chain, DL, Xtensa::SP, PtrVT);
+      unsigned Offset = VA.getLocMemOffset();
+      SDValue Address = DAG.getNode(ISD::ADD, DL, PtrVT, StackPtr,
+                                    DAG.getIntPtrConstant(Offset, DL));
+
+      // Emit the store.
+      MemOpChains.push_back(
+          DAG.getStore(Chain, DL, ArgValue, Address, MachinePointerInfo()));
+    }
+  }
+
+  // Join the stores, which are independent of one another.
+  if (!MemOpChains.empty())
+    Chain = DAG.getNode(ISD::TokenFactor, DL, MVT::Other, MemOpChains);
+
+  // Build a sequence of copy-to-reg nodes, chained and glued together.
+  SDValue Glue;
+  for (unsigned I = 0, E = RegsToPass.size(); I != E; ++I) {
+    unsigned Reg = RegsToPass[I].first;
+    if (Subtarget.isWinABI())
+      Reg = toCallerWindow(Reg);
+    Chain = DAG.getCopyToReg(Chain, DL, Reg, RegsToPass[I].second, Glue);
+    Glue = Chain.getValue(1);
+  }
+
+  std::string name;
+  unsigned char TF = 0;
+
+  // Accept direct calls by converting symbolic call addresses to the
+  // associated Target* opcodes.
+  if (ExternalSymbolSDNode *E = dyn_cast<ExternalSymbolSDNode>(Callee)) {
+    name = E->getSymbol();
+    TF = E->getTargetFlags();
+    if (isPositionIndependent()) {
+      report_fatal_error("PIC relocations is not supported");
+    } else
+      Callee = DAG.getTargetExternalSymbol(E->getSymbol(), PtrVT, TF);
+  } else if (GlobalAddressSDNode *G = dyn_cast<GlobalAddressSDNode>(Callee)) {
+    // TODO replace GlobalAddress to some special operand instead of
+    // ExternalSymbol
+    //   Callee =
+    //   DAG.getTargetExternalSymbol(strdup(G->getGlobal()->getName().str().c_str()),
+    //   PtrVT);
+
+    const GlobalValue *GV = G->getGlobal();
+    name = GV->getName().str();
+  }
+
+  if ((!name.empty()) && isLongCall(name.c_str())) {
+    // Create a constant pool entry for the callee address
+    XtensaCP::XtensaCPModifier Modifier = XtensaCP::no_modifier;
+
+    XtensaConstantPoolValue *CPV = XtensaConstantPoolSymbol::Create(
+        *DAG.getContext(), name.c_str(), 0 /* XtensaCLabelIndex */, false,
+        Modifier);
+
+    // Get the address of the callee into a register
+    SDValue CPAddr = DAG.getTargetConstantPool(CPV, PtrVT, 4, 0, TF);
+    SDValue CPWrap = getAddrPCRel(CPAddr, DAG);
+    Callee = CPWrap;
+  }
+
+  // The first call operand is the chain and the second is the target address.
+  SmallVector<SDValue, 8> Ops;
+  Ops.push_back(Chain);
+  Ops.push_back(Callee);
+
+  // Add a register mask operand representing the call-preserved registers.
+  const TargetRegisterInfo *TRI = Subtarget.getRegisterInfo();
+  const uint32_t *Mask = TRI->getCallPreservedMask(MF, CallConv);
+  assert(Mask && "Missing call preserved mask for calling convention");
+  Ops.push_back(DAG.getRegisterMask(Mask));
+
+  // Add argument registers to the end of the list so that they are
+  // known live into the call.
+  for (unsigned I = 0, E = RegsToPass.size(); I != E; ++I) {
+    unsigned Reg = RegsToPass[I].first;
+    if (Subtarget.isWinABI())
+      Reg = toCallerWindow(Reg);
+    Ops.push_back(DAG.getRegister(Reg, RegsToPass[I].second.getValueType()));
+  }
+
+  // Glue the call to the argument copies, if any.
+  if (Glue.getNode())
+    Ops.push_back(Glue);
+
+  SDVTList NodeTys = DAG.getVTList(MVT::Other, MVT::Glue);
+  Chain = DAG.getNode(Subtarget.isWinABI() ? XtensaISD::CALLW : XtensaISD::CALL,
+                      DL, NodeTys, Ops);
+  Glue = Chain.getValue(1);
+
+  // Mark the end of the call, which is glued to the call itself.
+  Chain = DAG.getCALLSEQ_END(Chain, DAG.getConstant(NumBytes, DL, PtrVT, true),
+                             DAG.getConstant(0, DL, PtrVT, true), Glue, DL);
+  Glue = Chain.getValue(1);
+
+  // Assign locations to each value returned by this call.
+  SmallVector<CCValAssign, 16> RetLocs;
+  CCState RetCCInfo(CallConv, IsVarArg, MF, RetLocs, *DAG.getContext());
+  RetCCInfo.AnalyzeCallResult(Ins, Subtarget.isWinABI() ? RetCCW_Xtensa
+                                                        : RetCC_Xtensa);
+
+  // Copy all of the result registers out of their specified physreg.
+  for (unsigned I = 0, E = RetLocs.size(); I != E; ++I) {
+    CCValAssign &VA = RetLocs[I];
+
+    // Copy the value out, gluing the copy to the end of the call sequence.
+    unsigned Reg = VA.getLocReg();
+    SDValue RetValue = DAG.getCopyFromReg(Chain, DL, Reg, VA.getLocVT(), Glue);
+    Chain = RetValue.getValue(1);
+    Glue = RetValue.getValue(2);
+
+    // Convert the value of the return register into the value that's
+    // being returned.
+    InVals.push_back(convertLocVTToValVT(DAG, DL, VA, Chain, RetValue));
+  }
+  return Chain;
+}
+
+bool XtensaTargetLowering::CanLowerReturn(
+    CallingConv::ID CallConv, MachineFunction &MF, bool IsVarArg,
+    const SmallVectorImpl<ISD::OutputArg> &Outs, LLVMContext &Context) const {
+  SmallVector<CCValAssign, 16> RVLocs;
+  CCState CCInfo(CallConv, IsVarArg, MF, RVLocs, Context);
+  return CCInfo.CheckReturn(Outs, RetCC_Xtensa);
+}
+
+SDValue
+XtensaTargetLowering::LowerReturn(SDValue Chain, CallingConv::ID CallConv,
+                                  bool IsVarArg,
+                                  const SmallVectorImpl<ISD::OutputArg> &Outs,
+                                  const SmallVectorImpl<SDValue> &OutVals,
+                                  const SDLoc &DL, SelectionDAG &DAG) const {
+  MachineFunction &MF = DAG.getMachineFunction();
+
+  // Assign locations to each returned value.
+  SmallVector<CCValAssign, 16> RetLocs;
+  CCState RetCCInfo(CallConv, IsVarArg, MF, RetLocs, *DAG.getContext());
+  RetCCInfo.AnalyzeReturn(Outs, RetCC_Xtensa);
+
+  SDValue Glue;
+  // Quick exit for void returns
+  if (RetLocs.empty())
+    return DAG.getNode(Subtarget.isWinABI() ? XtensaISD::RETW_FLAG
+                                            : XtensaISD::RET_FLAG,
+                       DL, MVT::Other, Chain);
+
+  // Copy the result values into the output registers.
+  SmallVector<SDValue, 4> RetOps;
+  RetOps.push_back(Chain);
+  for (unsigned I = 0, E = RetLocs.size(); I != E; ++I) {
+    CCValAssign &VA = RetLocs[I];
+    SDValue RetValue = OutVals[I];
+
+    // Make the return register live on exit.
+    assert(VA.isRegLoc() && "Can only return in registers!");
+
+    // Promote the value as required.
+    RetValue = convertValVTToLocVT(DAG, DL, VA, RetValue);
+
+    // Chain and glue the copies together.
+    unsigned Reg = VA.getLocReg();
+    Chain = DAG.getCopyToReg(Chain, DL, Reg, RetValue, Glue);
+    Glue = Chain.getValue(1);
+    RetOps.push_back(DAG.getRegister(Reg, VA.getLocVT()));
+  }
+
+  // Update chain and glue.
+  RetOps[0] = Chain;
+  if (Glue.getNode())
+    RetOps.push_back(Glue);
+
+  return DAG.getNode(Subtarget.isWinABI() ? XtensaISD::RETW_FLAG
+                                          : XtensaISD::RET_FLAG,
+                     DL, MVT::Other, RetOps);
+}
+
+static SDValue EmitCMP(SDValue &LHS, SDValue &RHS, ISD::CondCode CC, SDLoc dl,
+                       SelectionDAG &DAG, int &br_code) {
+  // Minor optimization: if LHS is a constant, swap operands, then the
+  // constant can be folded into comparison.
+  if (LHS.getOpcode() == ISD::Constant)
+    std::swap(LHS, RHS);
+  int cmp_code = 0;
+
+  switch (CC) {
+  default:
+    llvm_unreachable("Invalid condition!");
+    break;
+  case ISD::SETUNE:
+    br_code = XtensaISD::BR_CC_F;
+    cmp_code = XtensaISD::CMPOEQ;
+    break;
+  case ISD::SETUO:
+    br_code = XtensaISD::BR_CC_T;
+    cmp_code = XtensaISD::CMPUO;
+    break;
+  case ISD::SETO:
+    br_code = XtensaISD::BR_CC_F;
+    cmp_code = XtensaISD::CMPUO;
+    break;
+  case ISD::SETUEQ:
+    br_code = XtensaISD::BR_CC_T;
+    cmp_code = XtensaISD::CMPUEQ;
+    break;
+  case ISD::SETULE:
+    br_code = XtensaISD::BR_CC_T;
+    cmp_code = XtensaISD::CMPULE;
+    break;
+  case ISD::SETULT:
+    br_code = XtensaISD::BR_CC_T;
+    cmp_code = XtensaISD::CMPULT;
+    break;
+  case ISD::SETEQ:
+  case ISD::SETOEQ:
+    br_code = XtensaISD::BR_CC_T;
+    cmp_code = XtensaISD::CMPOEQ;
+    break;
+  case ISD::SETNE:
+    br_code = XtensaISD::BR_CC_F;
+    cmp_code = XtensaISD::CMPOEQ;
+    break;
+  case ISD::SETLE:
+  case ISD::SETOLE:
+    br_code = XtensaISD::BR_CC_T;
+    cmp_code = XtensaISD::CMPOLE;
+    break;
+  case ISD::SETLT:
+  case ISD::SETOLT:
+    br_code = XtensaISD::BR_CC_T;
+    cmp_code = XtensaISD::CMPOLT;
+    break;
+  case ISD::SETGE:
+    br_code = XtensaISD::BR_CC_F;
+    cmp_code = XtensaISD::CMPOLT;
+    break;
+  case ISD::SETGT:
+    br_code = XtensaISD::BR_CC_F;
+    cmp_code = XtensaISD::CMPOLE;
+    break;
+  }
+  return DAG.getNode(cmp_code, dl, MVT::i1, LHS, RHS);
+}
+
+SDValue XtensaTargetLowering::LowerBR_CC(SDValue Op, SelectionDAG &DAG) const {
+  SDValue Chain = Op.getOperand(0);
+  ISD::CondCode CC = cast<CondCodeSDNode>(Op.getOperand(1))->get();
+  SDValue LHS = Op.getOperand(2);
+  SDValue RHS = Op.getOperand(3);
+  SDValue Dest = Op.getOperand(4);
+  SDLoc DL(Op);
+
+  if (LHS.getValueType() == MVT::f32) {
+    int br_code;
+    SDValue Flag = EmitCMP(LHS, RHS, CC, DL, DAG, br_code);
+    return DAG.getNode(br_code, DL, Op.getValueType(), Chain, Flag, Dest);
+  } else {
+    llvm_unreachable("invalid BR_CC to lower");
+  }
+}
+
+SDValue XtensaTargetLowering::LowerSELECT_CC(SDValue Op,
+                                             SelectionDAG &DAG) const {
+  SDLoc DL(Op);
+  EVT Ty = Op.getOperand(0).getValueType();
+  SDValue LHS = Op.getOperand(0);
+  SDValue RHS = Op.getOperand(1);
+  SDValue TrueV = Op.getOperand(2);
+  SDValue FalseV = Op.getOperand(3);
+  ISD::CondCode CC = cast<CondCodeSDNode>(Op->getOperand(4))->get();
+  SDValue TargetCC = DAG.getConstant(CC, DL, MVT::i32);
+
+  // Wrap select nodes
+  if (LHS.getValueType() == MVT::f32)
+    return DAG.getNode(XtensaISD::SELECT_CC_FP, DL, TrueV.getValueType(), LHS,
+                       RHS, TrueV, FalseV, TargetCC);
+  else if (TrueV.getValueType() == MVT::f32)
+    return DAG.getNode(XtensaISD::SELECT_CC_FP, DL, TrueV.getValueType(), LHS,
+                       RHS, TrueV, FalseV, TargetCC);
+  else
+    return DAG.getNode(XtensaISD::SELECT_CC, DL, Ty, LHS, RHS, TrueV, FalseV,
+                       TargetCC);
+}
+
+SDValue XtensaTargetLowering::LowerSETCC(SDValue Op, SelectionDAG &DAG) const {
+  SDLoc DL(Op);
+  EVT Ty = Op.getOperand(0).getValueType();
+  SDValue LHS = Op.getOperand(0);
+  SDValue RHS = Op.getOperand(1);
+  ISD::CondCode CC = cast<CondCodeSDNode>(Op.getOperand(2))->get();
+  SDValue TargetCC = DAG.getConstant(CC, DL, MVT::i32);
+
+  // Check Op SDNode users
+  // If there are only CALL/CALLW nodes, don't expand Global Address
+  SDNode &OpNode = *Op.getNode();
+  bool Val = false;
+  for (SDNode::use_iterator UI = OpNode.use_begin(); UI != OpNode.use_end();
+       ++UI) {
+    SDNode &User = *UI.getUse().getUser();
+    unsigned OpCode = User.getOpcode();
+    if (OpCode == ISD::BRCOND) {
+      Val = true;
+      break;
+    }
+  }
+
+  // SETCC has BRCOND predecessor, return original operation
+  if (Val)
+    return Op;
+
+  // Expand to target SELECT_CC
+  SDValue TrueV = DAG.getConstant(1, DL, Op.getValueType());
+  SDValue FalseV = DAG.getConstant(0, DL, Op.getValueType());
+
+  if (LHS.getValueType() == MVT::f32)
+    return DAG.getNode(XtensaISD::SELECT_CC_FP, DL, TrueV.getValueType(), LHS,
+                       RHS, TrueV, FalseV, TargetCC);
+  else if (TrueV.getValueType() == MVT::f32)
+    return DAG.getNode(XtensaISD::SELECT_CC_FP, DL, TrueV.getValueType(), LHS,
+                       RHS, TrueV, FalseV, TargetCC);
+  else
+    return DAG.getNode(XtensaISD::SELECT_CC, DL, Ty, LHS, RHS, TrueV, FalseV,
+                       TargetCC);
+}
+
+SDValue XtensaTargetLowering::LowerRETURNADDR(SDValue Op,
+                                              SelectionDAG &DAG) const {
+  // check the depth
+  // TODO: xtensa-gcc can handle this, by navigating through the stack, we
+  // should be able to do this too
+  assert((cast<ConstantSDNode>(Op.getOperand(0))->getZExtValue() == 0) &&
+         "Return address can be determined only for current frame.");
+
+  MachineFunction &MF = DAG.getMachineFunction();
+  MachineFrameInfo &MFI = MF.getFrameInfo();
+  MVT VT = Op.getSimpleValueType();
+  unsigned RA = Xtensa::A0;
+  MFI.setReturnAddressIsTaken(true);
+
+  // Return RA, which contains the return address. Mark it an implicit
+  // live-in.
+  unsigned Reg = MF.addLiveIn(RA, getRegClassFor(VT));
+  return DAG.getCopyFromReg(DAG.getEntryNode(), SDLoc(Op), Reg, VT);
+}
+
+SDValue XtensaTargetLowering::LowerImmediate(SDValue Op,
+                                             SelectionDAG &DAG) const {
+  const ConstantSDNode *CN = cast<ConstantSDNode>(Op);
+  SDLoc DL(CN);
+  APInt apval = CN->getAPIntValue();
+  int64_t value = apval.getSExtValue();
+  if (Op.getValueType() == MVT::i32) {
+    if (value > -2048 && value <= 2047)
+      return Op;
+    Type *Ty = Type::getInt32Ty(*DAG.getContext());
+    Constant *CV = ConstantInt::get(Ty, value);
+    SDValue CP = DAG.getConstantPool(CV, MVT::i32, 0, 0, false);
+    return CP;
+  }
+  return Op;
+}
+
+SDValue XtensaTargetLowering::LowerImmediateFP(SDValue Op,
+                                               SelectionDAG &DAG) const {
+  const ConstantFPSDNode *CN = cast<ConstantFPSDNode>(Op);
+  SDLoc DL(CN);
+  APFloat apval = CN->getValueAPF();
+  int64_t value = FloatToBits(CN->getValueAPF().convertToFloat());
+  if (Op.getValueType() == MVT::f32) {
+    Type *Ty = Type::getInt32Ty(*DAG.getContext());
+    Constant *CV = ConstantInt::get(Ty, value);
+    SDValue CP = DAG.getConstantPool(CV, MVT::i32, 0, 0, false);
+    return DAG.getNode(ISD::BITCAST, DL, MVT::f32, CP);
+  }
+  return Op;
+}
+
+SDValue XtensaTargetLowering::LowerGlobalAddress(SDValue Op,
+                                                 SelectionDAG &DAG) const {
+  //  Reloc::Model RM = DAG.getTarget().getRelocationModel();
+  SDLoc DL(Op);
+
+  if (GlobalAddressSDNode *G = dyn_cast<GlobalAddressSDNode>(Op)) {
+    auto PtrVt = getPointerTy(DAG.getDataLayout());
+    const GlobalValue *GV = G->getGlobal();
+
+    // Check Op SDNode users
+    // If there are only CALL/CALLW nodes, don't expand Global Address
+    SDNode &OpNode = *Op.getNode();
+    bool Val = false;
+    for (SDNode::use_iterator UI = OpNode.use_begin(); UI != OpNode.use_end();
+         ++UI) {
+      SDNode &User = *UI.getUse().getUser();
+      unsigned OpCode = User.getOpcode();
+      if (OpCode != XtensaISD::CALL && OpCode != XtensaISD::CALLW) {
+        Val = true;
+        break;
+      }
+    }
+    if (!Val) {
+      SDValue TargAddr = DAG.getTargetGlobalAddress(G->getGlobal(), DL, PtrVt,
+                                                    0, 0 /* TargetFlags */);
+      return TargAddr;
+    }
+
+    SDValue CPAddr = DAG.getTargetConstantPool(GV, PtrVt, 4);
+    SDValue CPWrap = getAddrPCRel(CPAddr, DAG);
+
+    return CPWrap;
+  }
+  llvm_unreachable("invalid global addresses to lower");
+}
+
+SDValue XtensaTargetLowering::LowerGlobalTLSAddress(GlobalAddressSDNode *GA,
+                                                    SelectionDAG &DAG) const {
+  SDLoc DL(GA);
+  const GlobalValue *GV = GA->getGlobal();
+  EVT PtrVT = getPointerTy(DAG.getDataLayout());
+
+  if (DAG.getTarget().useEmulatedTLS())
+    return LowerToTLSEmulatedModel(GA, DAG);
+
+  TLSModel::Model model = getTargetMachine().getTLSModel(GV);
+
+  if (!Subtarget.hasTHREADPTR()) {
+    llvm_unreachable("only emulated TLS supported");
+  }
+
+  if ((model == TLSModel::LocalExec) || (model == TLSModel::InitialExec)) {
+    auto PtrVt = getPointerTy(DAG.getDataLayout());
+
+    bool Priv = GV->isPrivateLinkage(GV->getLinkage());
+    // Create a constant pool entry for the callee address
+    XtensaConstantPoolValue *CPV = XtensaConstantPoolSymbol::Create(
+        *DAG.getContext(), GV->getName().str().c_str() /* Sym */,
+        0 /* XtensaCLabelIndex */, Priv, XtensaCP::TPOFF);
+
+    // Get the address of the callee into a register
+    SDValue CPAddr = DAG.getTargetConstantPool(CPV, PtrVt, 4);
+    SDValue CPWrap = getAddrPCRel(CPAddr, DAG);
+
+    SDValue TPRegister = DAG.getRegister(Xtensa::THREADPTR, MVT::i32);
+    SDValue ThreadPointer =
+        DAG.getNode(XtensaISD::RUR, DL, MVT::i32, TPRegister);
+    return DAG.getNode(ISD::ADD, DL, PtrVT, ThreadPointer, CPWrap);
+  } else
+    llvm_unreachable("only local-exec and initial-exec TLS mode supported");
+
+  return SDValue();
+}
+
+SDValue XtensaTargetLowering::LowerBlockAddress(BlockAddressSDNode *Node,
+                                                SelectionDAG &DAG) const {
+  const BlockAddress *BA = Node->getBlockAddress();
+  EVT PtrVT = getPointerTy(DAG.getDataLayout());
+
+  XtensaConstantPoolValue *CPV =
+      XtensaConstantPoolConstant::Create(BA, 0, XtensaCP::CPBlockAddress, 0);
+  SDValue CPAddr = DAG.getTargetConstantPool(CPV, PtrVT, 4);
+
+  SDValue CPWrap = getAddrPCRel(CPAddr, DAG);
+  return CPWrap;
+}
+
+SDValue XtensaTargetLowering::LowerBR_JT(SDValue Op, SelectionDAG &DAG) const {
+  SDValue Chain = Op.getOperand(0);
+  SDValue Table = Op.getOperand(1);
+  SDValue Index = Op.getOperand(2);
+  SDLoc DL(Op);
+  JumpTableSDNode *JT = cast<JumpTableSDNode>(Table);
+  MachineFunction &MF = DAG.getMachineFunction();
+  const MachineJumpTableInfo *MJTI = MF.getJumpTableInfo();
+
+  SDValue TargetJT = DAG.getTargetJumpTable(JT->getIndex(), MVT::i32);
+
+  const DataLayout &TD = DAG.getDataLayout();
+  EVT PTy = getPointerTy(TD);
+
+  unsigned EntrySize = MJTI->getEntrySize(TD);
+
+  Index = DAG.getNode(ISD::MUL, DL, Index.getValueType(), Index,
+                      DAG.getConstant(EntrySize, DL, Index.getValueType()));
+  SDValue Addr = DAG.getNode(ISD::ADD, DL, Index.getValueType(), Index, Table);
+
+  EVT MemVT = EVT::getIntegerVT(*DAG.getContext(), EntrySize * 8);
+  SDValue LD = DAG.getExtLoad(ISD::SEXTLOAD, DL, PTy, Chain, Addr,
+                              MachinePointerInfo::getJumpTable(MF), MemVT);
+  Addr = LD;
+
+  return DAG.getNode(XtensaISD::BR_JT, DL, MVT::Other, LD.getValue(1), Addr,
+                     TargetJT);
+}
+
+SDValue XtensaTargetLowering::LowerJumpTable(JumpTableSDNode *JT,
+                                             SelectionDAG &DAG) const {
+  SDLoc DL(JT);
+  EVT PtrVt = getPointerTy(DAG.getDataLayout());
+
+  // Create a constant pool entry for the callee address
+  XtensaConstantPoolValue *CPV =
+      XtensaConstantPoolJumpTable::Create(*DAG.getContext(), JT->getIndex());
+
+  // Get the address of the callee into a register
+  SDValue CPAddr = DAG.getTargetConstantPool(CPV, PtrVt, 4);
+  SDValue CPWrap = getAddrPCRel(CPAddr, DAG);
+
+  return CPWrap;
+}
+
+SDValue XtensaTargetLowering::LowerConstantPool(ConstantPoolSDNode *CP,
+                                                SelectionDAG &DAG) const {
+  EVT PtrVT = getPointerTy(DAG.getDataLayout());
+
+  SDValue Result;
+  if (CP->isMachineConstantPoolEntry())
+    Result = DAG.getTargetConstantPool(CP->getMachineCPVal(), PtrVT,
+                                       CP->getAlignment());
+  else
+    Result = DAG.getTargetConstantPool(CP->getConstVal(), PtrVT,
+                                       CP->getAlignment(), CP->getOffset());
+
+  return getAddrPCRel(Result, DAG);
+}
+
+SDValue XtensaTargetLowering::LowerSTACKSAVE(SDValue Op,
+                                             SelectionDAG &DAG) const {
+  unsigned sp = Xtensa::SP;
+  return DAG.getCopyFromReg(Op.getOperand(0), SDLoc(Op), sp, Op.getValueType());
+}
+
+SDValue XtensaTargetLowering::LowerSTACKRESTORE(SDValue Op,
+                                                SelectionDAG &DAG) const {
+  unsigned sp = Xtensa::SP;
+  if (Subtarget.isWinABI()) {
+    SDValue NewSP =
+        DAG.getNode(XtensaISD::MOVSP, SDLoc(Op), MVT::i32, Op.getOperand(1));
+    return DAG.getCopyToReg(Op.getOperand(0), SDLoc(Op), sp, NewSP);
+  } else {
+    return DAG.getCopyToReg(Op.getOperand(0), SDLoc(Op), sp, Op.getOperand(1));
+  }
+}
+
+SDValue XtensaTargetLowering::LowerFRAMEADDR(SDValue Op,
+                                             SelectionDAG &DAG) const {
+  // check the depth
+  assert((cast<ConstantSDNode>(Op.getOperand(0))->getZExtValue() == 0) &&
+         "Frame address can only be determined for current frame.");
+
+  MachineFunction &MF = DAG.getMachineFunction();
+  MachineFrameInfo &MFI = DAG.getMachineFunction().getFrameInfo();
+  MFI.setFrameAddressIsTaken(true);
+  EVT VT = Op.getValueType();
+  SDLoc DL(Op);
+
+  unsigned FrameReg = Subtarget.getRegisterInfo()->getFrameRegister(MF);
+  SDValue FrameAddr = DAG.getCopyFromReg(DAG.getEntryNode(), DL, FrameReg, VT);
+  return FrameAddr;
+}
+
+SDValue XtensaTargetLowering::LowerDYNAMIC_STACKALLOC(SDValue Op,
+                                                      SelectionDAG &DAG) const {
+  SDValue Chain = Op.getOperand(0); // Legalize the chain.
+  SDValue Size = Op.getOperand(1);  // Legalize the size.
+  EVT VT = Size->getValueType(0);
+  SDLoc DL(Op);
+
+  // Round up Size to 32
+  SDValue Size1 =
+      DAG.getNode(ISD::ADD, DL, VT, Size, DAG.getConstant(31, DL, MVT::i32));
+  SDValue SizeRoundUp =
+      DAG.getNode(ISD::AND, DL, VT, Size1, DAG.getConstant(~31, DL, MVT::i32));
+
+  unsigned SPReg = Xtensa::SP;
+  SDValue SP = DAG.getCopyFromReg(Chain, DL, SPReg, VT);
+  SDValue NewSP = DAG.getNode(ISD::SUB, DL, VT, SP, SizeRoundUp); // Value
+  if (Subtarget.isWinABI()) {
+    SDValue NewSP1 = DAG.getNode(XtensaISD::MOVSP, DL, MVT::i32, NewSP);
+    Chain = DAG.getCopyToReg(SP.getValue(1), DL, SPReg, NewSP1); // Output chain
+  } else {
+    Chain = DAG.getCopyToReg(SP.getValue(1), DL, SPReg, NewSP); // Output chain
+  }
+
+  SDValue NewVal = DAG.getCopyFromReg(Chain, DL, SPReg, MVT::i32);
+  Chain = NewVal.getValue(1);
+
+  SDValue Ops[2] = {NewVal, Chain};
+  return DAG.getMergeValues(Ops, DL);
+}
+
+SDValue XtensaTargetLowering::LowerVASTART(SDValue Op,
+                                           SelectionDAG &DAG) const {
+  MachineFunction &MF = DAG.getMachineFunction();
+  XtensaFunctionInfo *XtensaFI = MF.getInfo<XtensaFunctionInfo>();
+  EVT PtrVT = getPointerTy(DAG.getDataLayout());
+  SDLoc DL(Op);
+
+  SDValue Chain = Op.getOperand(0);
+  SDValue Addr = Op.getOperand(1);
+
+  // typedef struct __va_list_tag {
+  //   int32_t *__va_stk; /* Initialized to point  to the position of the
+  //                       * first argument in memory offset to account for
+  //                       the
+  //                       * arguments passed in registers and to account for
+  //                       * the size of the argument registers not being
+  //                       16-byte
+  //                       * aligned.  E.G., there are 6 argument registers
+  //                       * of 4 bytes each, but we want the __va_ndx for the
+  //                       * first stack argument to have the maximal
+  //                       * alignment of 16 bytes, so we offset the __va_stk
+  //                       address by
+  //                       * 32 bytes so that __va_stk[32] references the
+  //                       first
+  //                       * argument on the stack.
+  //                       */
+  //   int32_t  *__va_reg; /* Points to a stack-allocated region holding the
+  //                        * contents
+  //                        * of the incoming argument registers
+  //                        */
+  //   int32_t __va_ndx;   /* Index initialized to the position of the first
+  //                        * unnamed (variable) argument.  This same index is
+  //                        also
+  //                        * used to address the arguments passed in memory.
+  //                       */
+  //  } __va_list_tag[1];
+
+  SDValue ArgAR;
+  SDValue OverflowPtrAdvance;
+  SDValue StackOffsetFI =
+      DAG.getFrameIndex(XtensaFI->getVarArgsStackOffset(), PtrVT);
+
+  if (XtensaFI->getVarArgsFirstGPR() < 8) {
+    ArgAR =
+        DAG.getConstant(XtensaFI->getVarArgsFirstGPR() * 4 - 8, DL, MVT::i32);
+    OverflowPtrAdvance = DAG.getConstant(32, DL, PtrVT);
+  } else {
+    OverflowPtrAdvance = DAG.getNode(ISD::AND, DL, PtrVT, StackOffsetFI,
+                                     DAG.getConstant(0xf, DL, PtrVT));
+    OverflowPtrAdvance = DAG.getNode(ISD::ADD, DL, PtrVT, OverflowPtrAdvance,
+                                     DAG.getConstant(32, DL, PtrVT));
+    ArgAR = OverflowPtrAdvance;
+  }
+
+  SDValue FR = DAG.getFrameIndex(XtensaFI->getVarArgsFrameIndex(), PtrVT);
+
+  uint64_t FrameOffset = PtrVT.getSizeInBits() / 8;
+  SDValue ConstFrameOffset1 = DAG.getConstant(FrameOffset, DL, PtrVT);
+  SDValue ConstFrameOffset2 = DAG.getConstant(FrameOffset * 2, DL, PtrVT);
+
+  const Value *SV = cast<SrcValueSDNode>(Op.getOperand(2))->getValue();
+
+  // Store first word : arguments given in stack  (__va_stk)
+  // Advance Argument Overflow pointer down, lest it will point to start
+  // after register argument va_arg finished
+  SDValue StackOffsetFICorr =
+      DAG.getNode(ISD::SUB, DL, PtrVT, StackOffsetFI, OverflowPtrAdvance);
+  SDValue firstStore =
+      DAG.getStore(Chain, DL, StackOffsetFICorr, Addr, MachinePointerInfo(SV));
+
+  uint64_t nextOffset = FrameOffset;
+  SDValue nextPtr = DAG.getNode(ISD::ADD, DL, PtrVT, Addr, ConstFrameOffset1);
+
+  // Store second word : arguments given on registers  (__va_reg)
+  SDValue FRAdvance =
+      DAG.getConstant(XtensaFI->getVarArgsFirstGPR() * 4 - 8, DL, PtrVT);
+  SDValue FRDecr = DAG.getNode(ISD::SUB, DL, PtrVT, FR, FRAdvance);
+  SDValue secondStore = DAG.getStore(firstStore, DL, FRDecr, nextPtr,
+                                     MachinePointerInfo(SV, nextOffset));
+  nextOffset += FrameOffset;
+  nextPtr = DAG.getNode(ISD::ADD, DL, PtrVT, Addr, ConstFrameOffset2);
+
+  // Store first word : number of int regs  (__va_ndx)
+  return DAG.getStore(secondStore, DL, ArgAR, nextPtr,
+                      MachinePointerInfo(SV, nextOffset));
+}
+
+SDValue XtensaTargetLowering::LowerVACOPY(SDValue Op, SelectionDAG &DAG) const {
+  // We have to copy the entire va_list struct:
+  // 2*sizeof(int*) + sizeof(int) = 12 Byte
+  unsigned VAListSize = 12;
+  return DAG.getMemcpy(Op.getOperand(0), Op, Op.getOperand(1), Op.getOperand(2),
+                       DAG.getConstant(VAListSize, SDLoc(Op), MVT::i32), 8,
+                       false, true, false, MachinePointerInfo(),
+                       MachinePointerInfo());
+}
+
+SDValue XtensaTargetLowering::LowerShiftLeftParts(SDValue Op,
+                                                  SelectionDAG &DAG) const {
+  SDLoc DL(Op);
+  MVT VT = MVT::i32;
+
+  SDValue Lo = Op.getOperand(0), Hi = Op.getOperand(1);
+  SDValue Shamt = Op.getOperand(2);
+
+  SDValue SetShiftLeft = DAG.getNode(XtensaISD::SSL, DL, MVT::Glue, Shamt);
+  SDValue ShiftLeftHi =
+      DAG.getNode(XtensaISD::SRC, DL, VT, Hi, Lo, SetShiftLeft);
+  SDValue SetShiftLeft1 = DAG.getNode(XtensaISD::SSL, DL, MVT::Glue, Shamt);
+  SDValue ShiftLeftLo = DAG.getNode(XtensaISD::SHL, DL, VT, Lo, SetShiftLeft1);
+  SDValue Cond = DAG.getNode(ISD::AND, DL, MVT::i32, Shamt,
+                             DAG.getConstant(VT.getSizeInBits(), DL, MVT::i32));
+  Lo = DAG.getNode(ISD::SELECT, DL, VT, Cond, DAG.getConstant(0, DL, VT),
+                   ShiftLeftLo);
+  Hi = DAG.getNode(ISD::SELECT, DL, VT, Cond, ShiftLeftLo, ShiftLeftHi);
+
+  SDValue Ops[2] = {Lo, Hi};
+  return DAG.getMergeValues(Ops, DL);
+}
+
+SDValue XtensaTargetLowering::LowerShiftRightParts(SDValue Op,
+                                                   SelectionDAG &DAG,
+                                                   bool IsSRA) const {
+  SDLoc DL(Op);
+  SDValue Lo = Op.getOperand(0), Hi = Op.getOperand(1);
+  SDValue Shamt = Op.getOperand(2);
+  MVT VT = MVT::i32;
+
+  if (IsSRA) {
+    SDValue SetShiftRight1 = DAG.getNode(XtensaISD::SSR, DL, MVT::Glue, Shamt);
+    SDValue ShiftRightLo1 =
+        DAG.getNode(XtensaISD::SRC, DL, VT, Hi, Lo, SetShiftRight1);
+
+    SDValue SetShiftRight2 = DAG.getNode(XtensaISD::SSR, DL, MVT::Glue, Shamt);
+    SDValue ShiftRightHi1 =
+        DAG.getNode(XtensaISD::SRA, DL, VT, Hi, SetShiftRight2);
+
+    SDValue SetShiftRight3 = DAG.getNode(XtensaISD::SSR, DL, MVT::Glue, Shamt);
+    SDValue ShiftRightLo2 =
+        DAG.getNode(XtensaISD::SRA, DL, VT, Hi, SetShiftRight3);
+
+    SDValue ShiftRightHi2 =
+        DAG.getNode(ISD::SRA, DL, VT, Hi, DAG.getConstant(31, DL, VT));
+
+    SDValue Cond =
+        DAG.getNode(ISD::AND, DL, MVT::i32, Shamt,
+                    DAG.getConstant(VT.getSizeInBits(), DL, MVT::i32));
+    Hi = DAG.getNode(ISD::SELECT, DL, VT, Cond, ShiftRightHi2, ShiftRightHi1);
+    Lo = DAG.getNode(ISD::SELECT, DL, VT, Cond, ShiftRightLo2, ShiftRightLo1);
+  } else {
+    SDValue SetShiftRight1 = DAG.getNode(XtensaISD::SSR, DL, MVT::Glue, Shamt);
+    SDValue ShiftRightLo1 =
+        DAG.getNode(XtensaISD::SRC, DL, VT, Hi, Lo, SetShiftRight1);
+
+    SDValue SetShiftRight2 = DAG.getNode(XtensaISD::SSR, DL, MVT::Glue, Shamt);
+    SDValue ShiftRightHi1 =
+        DAG.getNode(XtensaISD::SRL, DL, VT, Hi, SetShiftRight2);
+
+    SDValue SetShiftRight3 = DAG.getNode(XtensaISD::SSR, DL, MVT::Glue, Shamt);
+    SDValue ShiftRightLo2 =
+        DAG.getNode(XtensaISD::SRL, DL, VT, Hi, SetShiftRight3);
+
+    SDValue Cond =
+        DAG.getNode(ISD::AND, DL, MVT::i32, Shamt,
+                    DAG.getConstant(VT.getSizeInBits(), DL, MVT::i32));
+    Hi = DAG.getNode(ISD::SELECT, DL, VT, Cond, DAG.getConstant(0, DL, VT),
+                     ShiftRightHi1);
+    Lo = DAG.getNode(ISD::SELECT, DL, VT, Cond, ShiftRightLo2, ShiftRightLo1);
+  }
+
+  SDValue Ops[2] = {Lo, Hi};
+  return DAG.getMergeValues(Ops, DL);
+}
+
+SDValue XtensaTargetLowering::LowerFunnelShift(SDValue Op,
+                                               SelectionDAG &DAG) const {
+  SDLoc DL(Op);
+  SDValue Op0 = Op.getOperand(0);
+  SDValue Op1 = Op.getOperand(1);
+  SDValue Shamt = Op.getOperand(2);
+  MVT VT = Op.getSimpleValueType();
+
+  bool IsFSHR = Op.getOpcode() == ISD::FSHR;
+  assert((VT == MVT::i32) && "Unexpected funnel shift type!");
+
+  SDValue SetSAR = DAG.getNode(IsFSHR ? XtensaISD::SSR : XtensaISD::SSL, DL,
+                               MVT::Glue, Shamt);
+  return DAG.getNode(XtensaISD::SRC, DL, VT, IsFSHR ? Op0 : Op1,
+                     IsFSHR ? Op1 : Op0, SetSAR);
+} 
+
+SDValue XtensaTargetLowering::LowerATOMIC_FENCE(SDValue Op,
+                                                SelectionDAG &DAG) const {
+  SDLoc DL(Op);
+  SDValue Chain = Op.getOperand(0);
+  return DAG.getNode(XtensaISD::MEMW, DL, MVT::Other, Chain);
+}
+
+SDValue XtensaTargetLowering::LowerOperation(SDValue Op,
+                                             SelectionDAG &DAG) const {
+  switch (Op.getOpcode()) {
+  case ISD::BR_JT:
+    return LowerBR_JT(Op, DAG);
+  case ISD::Constant:
+    return LowerImmediate(Op, DAG);
+  case ISD::ConstantFP:
+    return LowerImmediateFP(Op, DAG);
+  case ISD::RETURNADDR:
+    return LowerRETURNADDR(Op, DAG);
+  case ISD::BR_CC:
+    return LowerBR_CC(Op, DAG);
+  case ISD::SETCC:
+    return LowerSETCC(Op, DAG);
+  case ISD::SELECT_CC:
+    return LowerSELECT_CC(Op, DAG);
+  case ISD::GlobalAddress:
+    return LowerGlobalAddress(Op, DAG);
+  case ISD::GlobalTLSAddress:
+    return LowerGlobalTLSAddress(cast<GlobalAddressSDNode>(Op), DAG);
+  case ISD::BlockAddress:
+    return LowerBlockAddress(cast<BlockAddressSDNode>(Op), DAG);
+  case ISD::JumpTable:
+    return LowerJumpTable(cast<JumpTableSDNode>(Op), DAG);
+  case ISD::ConstantPool:
+    return LowerConstantPool(cast<ConstantPoolSDNode>(Op), DAG);
+  case ISD::STACKSAVE:
+    return LowerSTACKSAVE(Op, DAG);
+  case ISD::STACKRESTORE:
+    return LowerSTACKRESTORE(Op, DAG);
+  case ISD::FRAMEADDR:
+    return LowerFRAMEADDR(Op, DAG);
+  case ISD::DYNAMIC_STACKALLOC:
+    return LowerDYNAMIC_STACKALLOC(Op, DAG);
+  case ISD::VASTART:
+    return LowerVASTART(Op, DAG);
+  case ISD::VACOPY:
+    return LowerVACOPY(Op, DAG);
+  case ISD::ATOMIC_FENCE:
+    return LowerATOMIC_FENCE(Op, DAG);
+  case ISD::SHL_PARTS:
+    return LowerShiftLeftParts(Op, DAG);
+  case ISD::SRA_PARTS:
+    return LowerShiftRightParts(Op, DAG, true);
+  case ISD::SRL_PARTS:
+    return LowerShiftRightParts(Op, DAG, false);
+  case ISD::FSHL:
+  case ISD::FSHR:
+    return LowerFunnelShift(Op, DAG);
+  default:
+    llvm_unreachable("Unexpected node to lower");
+  }
+}
+
+const char *XtensaTargetLowering::getTargetNodeName(unsigned Opcode) const {
+#define OPCODE(NAME)                                                           \
+  case XtensaISD::NAME:                                                        \
+    return "XtensaISD::" #NAME
+  switch (Opcode) {
+    OPCODE(RET_FLAG);
+    OPCODE(RETW_FLAG);
+    OPCODE(CALL);
+    OPCODE(CALLW);
+    OPCODE(PCREL_WRAPPER);
+    OPCODE(SELECT);
+    OPCODE(SELECT_CC);
+    OPCODE(SELECT_CC_FP);
+    OPCODE(BR_CC_T);
+    OPCODE(BR_CC_F);
+    OPCODE(BR_JT);
+    OPCODE(CMPUO);
+    OPCODE(CMPUEQ);
+    OPCODE(CMPULE);
+    OPCODE(CMPULT);
+    OPCODE(CMPOEQ);
+    OPCODE(CMPOLE);
+    OPCODE(CMPOLT);
+    OPCODE(MADD);
+    OPCODE(MSUB);
+    OPCODE(MOVS);
+    OPCODE(MEMW);
+    OPCODE(MOVSP);
+    OPCODE(RUR);
+    OPCODE(SHL);
+    OPCODE(SRA);
+    OPCODE(SRL);
+    OPCODE(SRC);
+    OPCODE(SSL);
+    OPCODE(SSR);
+  }
+  return NULL;
+#undef OPCODE
+}
+
+//===----------------------------------------------------------------------===//
+// Custom insertion
+//===----------------------------------------------------------------------===//
+
+static int GetBranchKind(int Cond, bool &BrInv) {
+  switch (Cond) {
+  case ISD::SETEQ:
+  case ISD::SETOEQ:
+  case ISD::SETUEQ:
+    return Xtensa::BEQ;
+  case ISD::SETNE:
+  case ISD::SETONE:
+  case ISD::SETUNE:
+    return Xtensa::BNE;
+  case ISD::SETLT:
+  case ISD::SETOLT:
+    return Xtensa::BLT;
+  case ISD::SETLE:
+  case ISD::SETOLE:
+    BrInv = true;
+    return Xtensa::BGE;
+  case ISD::SETGT:
+  case ISD::SETOGT:
+    BrInv = true;
+    return Xtensa::BLT;
+  case ISD::SETGE:
+  case ISD::SETOGE:
+    return Xtensa::BGE;
+  case ISD::SETULT:
+    return Xtensa::BLTU;
+  case ISD::SETULE:
+    BrInv = true;
+    return Xtensa::BGEU;
+  case ISD::SETUGT:
+    BrInv = true;
+    return Xtensa::BLTU;
+  case ISD::SETUGE:
+    return Xtensa::BGEU;
+  default:
+    return -1;
+  }
+}
+
+static void GetFPBranchKind(int Cond, int &BrKind, int &CmpKind) {
+
+  switch (Cond) {
+  default:
+    llvm_unreachable("Invalid condition!");
+    break;
+  case ISD::SETUNE:
+    BrKind = Xtensa::BF;
+    CmpKind = Xtensa::OEQ_S;
+    break;
+  case ISD::SETUO:
+    BrKind = Xtensa::BT;
+    CmpKind = Xtensa::UN_S;
+    break;
+  case ISD::SETO:
+    BrKind = Xtensa::BF;
+    CmpKind = Xtensa::UN_S;
+    break;
+  case ISD::SETUEQ:
+    BrKind = Xtensa::BT;
+    CmpKind = Xtensa::UEQ_S;
+    break;
+  case ISD::SETULE:
+    BrKind = Xtensa::BT;
+    CmpKind = Xtensa::ULE_S;
+    break;
+  case ISD::SETULT:
+    BrKind = Xtensa::BT;
+    CmpKind = Xtensa::ULT_S;
+    break;
+  case ISD::SETEQ:
+  case ISD::SETOEQ:
+    BrKind = Xtensa::BT;
+    CmpKind = Xtensa::OEQ_S;
+    break;
+  case ISD::SETNE:
+    BrKind = Xtensa::BF;
+    CmpKind = Xtensa::OEQ_S;
+    break;
+  case ISD::SETLE:
+  case ISD::SETOLE:
+    BrKind = Xtensa::BT;
+    CmpKind = Xtensa::OLE_S;
+    break;
+  case ISD::SETLT:
+  case ISD::SETOLT:
+    BrKind = Xtensa::BT;
+    CmpKind = Xtensa::OLT_S;
+    break;
+  case ISD::SETGE:
+    BrKind = Xtensa::BF;
+    CmpKind = Xtensa::OLT_S;
+    break;
+  case ISD::SETGT:
+    BrKind = Xtensa::BF;
+    CmpKind = Xtensa::OLE_S;
+    break;
+  }
+}
+
+MachineBasicBlock *
+XtensaTargetLowering::emitSelectCC(MachineInstr &MI,
+                                   MachineBasicBlock *BB) const {
+  const TargetInstrInfo &TII = *Subtarget.getInstrInfo();
+  DebugLoc DL = MI.getDebugLoc();
+
+  MachineOperand &LHS = MI.getOperand(1);
+  MachineOperand &RHS = MI.getOperand(2);
+  MachineOperand &TrueV = MI.getOperand(3);
+  MachineOperand &FalseV = MI.getOperand(4);
+  MachineOperand &Cond = MI.getOperand(5);
+
+  // To "insert" a SELECT_CC instruction, we actually have to insert the
+  // diamond control-flow pattern.  The incoming instruction knows the
+  // destination vreg to set, the condition code register to branch on, the
+  // true/false values to select between, and a branch opcode to use.
+  const BasicBlock *LLVM_BB = BB->getBasicBlock();
+  MachineFunction::iterator It = ++BB->getIterator();
+
+  //  thisMBB:
+  //  ...
+  //   TrueVal = ...
+  //   cmpTY ccX, r1, r2
+  //   bCC copy1MBB
+  //   fallthrough --> copy0MBB
+  MachineBasicBlock *thisMBB = BB;
+  MachineFunction *F = BB->getParent();
+  MachineBasicBlock *copy0MBB = F->CreateMachineBasicBlock(LLVM_BB);
+  MachineBasicBlock *sinkMBB = F->CreateMachineBasicBlock(LLVM_BB);
+
+  F->insert(It, copy0MBB);
+  F->insert(It, sinkMBB);
+
+  // Transfer the remainder of BB and its successor edges to sinkMBB.
+  sinkMBB->splice(sinkMBB->begin(), BB,
+                  std::next(MachineBasicBlock::iterator(MI)), BB->end());
+  sinkMBB->transferSuccessorsAndUpdatePHIs(BB);
+
+  // Next, add the true and fallthrough blocks as its successors.
+  BB->addSuccessor(copy0MBB);
+  BB->addSuccessor(sinkMBB);
+
+  if ((MI.getOpcode() == Xtensa::SELECT_CC_FP_FP) ||
+      (MI.getOpcode() == Xtensa::SELECT_CC_FP_INT)) {
+    int BrKind = 0;
+    int CmpKind = 0;
+    MachineFunction *MF = BB->getParent();
+    MachineRegisterInfo &RegInfo = MF->getRegInfo();
+    const TargetRegisterClass *RC = getRegClassFor(MVT::i1);
+    unsigned b = RegInfo.createVirtualRegister(RC);
+    GetFPBranchKind(Cond.getImm(), BrKind, CmpKind);
+    BuildMI(BB, DL, TII.get(CmpKind), b)
+        .addReg(LHS.getReg())
+        .addReg(RHS.getReg());
+    BuildMI(BB, DL, TII.get(BrKind)).addReg(b).addMBB(sinkMBB);
+  } else {
+    bool BrInv = false;
+    int BrKind = GetBranchKind(Cond.getImm(), BrInv);
+    if (BrInv) {
+      BuildMI(BB, DL, TII.get(BrKind))
+          .addReg(RHS.getReg())
+          .addReg(LHS.getReg())
+          .addMBB(sinkMBB);
+    } else {
+      BuildMI(BB, DL, TII.get(BrKind))
+          .addReg(LHS.getReg())
+          .addReg(RHS.getReg())
+          .addMBB(sinkMBB);
+    }
+  }
+
+  //  copy0MBB:
+  //   %FalseValue = ...
+  //   # fallthrough to sinkMBB
+  BB = copy0MBB;
+
+  // Update machine-CFG edges
+  BB->addSuccessor(sinkMBB);
+
+  //  sinkMBB:
+  //   %Result = phi [ %FalseValue, copy0MBB ], [ %TrueValue, thisMBB ]
+  //  ...
+  BB = sinkMBB;
+
+  BuildMI(*BB, BB->begin(), DL, TII.get(Xtensa::PHI), MI.getOperand(0).getReg())
+      .addReg(FalseV.getReg())
+      .addMBB(copy0MBB)
+      .addReg(TrueV.getReg())
+      .addMBB(thisMBB);
+
+  MI.eraseFromParent(); // The pseudo instruction is gone now.
+  return BB;
+}
+
+// Emit instructions for atomic_cmp_swap node for 8/16 bit operands
+MachineBasicBlock *
+XtensaTargetLowering::emitAtomicCmpSwap(MachineInstr &MI, MachineBasicBlock *BB,
+                                        int isByteOperand) const {
+  const TargetInstrInfo &TII = *Subtarget.getInstrInfo();
+  DebugLoc DL = MI.getDebugLoc();
+
+  const BasicBlock *LLVM_BB = BB->getBasicBlock();
+  MachineFunction::iterator It = ++BB->getIterator();
+
+  MachineBasicBlock *thisBB = BB;
+  MachineFunction *F = BB->getParent();
+  MachineBasicBlock *BBLoop = F->CreateMachineBasicBlock(LLVM_BB);
+  MachineBasicBlock *BBExit = F->CreateMachineBasicBlock(LLVM_BB);
+
+  F->insert(It, BBLoop);
+  F->insert(It, BBExit);
+
+  // Transfer the remainder of BB and its successor edges to BBExit.
+  BBExit->splice(BBExit->begin(), BB,
+                 std::next(MachineBasicBlock::iterator(MI)), BB->end());
+  BBExit->transferSuccessorsAndUpdatePHIs(BB);
+
+  BB->addSuccessor(BBLoop);
+
+  MachineOperand &Res = MI.getOperand(0);
+  MachineOperand &AtomValAddr = MI.getOperand(1);
+  MachineOperand &CmpVal = MI.getOperand(2);
+  MachineOperand &SwpVal = MI.getOperand(3);
+
+  MachineFunction *MF = BB->getParent();
+  MachineRegisterInfo &MRI = MF->getRegInfo();
+  const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+
+  unsigned R1 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), R1).addImm(3);
+
+  unsigned ByteOffs = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::AND), ByteOffs)
+      .addReg(R1)
+      .addReg(AtomValAddr.getReg());
+
+  unsigned AddrAlign = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SUB), AddrAlign)
+      .addReg(AtomValAddr.getReg())
+      .addReg(ByteOffs);
+
+  unsigned BitOffs = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLLI), BitOffs)
+      .addReg(ByteOffs)
+      .addImm(3);
+
+  unsigned Mask1 = MRI.createVirtualRegister(RC);
+  if (isByteOperand) {
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), Mask1).addImm(0xff);
+  } else {
+    unsigned R2 = MRI.createVirtualRegister(RC);
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), R2).addImm(1);
+    unsigned R3 = MRI.createVirtualRegister(RC);
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::SLLI), R3).addReg(R2).addImm(16);
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::ADDI), Mask1).addReg(R3).addImm(-1);
+  }
+
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SSL)).addReg(BitOffs);
+
+  unsigned R2 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), R2).addImm(-1);
+
+  unsigned Mask2 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLL), Mask2).addReg(Mask1);
+
+  unsigned Mask3 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::XOR), Mask3).addReg(Mask2).addReg(R2);
+
+  unsigned R3 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::L32I), R3).addReg(AddrAlign).addImm(0);
+
+  unsigned R4 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::AND), R4).addReg(R3).addReg(Mask3);
+
+  unsigned Cmp1 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLL), Cmp1).addReg(CmpVal.getReg());
+
+  unsigned Swp1 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLL), Swp1).addReg(SwpVal.getReg());
+
+  BB = BBLoop;
+
+  unsigned MaskPhi = MRI.createVirtualRegister(RC);
+  unsigned MaskLoop = MRI.createVirtualRegister(RC);
+
+  BuildMI(*BB, BB->begin(), DL, TII.get(Xtensa::PHI), MaskPhi)
+      .addReg(MaskLoop)
+      .addMBB(BBLoop)
+      .addReg(R4)
+      .addMBB(thisBB);
+
+  unsigned Cmp2 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::OR), Cmp2).addReg(Cmp1).addReg(MaskPhi);
+
+  unsigned Swp2 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::OR), Swp2).addReg(Swp1).addReg(MaskPhi);
+
+  BuildMI(BB, DL, TII.get(Xtensa::WSR), Xtensa::SCOMPARE1).addReg(Cmp2);
+
+  unsigned Swp3 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::S32C1I), Swp3)
+      .addReg(Swp2)
+      .addReg(AddrAlign)
+      .addImm(0);
+
+  BuildMI(BB, DL, TII.get(Xtensa::AND), MaskLoop).addReg(Swp3).addReg(Mask3);
+
+  BuildMI(BB, DL, TII.get(Xtensa::BNE))
+      .addReg(MaskLoop)
+      .addReg(MaskPhi)
+      .addMBB(BBLoop);
+
+  BB->addSuccessor(BBLoop);
+  BB->addSuccessor(BBExit);
+
+  BB = BBExit;
+  auto St = BBExit->begin();
+
+  unsigned R5 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, St, DL, TII.get(Xtensa::SSR)).addReg(BitOffs);
+
+  BuildMI(*BB, St, DL, TII.get(Xtensa::SRL), R5).addReg(Swp3);
+
+  BuildMI(*BB, St, DL, TII.get(Xtensa::AND), Res.getReg())
+      .addReg(R5)
+      .addReg(Mask1);
+
+  MI.eraseFromParent(); // The pseudo instruction is gone now.
+  return BB;
+}
+
+// Emit instructions for atomic_swap node for 8/16 bit operands
+MachineBasicBlock *
+XtensaTargetLowering::emitAtomicSwap(MachineInstr &MI, MachineBasicBlock *BB,
+                                     int isByteOperand) const {
+  const TargetInstrInfo &TII = *Subtarget.getInstrInfo();
+  DebugLoc DL = MI.getDebugLoc();
+
+  const BasicBlock *LLVM_BB = BB->getBasicBlock();
+  MachineFunction::iterator It = ++BB->getIterator();
+
+  MachineFunction *F = BB->getParent();
+  MachineBasicBlock *BBLoop1 = F->CreateMachineBasicBlock(LLVM_BB);
+  MachineBasicBlock *BBLoop2 = F->CreateMachineBasicBlock(LLVM_BB);
+  MachineBasicBlock *BBLoop3 = F->CreateMachineBasicBlock(LLVM_BB);
+  MachineBasicBlock *BBLoop4 = F->CreateMachineBasicBlock(LLVM_BB);
+  MachineBasicBlock *BBExit = F->CreateMachineBasicBlock(LLVM_BB);
+
+  F->insert(It, BBLoop1);
+  F->insert(It, BBLoop2);
+  F->insert(It, BBLoop3);
+  F->insert(It, BBLoop4);
+  F->insert(It, BBExit);
+
+  // Transfer the remainder of BB and its successor edges to BBExit.
+  BBExit->splice(BBExit->begin(), BB,
+                 std::next(MachineBasicBlock::iterator(MI)), BB->end());
+  BBExit->transferSuccessorsAndUpdatePHIs(BB);
+
+  BB->addSuccessor(BBLoop1);
+  BBLoop1->addSuccessor(BBLoop2);
+  BBLoop2->addSuccessor(BBLoop3);
+  BBLoop2->addSuccessor(BBLoop4);
+  BBLoop3->addSuccessor(BBLoop2);
+  BBLoop3->addSuccessor(BBLoop4);
+  BBLoop4->addSuccessor(BBLoop1);
+  BBLoop4->addSuccessor(BBExit);
+
+  MachineOperand &Res = MI.getOperand(0);
+  MachineOperand &AtomValAddr = MI.getOperand(1);
+  MachineOperand &SwpVal = MI.getOperand(2);
+
+  MachineFunction *MF = BB->getParent();
+  MachineRegisterInfo &MRI = MF->getRegInfo();
+  const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+
+  unsigned R1 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), R1).addImm(3);
+
+  unsigned ByteOffs = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::AND), ByteOffs)
+      .addReg(R1)
+      .addReg(AtomValAddr.getReg());
+
+  unsigned AddrAlign = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SUB), AddrAlign)
+      .addReg(AtomValAddr.getReg())
+      .addReg(ByteOffs);
+
+  unsigned BitOffs = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLLI), BitOffs)
+      .addReg(ByteOffs)
+      .addImm(3);
+
+  unsigned Mask1 = MRI.createVirtualRegister(RC);
+  if (isByteOperand) {
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), Mask1).addImm(0xff);
+  } else {
+    unsigned R2 = MRI.createVirtualRegister(RC);
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), R2).addImm(1);
+    unsigned R3 = MRI.createVirtualRegister(RC);
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::SLLI), R3).addReg(R2).addImm(16);
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::ADDI), Mask1).addReg(R3).addImm(-1);
+  }
+
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SSL)).addReg(BitOffs);
+
+  unsigned R2 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), R2).addImm(-1);
+
+  unsigned Mask2 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLL), Mask2).addReg(Mask1);
+
+  unsigned Mask3 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::XOR), Mask3).addReg(Mask2).addReg(R2);
+
+  unsigned R3 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::L32I), R3).addReg(AddrAlign).addImm(0);
+
+  unsigned R4 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::AND), R4).addReg(R3).addReg(Mask3);
+
+  unsigned SwpValShifted = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLL), SwpValShifted)
+      .addReg(SwpVal.getReg());
+
+  unsigned R5 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::L32I), R5).addReg(AddrAlign).addImm(0);
+
+  unsigned AtomVal = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::AND), AtomVal).addReg(R5).addReg(Mask2);
+
+  unsigned AtomValPhi = MRI.createVirtualRegister(RC);
+  unsigned AtomValLoop = MRI.createVirtualRegister(RC);
+
+  BuildMI(*BBLoop1, BBLoop1->begin(), DL, TII.get(Xtensa::PHI), AtomValPhi)
+      .addReg(AtomValLoop)
+      .addMBB(BBLoop4)
+      .addReg(AtomVal)
+      .addMBB(BB);
+
+  BB = BBLoop1;
+
+  BuildMI(BB, DL, TII.get(Xtensa::MEMW));
+
+  unsigned R6 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::L32I), R6).addReg(AddrAlign).addImm(0);
+
+  unsigned R7 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::AND), R7).addReg(R6).addReg(Mask3);
+
+  unsigned MaskPhi = MRI.createVirtualRegister(RC);
+  unsigned MaskLoop = MRI.createVirtualRegister(RC);
+
+  BuildMI(*BBLoop2, BBLoop2->begin(), DL, TII.get(Xtensa::PHI), MaskPhi)
+      .addReg(MaskLoop)
+      .addMBB(BBLoop3)
+      .addReg(R7)
+      .addMBB(BBLoop1);
+
+  BB = BBLoop2;
+
+  unsigned Swp1 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::OR), Swp1)
+      .addReg(SwpValShifted)
+      .addReg(MaskPhi);
+
+  unsigned AtomVal1 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::OR), AtomVal1)
+      .addReg(AtomValPhi)
+      .addReg(MaskPhi);
+
+  BuildMI(BB, DL, TII.get(Xtensa::WSR), Xtensa::SCOMPARE1).addReg(AtomVal1);
+
+  unsigned Swp2 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::S32C1I), Swp2)
+      .addReg(Swp1)
+      .addReg(AddrAlign)
+      .addImm(0);
+
+  BuildMI(BB, DL, TII.get(Xtensa::BEQ))
+      .addReg(AtomVal1)
+      .addReg(Swp2)
+      .addMBB(BBLoop4);
+
+  BB = BBLoop3;
+
+  BuildMI(BB, DL, TII.get(Xtensa::AND), MaskLoop).addReg(Swp2).addReg(Mask3);
+
+  BuildMI(BB, DL, TII.get(Xtensa::BNE))
+      .addReg(MaskLoop)
+      .addReg(MaskPhi)
+      .addMBB(BBLoop2);
+
+  BB = BBLoop4;
+
+  BuildMI(BB, DL, TII.get(Xtensa::AND), AtomValLoop).addReg(Swp2).addReg(Mask2);
+
+  BuildMI(BB, DL, TII.get(Xtensa::BNE))
+      .addReg(AtomValLoop)
+      .addReg(AtomValPhi)
+      .addMBB(BBLoop1);
+
+  BB = BBExit;
+
+  auto St = BB->begin();
+
+  unsigned R8 = MRI.createVirtualRegister(RC);
+
+  BuildMI(*BB, St, DL, TII.get(Xtensa::SSR)).addReg(BitOffs);
+  BuildMI(*BB, St, DL, TII.get(Xtensa::SLL), R8).addReg(AtomValLoop);
+
+  if (isByteOperand) {
+    BuildMI(*BB, St, DL, TII.get(Xtensa::SEXT), Res.getReg())
+        .addReg(R8)
+        .addImm(7);
+  } else {
+    BuildMI(*BB, St, DL, TII.get(Xtensa::SEXT), Res.getReg())
+        .addReg(R8)
+        .addImm(15);
+  }
+
+  MI.eraseFromParent(); // The pseudo instruction is gone now.
+  return BB;
+}
+
+// Emit instructions for atomic_swap node for 32 bit operands
+MachineBasicBlock *
+XtensaTargetLowering::emitAtomicSwap(MachineInstr &MI,
+                                     MachineBasicBlock *BB) const {
+  const TargetInstrInfo &TII = *Subtarget.getInstrInfo();
+  DebugLoc DL = MI.getDebugLoc();
+
+  const BasicBlock *LLVM_BB = BB->getBasicBlock();
+  MachineFunction::iterator It = ++BB->getIterator();
+
+  MachineFunction *F = BB->getParent();
+  MachineBasicBlock *BBLoop = F->CreateMachineBasicBlock(LLVM_BB);
+  MachineBasicBlock *BBExit = F->CreateMachineBasicBlock(LLVM_BB);
+
+  F->insert(It, BBLoop);
+  F->insert(It, BBExit);
+
+  // Transfer the remainder of BB and its successor edges to BBExit.
+  BBExit->splice(BBExit->begin(), BB,
+                 std::next(MachineBasicBlock::iterator(MI)), BB->end());
+  BBExit->transferSuccessorsAndUpdatePHIs(BB);
+
+  BB->addSuccessor(BBLoop);
+  BBLoop->addSuccessor(BBLoop);
+  BBLoop->addSuccessor(BBExit);
+
+  MachineOperand &Res = MI.getOperand(0);
+  MachineOperand &AtomValAddr = MI.getOperand(1);
+  MachineOperand &SwpVal = MI.getOperand(2);
+
+  MachineFunction *MF = BB->getParent();
+  MachineRegisterInfo &MRI = MF->getRegInfo();
+  const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::MEMW));
+
+  unsigned AtomVal = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::L32I), AtomVal)
+      .addReg(AtomValAddr.getReg())
+      .addImm(0);
+
+  unsigned AtomValLoop = MRI.createVirtualRegister(RC);
+
+  BuildMI(*BBLoop, BBLoop->begin(), DL, TII.get(Xtensa::PHI), Res.getReg())
+      .addReg(AtomValLoop)
+      .addMBB(BBLoop)
+      .addReg(AtomVal)
+      .addMBB(BB);
+
+  BB = BBLoop;
+
+  BuildMI(BB, DL, TII.get(Xtensa::WSR), Xtensa::SCOMPARE1).addReg(Res.getReg());
+
+  BuildMI(BB, DL, TII.get(Xtensa::S32C1I), AtomValLoop)
+      .addReg(SwpVal.getReg())
+      .addReg(AtomValAddr.getReg())
+      .addImm(0);
+
+  BuildMI(BB, DL, TII.get(Xtensa::BNE))
+      .addReg(AtomValLoop)
+      .addReg(Res.getReg())
+      .addMBB(BBLoop);
+
+  MI.eraseFromParent(); // The pseudo instruction is gone now.
+  return BB;
+}
+
+MachineBasicBlock *XtensaTargetLowering::emitAtomicRMW(MachineInstr &MI,
+                                                       MachineBasicBlock *BB,
+                                                       unsigned Opcode,
+                                                       bool inv,
+                                                       bool minmax) const {
+  const TargetInstrInfo &TII = *Subtarget.getInstrInfo();
+  DebugLoc DL = MI.getDebugLoc();
+
+  const BasicBlock *LLVM_BB = BB->getBasicBlock();
+  MachineFunction::iterator It = ++BB->getIterator();
+
+  MachineBasicBlock *ThisBB = BB;
+  MachineFunction *F = BB->getParent();
+  MachineBasicBlock *BBLoop = F->CreateMachineBasicBlock(LLVM_BB);
+  MachineBasicBlock *BBExit = F->CreateMachineBasicBlock(LLVM_BB);
+
+  F->insert(It, BBLoop);
+  F->insert(It, BBExit);
+
+  // Transfer the remainder of BB and its successor edges to BB2.
+  BBExit->splice(BBExit->begin(), BB,
+                 std::next(MachineBasicBlock::iterator(MI)), BB->end());
+  BBExit->transferSuccessorsAndUpdatePHIs(BB);
+
+  BB->addSuccessor(BBLoop);
+
+  MachineOperand &Res = MI.getOperand(0);
+  MachineOperand &AtomicValAddr = MI.getOperand(1);
+  MachineOperand &Val = MI.getOperand(2);
+  MachineFunction *MF = BB->getParent();
+  MachineRegisterInfo &MRI = MF->getRegInfo();
+  const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+
+  unsigned R1 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::L32I), R1).add(AtomicValAddr).addImm(0);
+
+  BB = BBLoop;
+
+  unsigned AtomicValPhi = MRI.createVirtualRegister(RC);
+  unsigned AtomicValLoop = MRI.createVirtualRegister(RC);
+
+  BuildMI(*BB, BB->begin(), DL, TII.get(Xtensa::PHI), AtomicValPhi)
+      .addReg(AtomicValLoop)
+      .addMBB(BBLoop)
+      .addReg(R1)
+      .addMBB(ThisBB);
+
+  unsigned R2 = MRI.createVirtualRegister(RC);
+
+  if (minmax) {
+    MachineBasicBlock *BBLoop1 = F->CreateMachineBasicBlock(LLVM_BB);
+    F->insert(It, BBLoop1);
+    BB->addSuccessor(BBLoop1);
+    MachineBasicBlock *BBLoop2 = F->CreateMachineBasicBlock(LLVM_BB);
+    F->insert(It, BBLoop2);
+    BB->addSuccessor(BBLoop2);
+
+    BuildMI(BB, DL, TII.get(Opcode))
+        .addReg(AtomicValPhi)
+        .addReg(Val.getReg())
+        .addMBB(BBLoop1);
+
+    unsigned R7 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::MOV_N), R7).addReg(Val.getReg());
+
+    BB = BBLoop1;
+    unsigned R8 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::MOV_N), R8).addReg(AtomicValPhi);
+    BB->addSuccessor(BBLoop2);
+
+    BB = BBLoop2;
+    unsigned R9 = MRI.createVirtualRegister(RC);
+
+    BuildMI(*BB, BB->begin(), DL, TII.get(Xtensa::PHI), R9)
+        .addReg(R7)
+        .addMBB(BBLoop)
+        .addReg(R8)
+        .addMBB(BBLoop1);
+    BuildMI(BB, DL, TII.get(Xtensa::MOV_N), R2).addReg(R9);
+  } else {
+    BuildMI(BB, DL, TII.get(Opcode), R2)
+        .addReg(AtomicValPhi)
+        .addReg(Val.getReg());
+    if (inv) {
+      unsigned Rtmp1 = MRI.createVirtualRegister(RC);
+      BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), Rtmp1).addImm(-1);
+      unsigned Rtmp2 = MRI.createVirtualRegister(RC);
+      BuildMI(*BB, MI, DL, TII.get(Xtensa::XOR), Rtmp2)
+          .addReg(R2)
+          .addReg(Rtmp1);
+      R2 = Rtmp2;
+    }
+  }
+
+  unsigned R4 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::WSR), Xtensa::SCOMPARE1).addReg(AtomicValPhi);
+  BuildMI(BB, DL, TII.get(Xtensa::S32C1I), R4)
+      .addReg(R2)
+      .addReg(AtomicValAddr.getReg())
+      .addImm(0);
+
+  BuildMI(BB, DL, TII.get(Xtensa::MOV_N), AtomicValLoop).addReg(R4);
+
+  BuildMI(BB, DL, TII.get(Xtensa::BNE))
+      .addReg(AtomicValPhi)
+      .addReg(R4)
+      .addMBB(BBLoop);
+
+  BB->addSuccessor(BBLoop);
+  BB->addSuccessor(BBExit);
+
+  BB = BBExit;
+  auto st = BBExit->begin();
+
+  BuildMI(*BB, st, DL, TII.get(Xtensa::MOV_N), Res.getReg()).addReg(R4);
+
+  MI.eraseFromParent(); // The pseudo instruction is gone now.
+
+  return BB;
+}
+
+MachineBasicBlock *
+XtensaTargetLowering::emitAtomicRMW(MachineInstr &MI, MachineBasicBlock *BB,
+                                    bool isByteOperand, unsigned Opcode,
+                                    bool inv, bool minmax) const {
+  const TargetInstrInfo &TII = *Subtarget.getInstrInfo();
+  DebugLoc DL = MI.getDebugLoc();
+
+  const BasicBlock *LLVM_BB = BB->getBasicBlock();
+  MachineFunction::iterator It = ++BB->getIterator();
+
+  MachineBasicBlock *ThisBB = BB;
+  MachineFunction *F = BB->getParent();
+  MachineBasicBlock *BBLoop = F->CreateMachineBasicBlock(LLVM_BB);
+  MachineBasicBlock *BBExit = F->CreateMachineBasicBlock(LLVM_BB);
+
+  F->insert(It, BBLoop);
+  F->insert(It, BBExit);
+
+  // Transfer the remainder of BB and its successor edges to BB2.
+  BBExit->splice(BBExit->begin(), BB,
+                 std::next(MachineBasicBlock::iterator(MI)), BB->end());
+  BBExit->transferSuccessorsAndUpdatePHIs(BB);
+
+  BB->addSuccessor(BBLoop);
+
+  MachineOperand &Res = MI.getOperand(0);
+  MachineOperand &AtomValAddr = MI.getOperand(1);
+  MachineOperand &Val = MI.getOperand(2);
+
+  MachineFunction *MF = BB->getParent();
+  MachineRegisterInfo &MRI = MF->getRegInfo();
+  const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+
+  unsigned R1 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), R1).addImm(3);
+
+  unsigned ByteOffs = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::AND), ByteOffs)
+      .addReg(R1)
+      .addReg(AtomValAddr.getReg());
+
+  unsigned AddrAlign = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SUB), AddrAlign)
+      .addReg(AtomValAddr.getReg())
+      .addReg(ByteOffs);
+
+  unsigned BitOffs = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLLI), BitOffs)
+      .addReg(ByteOffs)
+      .addImm(3);
+
+  unsigned Mask1 = MRI.createVirtualRegister(RC);
+  if (isByteOperand) {
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), Mask1).addImm(0xff);
+  } else {
+    unsigned R2 = MRI.createVirtualRegister(RC);
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), R2).addImm(1);
+    unsigned R3 = MRI.createVirtualRegister(RC);
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::SLLI), R3).addReg(R2).addImm(16);
+    BuildMI(*BB, MI, DL, TII.get(Xtensa::ADDI), Mask1).addReg(R3).addImm(-1);
+  }
+
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SSL)).addReg(BitOffs);
+
+  unsigned R2 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::MOVI), R2).addImm(-1);
+
+  unsigned Mask2 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLL), Mask2).addReg(Mask1);
+
+  unsigned Mask3 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::XOR), Mask3).addReg(Mask2).addReg(R2);
+
+  unsigned R3 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::L32I), R3).addReg(AddrAlign).addImm(0);
+
+  unsigned Val1 = MRI.createVirtualRegister(RC);
+  BuildMI(*BB, MI, DL, TII.get(Xtensa::SLL), Val1).addReg(Val.getReg());
+
+  BB = BBLoop;
+
+  unsigned AtomicValPhi = MRI.createVirtualRegister(RC);
+  unsigned AtomicValLoop = MRI.createVirtualRegister(RC);
+
+  BuildMI(*BB, BB->begin(), DL, TII.get(Xtensa::PHI), AtomicValPhi)
+      .addReg(AtomicValLoop)
+      .addMBB(BBLoop)
+      .addReg(R3)
+      .addMBB(ThisBB);
+
+  unsigned Swp2;
+
+  if (minmax) {
+    MachineBasicBlock *BBLoop1 = F->CreateMachineBasicBlock(LLVM_BB);
+    F->insert(It, BBLoop1);
+    BB->addSuccessor(BBLoop1);
+    MachineBasicBlock *BBLoop2 = F->CreateMachineBasicBlock(LLVM_BB);
+    F->insert(It, BBLoop2);
+    BB->addSuccessor(BBLoop2);
+
+    unsigned R1 = MRI.createVirtualRegister(RC);
+    unsigned R2 = MRI.createVirtualRegister(RC);
+    unsigned R3 = MRI.createVirtualRegister(RC);
+    unsigned R4 = MRI.createVirtualRegister(RC);
+
+    unsigned R5 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::AND), R5)
+        .addReg(AtomicValPhi)
+        .addReg(Mask2);
+
+    BuildMI(BB, DL, TII.get(Xtensa::SRL), R1).addReg(R5);
+    BuildMI(BB, DL, TII.get(Xtensa::SRL), R2).addReg(Val1);
+
+    if ((Opcode == Xtensa::BLT) || (Opcode == Xtensa::BGE)) {
+      if (isByteOperand) {
+        BuildMI(BB, DL, TII.get(Xtensa::SEXT), R3).addReg(R1).addImm(7);
+        BuildMI(BB, DL, TII.get(Xtensa::SEXT), R4).addReg(R2).addImm(7);
+      } else {
+        BuildMI(BB, DL, TII.get(Xtensa::SEXT), R3).addReg(R1).addImm(15);
+        BuildMI(BB, DL, TII.get(Xtensa::SEXT), R4).addReg(R2).addImm(15);
+      }
+    } else {
+      R3 = R1;
+      R4 = R2;
+    }
+
+    BuildMI(BB, DL, TII.get(Opcode)).addReg(R3).addReg(R4).addMBB(BBLoop1);
+
+    unsigned R7 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::MOV_N), R7).addReg(Val1);
+
+    BB = BBLoop1;
+    unsigned R8 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::MOV_N), R8).addReg(AtomicValPhi);
+    BB->addSuccessor(BBLoop2);
+
+    BB = BBLoop2;
+    unsigned R9 = MRI.createVirtualRegister(RC);
+
+    BuildMI(*BB, BB->begin(), DL, TII.get(Xtensa::PHI), R9)
+        .addReg(R7)
+        .addMBB(BBLoop)
+        .addReg(R8)
+        .addMBB(BBLoop1);
+
+    unsigned R10 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::AND), R10)
+        .addReg(AtomicValPhi)
+        .addReg(Mask3);
+
+    unsigned R11 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::AND), R11).addReg(R9).addReg(Mask2);
+
+    Swp2 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::OR), Swp2).addReg(R10).addReg(R11);
+  } else {
+    unsigned R4 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::AND), R4)
+        .addReg(AtomicValPhi)
+        .addReg(Mask2);
+
+    unsigned Res1 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Opcode), Res1).addReg(R4).addReg(Val1);
+
+    unsigned Swp1 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::AND), Swp1).addReg(Res1).addReg(Mask2);
+
+    unsigned R5 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::AND), R5)
+        .addReg(AtomicValPhi)
+        .addReg(Mask3);
+
+    if (inv) {
+      unsigned Rtmp1 = MRI.createVirtualRegister(RC);
+      BuildMI(BB, DL, TII.get(Xtensa::XOR), Rtmp1)
+          .addReg(AtomicValPhi)
+          .addReg(Mask2);
+      R5 = Rtmp1;
+    }
+
+    Swp2 = MRI.createVirtualRegister(RC);
+    BuildMI(BB, DL, TII.get(Xtensa::OR), Swp2).addReg(Swp1).addReg(R5);
+  }
+
+  unsigned Swp3 = MRI.createVirtualRegister(RC);
+  BuildMI(BB, DL, TII.get(Xtensa::WSR), Xtensa::SCOMPARE1).addReg(AtomicValPhi);
+  BuildMI(BB, DL, TII.get(Xtensa::S32C1I), Swp3)
+      .addReg(Swp2)
+      .addReg(AddrAlign)
+      .addImm(0);
+
+  BuildMI(BB, DL, TII.get(Xtensa::MOV_N), AtomicValLoop).addReg(Swp3);
+
+  BuildMI(BB, DL, TII.get(Xtensa::BNE))
+      .addReg(Swp3)
+      .addReg(AtomicValPhi)
+      .addMBB(BBLoop);
+
+  BB->addSuccessor(BBLoop);
+  BB->addSuccessor(BBExit);
+  BB = BBExit;
+  auto St = BBExit->begin();
+
+  unsigned R6 = MRI.createVirtualRegister(RC);
+
+  BuildMI(*BB, St, DL, TII.get(Xtensa::SSR)).addReg(BitOffs);
+
+  BuildMI(*BB, St, DL, TII.get(Xtensa::SRL), R6).addReg(AtomicValLoop);
+
+  BuildMI(*BB, St, DL, TII.get(Xtensa::AND), Res.getReg())
+      .addReg(R6)
+      .addReg(Mask1);
+
+  MI.eraseFromParent(); // The pseudo instruction is gone now.
+
+  return BB;
+}
+
+MachineBasicBlock *XtensaTargetLowering::EmitInstrWithCustomInserter(
+    MachineInstr &MI, MachineBasicBlock *MBB) const {
+  const TargetInstrInfo &TII = *Subtarget.getInstrInfo();
+  MachineFunction *MF = MBB->getParent();
+  MachineRegisterInfo &MRI = MF->getRegInfo();
+  DebugLoc DL = MI.getDebugLoc();
+
+  switch (MI.getOpcode()) {
+  case Xtensa::MULA_DA_LL_LDDEC_P:
+  case Xtensa::MULA_DA_LH_LDDEC_P:
+  case Xtensa::MULA_DA_HL_LDDEC_P:
+  case Xtensa::MULA_DA_HH_LDDEC_P:
+  case Xtensa::MULA_DA_LL_LDINC_P:
+  case Xtensa::MULA_DA_LH_LDINC_P:
+  case Xtensa::MULA_DA_HL_LDINC_P:
+  case Xtensa::MULA_DA_HH_LDINC_P: {
+    MachineOperand &MW = MI.getOperand(0);
+    MachineOperand &S = MI.getOperand(1);
+    MachineOperand &MX = MI.getOperand(2);
+    MachineOperand &T = MI.getOperand(3);
+    const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+    unsigned Reg1 = MRI.createVirtualRegister(RC);
+    unsigned Reg2 = MRI.createVirtualRegister(RC);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::L32I), Reg1)
+        .addReg(S.getReg())
+        .addImm(0);
+
+    unsigned Opc;
+    switch (MI.getOpcode()) {
+    case Xtensa::MULA_DA_LL_LDDEC_P:
+      Opc = Xtensa::MULA_DA_LL_LDDEC;
+      break;
+    case Xtensa::MULA_DA_LH_LDDEC_P:
+      Opc = Xtensa::MULA_DA_LH_LDDEC;
+      break;
+    case Xtensa::MULA_DA_HL_LDDEC_P:
+      Opc = Xtensa::MULA_DA_HL_LDDEC;
+      break;
+    case Xtensa::MULA_DA_HH_LDDEC_P:
+      Opc = Xtensa::MULA_DA_HH_LDDEC;
+      break;
+    case Xtensa::MULA_DA_LL_LDINC_P:
+      Opc = Xtensa::MULA_DA_LL_LDINC;
+      break;
+    case Xtensa::MULA_DA_LH_LDINC_P:
+      Opc = Xtensa::MULA_DA_LH_LDINC;
+      break;
+    case Xtensa::MULA_DA_HL_LDINC_P:
+      Opc = Xtensa::MULA_DA_HL_LDINC;
+      break;
+    case Xtensa::MULA_DA_HH_LDINC_P:
+      Opc = Xtensa::MULA_DA_HH_LDINC;
+      break;
+    }
+
+    unsigned MWVal = MW.getImm();
+    assert((MWVal < 4) && "Unexpected value of mula_da*ld* first argument, it "
+                          "must be from m0..m3");
+    unsigned MXVal = MX.getImm();
+    assert((MXVal < 2) && "Unexpected value of mula_da*ld* third "
+                          "argument, it must be m0 or m1");
+
+    BuildMI(*MBB, MI, DL, TII.get(Opc))
+        .addReg(Xtensa::M0 + MWVal, RegState::Define)
+        .addReg(Reg2, RegState::Define)
+        .addReg(Reg1)
+        .addReg(Xtensa::M0 + MXVal)
+        .addReg(T.getReg());
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::S32I))
+        .addReg(Reg2)
+        .addReg(S.getReg())
+        .addImm(0);
+
+    MI.eraseFromParent();
+    return MBB;
+  }
+  case Xtensa::MULA_DD_LL_LDDEC_P:
+  case Xtensa::MULA_DD_LH_LDDEC_P:
+  case Xtensa::MULA_DD_HL_LDDEC_P:
+  case Xtensa::MULA_DD_HH_LDDEC_P:
+  case Xtensa::MULA_DD_LL_LDINC_P:
+  case Xtensa::MULA_DD_LH_LDINC_P:
+  case Xtensa::MULA_DD_HL_LDINC_P:
+  case Xtensa::MULA_DD_HH_LDINC_P: {
+    MachineOperand &MW = MI.getOperand(0);
+    MachineOperand &S = MI.getOperand(1);
+    MachineOperand &MX = MI.getOperand(2);
+    MachineOperand &MY = MI.getOperand(3);
+    const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+    unsigned Reg1 = MRI.createVirtualRegister(RC);
+    unsigned Reg2 = MRI.createVirtualRegister(RC);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::L32I), Reg1)
+        .addReg(S.getReg())
+        .addImm(0);
+
+    unsigned Opc;
+    switch (MI.getOpcode()) {
+    case Xtensa::MULA_DD_LL_LDDEC_P:
+      Opc = Xtensa::MULA_DD_LL_LDDEC;
+      break;
+    case Xtensa::MULA_DD_LH_LDDEC_P:
+      Opc = Xtensa::MULA_DD_LH_LDDEC;
+      break;
+    case Xtensa::MULA_DD_HL_LDDEC_P:
+      Opc = Xtensa::MULA_DD_HL_LDDEC;
+      break;
+    case Xtensa::MULA_DD_HH_LDDEC_P:
+      Opc = Xtensa::MULA_DD_HH_LDDEC;
+      break;
+    case Xtensa::MULA_DD_LL_LDINC_P:
+      Opc = Xtensa::MULA_DD_LL_LDINC;
+      break;
+    case Xtensa::MULA_DD_LH_LDINC_P:
+      Opc = Xtensa::MULA_DD_LH_LDINC;
+      break;
+    case Xtensa::MULA_DD_HL_LDINC_P:
+      Opc = Xtensa::MULA_DD_HL_LDINC;
+      break;
+    case Xtensa::MULA_DD_HH_LDINC_P:
+      Opc = Xtensa::MULA_DD_HH_LDINC;
+      break;
+    }
+
+    unsigned MWVal = MW.getImm();
+    assert((MWVal < 4) && "Unexpected value of mula_dd*ld* first argument, "
+                          "it must be from m0..m3");
+    unsigned MXVal = MX.getImm();
+    assert((MXVal < 2) && "Unexpected value of mula_dd*ld* third "
+                          "argument, it must be m0 or m1");
+    unsigned MYVal = MY.getImm();
+    assert(((MYVal > 1) && (MYVal < 4)) &&
+           "Unexpected value of mula_dd*ld* fourth "
+           "argument, it must be m2 or m3");
+
+    BuildMI(*MBB, MI, DL, TII.get(Opc))
+        .addReg(Xtensa::M0 + MWVal, RegState::Define)
+        .addReg(Reg2, RegState::Define)
+        .addReg(Reg1)
+        .addReg(Xtensa::M0 + MXVal)
+        .addReg(Xtensa::M0 + MYVal);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::S32I))
+        .addReg(Reg2)
+        .addReg(S.getReg())
+        .addImm(0);
+
+    MI.eraseFromParent();
+    return MBB;
+  }
+  case Xtensa::XSR_ACCLO_P:
+  case Xtensa::XSR_ACCHI_P:
+  case Xtensa::XSR_M0_P:
+  case Xtensa::XSR_M1_P:
+  case Xtensa::XSR_M2_P:
+  case Xtensa::XSR_M3_P: {
+    MachineOperand &T = MI.getOperand(0);
+    const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+    unsigned Reg1 = MRI.createVirtualRegister(RC);
+    unsigned Reg2 = MRI.createVirtualRegister(RC);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::L32I), Reg1)
+        .addReg(T.getReg())
+        .addImm(0);
+
+    unsigned SReg;
+    switch (MI.getOpcode()) {
+    case Xtensa::XSR_ACCLO_P:
+      SReg = Xtensa::ACCLO;
+      break;
+    case Xtensa::XSR_ACCHI_P:
+      SReg = Xtensa::ACCHI;
+      break;
+    case Xtensa::XSR_M0_P:
+      SReg = Xtensa::M0;
+      break;
+    case Xtensa::XSR_M1_P:
+      SReg = Xtensa::M1;
+      break;
+    case Xtensa::XSR_M2_P:
+      SReg = Xtensa::M2;
+      break;
+    case Xtensa::XSR_M3_P:
+      SReg = Xtensa::M3;
+      break;
+    }
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::XSR))
+        .addReg(Reg2, RegState::Define)
+        .addReg(SReg, RegState::Define)
+        .addReg(Reg1)
+        .addReg(SReg);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::S32I))
+        .addReg(Reg2)
+        .addReg(T.getReg())
+        .addImm(0);
+
+    MI.eraseFromParent();
+    return MBB;
+  }
+  case Xtensa::WSR_ACCLO_P:
+  case Xtensa::WSR_ACCHI_P:
+  case Xtensa::WSR_M0_P:
+  case Xtensa::WSR_M1_P:
+  case Xtensa::WSR_M2_P:
+  case Xtensa::WSR_M3_P: {
+    MachineOperand &T = MI.getOperand(0);
+
+    unsigned SReg;
+    switch (MI.getOpcode()) {
+    case Xtensa::WSR_ACCLO_P:
+      SReg = Xtensa::ACCLO;
+      break;
+    case Xtensa::WSR_ACCHI_P:
+      SReg = Xtensa::ACCHI;
+      break;
+    case Xtensa::WSR_M0_P:
+      SReg = Xtensa::M0;
+      break;
+    case Xtensa::WSR_M1_P:
+      SReg = Xtensa::M1;
+      break;
+    case Xtensa::WSR_M2_P:
+      SReg = Xtensa::M2;
+      break;
+    case Xtensa::WSR_M3_P:
+      SReg = Xtensa::M3;
+      break;
+    }
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::WSR))
+        .addReg(SReg, RegState::Define)
+        .addReg(T.getReg());
+    MI.eraseFromParent();
+    return MBB;
+  }
+  case Xtensa::LDDEC_P:
+  case Xtensa::LDINC_P: {
+    MachineOperand &MW = MI.getOperand(0);
+    MachineOperand &S = MI.getOperand(1);
+    const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+    unsigned Reg1 = MRI.createVirtualRegister(RC);
+    unsigned Reg2 = MRI.createVirtualRegister(RC);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::L32I), Reg1)
+        .addReg(S.getReg())
+        .addImm(0);
+
+    unsigned Opc = Xtensa::LDDEC;
+
+    if (MI.getOpcode() == Xtensa::LDINC_P)
+      Opc = Xtensa::LDINC;
+
+    BuildMI(*MBB, MI, DL, TII.get(Opc))
+        .addReg(Xtensa::M0 + MW.getImm(), RegState::Define)
+        .addReg(Reg2, RegState::Define)
+        .addReg(Reg1);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::S32I))
+        .addReg(Reg2)
+        .addReg(S.getReg())
+        .addImm(0);
+
+    MI.eraseFromParent();
+    return MBB;
+  }
+
+  case Xtensa::SELECT_CC_FP_FP:
+  case Xtensa::SELECT_CC_FP_INT:
+  case Xtensa::SELECT_CC_INT_FP:
+  case Xtensa::SELECT:
+    return emitSelectCC(MI, MBB);
+
+  case Xtensa::SLL_P: {
+    MachineOperand &R = MI.getOperand(0);
+    MachineOperand &S = MI.getOperand(1);
+    MachineOperand &SA = MI.getOperand(2);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::SSL)).addReg(SA.getReg());
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::SLL), R.getReg()).addReg(S.getReg());
+    MI.eraseFromParent();
+    return MBB;
+  }
+  case Xtensa::SRA_P: {
+    MachineOperand &R = MI.getOperand(0);
+    MachineOperand &T = MI.getOperand(1);
+    MachineOperand &SA = MI.getOperand(2);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::SSR)).addReg(SA.getReg());
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::SRA), R.getReg()).addReg(T.getReg());
+    MI.eraseFromParent();
+    return MBB;
+  }
+  case Xtensa::SRL_P: {
+    MachineOperand &R = MI.getOperand(0);
+    MachineOperand &T = MI.getOperand(1);
+    MachineOperand &SA = MI.getOperand(2);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::SSR)).addReg(SA.getReg());
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::SRL), R.getReg()).addReg(T.getReg());
+    MI.eraseFromParent();
+    return MBB;
+  }
+
+  case Xtensa::L8I_P: {
+    MachineOperand &R = MI.getOperand(0);
+    MachineOperand &Op1 = MI.getOperand(1);
+    MachineOperand &Op2 = MI.getOperand(2);
+
+    const TargetRegisterClass *RC = getRegClassFor(MVT::i32);
+    unsigned R1 = MRI.createVirtualRegister(RC);
+
+    const MachineMemOperand &MMO = **MI.memoperands_begin();
+    if (MMO.isVolatile()) {
+      BuildMI(*MBB, MI, DL, TII.get(Xtensa::MEMW));
+    }
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::L8UI), R1).add(Op1).add(Op2);
+
+    if (Subtarget.hasSEXT()) {
+      BuildMI(*MBB, MI, DL, TII.get(Xtensa::SEXT), R.getReg())
+          .addReg(R1)
+          .addImm(7);
+    } else {
+      unsigned R2 = MRI.createVirtualRegister(RC);
+      BuildMI(*MBB, MI, DL, TII.get(Xtensa::SLLI), R2).addReg(R1).addImm(24);
+      BuildMI(*MBB, MI, DL, TII.get(Xtensa::SRAI), R.getReg())
+          .addReg(R2)
+          .addImm(24);
+    }
+
+    MI.eraseFromParent();
+    return MBB;
+  }
+
+  case Xtensa::ATOMIC_CMP_SWAP_8_P: {
+    return emitAtomicCmpSwap(MI, MBB, 1);
+  }
+
+  case Xtensa::ATOMIC_CMP_SWAP_16_P: {
+    return emitAtomicCmpSwap(MI, MBB, 0);
+  }
+
+  case Xtensa::ATOMIC_CMP_SWAP_32_P: {
+    MachineOperand &R = MI.getOperand(0);
+    MachineOperand &Addr = MI.getOperand(1);
+    MachineOperand &Cmp = MI.getOperand(2);
+    MachineOperand &Swap = MI.getOperand(3);
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::WSR), Xtensa::SCOMPARE1)
+        .addReg(Cmp.getReg());
+
+    BuildMI(*MBB, MI, DL, TII.get(Xtensa::S32C1I), R.getReg())
+        .addReg(Swap.getReg())
+        .addReg(Addr.getReg())
+        .addImm(0);
+
+    MI.eraseFromParent();
+    return MBB;
+  }
+
+  case Xtensa::ATOMIC_SWAP_8_P: {
+    return emitAtomicSwap(MI, MBB, 1);
+  }
+
+  case Xtensa::ATOMIC_SWAP_16_P: {
+    return emitAtomicSwap(MI, MBB, 0);
+  }
+
+  case Xtensa::ATOMIC_SWAP_32_P: {
+    return emitAtomicSwap(MI, MBB);
+  }
+
+  case Xtensa::ATOMIC_LOAD_ADD_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::ADD, false, false);
+  case Xtensa::ATOMIC_LOAD_SUB_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::SUB, false, false);
+  case Xtensa::ATOMIC_LOAD_OR_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::OR, false, false);
+  case Xtensa::ATOMIC_LOAD_XOR_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::XOR, false, false);
+  case Xtensa::ATOMIC_LOAD_AND_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::AND, false, false);
+  case Xtensa::ATOMIC_LOAD_NAND_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::AND, true, false);
+  case Xtensa::ATOMIC_LOAD_MIN_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::BGE, false, true);
+  case Xtensa::ATOMIC_LOAD_MAX_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::BLT, false, true);
+  case Xtensa::ATOMIC_LOAD_UMIN_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::BGEU, false, true);
+  case Xtensa::ATOMIC_LOAD_UMAX_8_P:
+    return emitAtomicRMW(MI, MBB, true, Xtensa::BLTU, false, true);
+
+  case Xtensa::ATOMIC_LOAD_ADD_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::ADD, false, false);
+  case Xtensa::ATOMIC_LOAD_SUB_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::SUB, false, false);
+  case Xtensa::ATOMIC_LOAD_OR_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::OR, false, false);
+  case Xtensa::ATOMIC_LOAD_XOR_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::XOR, false, false);
+  case Xtensa::ATOMIC_LOAD_AND_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::AND, false, false);
+  case Xtensa::ATOMIC_LOAD_NAND_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::AND, true, false);
+  case Xtensa::ATOMIC_LOAD_MIN_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::BGE, false, true);
+  case Xtensa::ATOMIC_LOAD_MAX_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::BLT, false, true);
+  case Xtensa::ATOMIC_LOAD_UMIN_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::BGEU, false, true);
+  case Xtensa::ATOMIC_LOAD_UMAX_16_P:
+    return emitAtomicRMW(MI, MBB, false, Xtensa::BLTU, false, true);
+
+  case Xtensa::ATOMIC_LOAD_ADD_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::ADD, false, false);
+  case Xtensa::ATOMIC_LOAD_SUB_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::SUB, false, false);
+  case Xtensa::ATOMIC_LOAD_OR_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::OR, false, false);
+  case Xtensa::ATOMIC_LOAD_XOR_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::XOR, false, false);
+  case Xtensa::ATOMIC_LOAD_AND_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::AND, false, false);
+  case Xtensa::ATOMIC_LOAD_NAND_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::AND, true, false);
+  case Xtensa::ATOMIC_LOAD_MIN_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::BGE, false, true);
+  case Xtensa::ATOMIC_LOAD_MAX_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::BLT, false, true);
+  case Xtensa::ATOMIC_LOAD_UMIN_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::BGEU, false, true);
+  case Xtensa::ATOMIC_LOAD_UMAX_32_P:
+    return emitAtomicRMW(MI, MBB, Xtensa::BLTU, false, true);
+
+  case Xtensa::S8I:
+  case Xtensa::S16I:
+  case Xtensa::S32I:
+  case Xtensa::S32I_N:
+  case Xtensa::S32F:
+  case Xtensa::L8UI:
+  case Xtensa::L16SI:
+  case Xtensa::L16UI:
+  case Xtensa::L32I:
+  case Xtensa::L32I_N:
+  case Xtensa::L32F: {
+    const MachineMemOperand &MMO = **MI.memoperands_begin();
+    if (MMO.isVolatile()) {
+      BuildMI(*MBB, MI, DL, TII.get(Xtensa::MEMW));
+    }
+    return MBB;
+  }
+  default:
+    llvm_unreachable("Unexpected instr type to insert");
+  }
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaISelLowering.h
@@ -0,0 +1,233 @@
+//===- XtensaISelLowering.h - Xtensa DAG Lowering Interface -----*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file defines the interfaces that Xtensa uses to lower LLVM code into a
+// selection DAG.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSAISELLOWERING_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSAISELLOWERING_H
+
+#include "llvm/CodeGen/CallingConvLower.h"
+#include "llvm/CodeGen/SelectionDAG.h"
+#include "llvm/CodeGen/TargetLowering.h"
+
+namespace llvm {
+namespace XtensaISD {
+enum {
+  FIRST_NUMBER = ISD::BUILTIN_OP_END,
+
+  BR_CC_T,
+  BR_CC_F,
+
+  BR_JT,
+
+  // Calls a function.  Operand 0 is the chain operand and operand 1
+  // is the target address.  The arguments start at operand 2.
+  // There is an optional glue operand at the end.
+  CALL,
+  // WinABI Call version
+  CALLW,
+
+  // Floating point unordered compare conditions
+  CMPUEQ,
+  CMPULE,
+  CMPULT,
+  CMPUO,
+  // Floating point compare conditions
+  CMPOEQ,
+  CMPOLE,
+  CMPOLT,
+  // FP multipy-add/sub
+  MADD,
+  MSUB,
+  // FP move
+  MOVS,
+
+  MEMW,
+
+  MOVSP,
+
+  // Wraps a TargetGlobalAddress that should be loaded using PC-relative
+  // accesses.  Operand 0 is the address.
+  PCREL_WRAPPER,
+
+  // Return with a flag operand.  Operand 0 is the chain operand.
+  RET_FLAG,
+  // WinABI Return
+  RETW_FLAG,
+
+  RUR,
+
+  // Selects between operand 0 and operand 1.  Operand 2 is the
+  // mask of condition-code values for which operand 0 should be
+  // chosen over operand 1; it has the same form as BR_CCMASK.
+  // Operand 3 is the flag operand.
+  SELECT,
+  SELECT_CC,
+  SELECT_CC_FP,
+
+  // Shift
+  SHL,
+  SRA,
+  SRL,
+  SRC,
+  SSL,
+  SSR
+};
+}
+
+class XtensaSubtarget;
+
+class XtensaTargetLowering : public TargetLowering {
+public:
+  explicit XtensaTargetLowering(const TargetMachine &TM,
+                                const XtensaSubtarget &STI);
+
+  MVT getScalarShiftAmountTy(const DataLayout &, EVT LHSTy) const override {
+    return LHSTy.getSizeInBits() <= 32 ? MVT::i32 : MVT::i64;
+  }
+
+  EVT getSetCCResultType(const DataLayout &, LLVMContext &,
+                         EVT VT) const override {
+    if (!VT.isVector())
+      return MVT::i32;
+    return VT.changeVectorElementTypeToInteger();
+  }
+
+  bool isFMAFasterThanFMulAndFAdd(const MachineFunction &MF,
+                                  EVT VT) const override {
+    return true;
+  }
+
+  /// If a physical register, this returns the register that receives the
+  /// exception address on entry to an EH pad.
+  unsigned
+  getExceptionPointerRegister(const Constant *PersonalityFn) const override;
+  /// If a physical register, this returns the register that receives the
+  /// exception typeid on entry to a landing pad.
+  unsigned
+  getExceptionSelectorRegister(const Constant *PersonalityFn) const override;
+
+  bool isOffsetFoldingLegal(const GlobalAddressSDNode *GA) const override;
+  bool isFPImmLegal(const APFloat &Imm, EVT VT,
+                    bool ForCodeSize) const override;
+  const char *getTargetNodeName(unsigned Opcode) const override;
+
+  /// Returns the size of the platform's va_list object.
+  unsigned getVaListSizeInBits(const DataLayout &DL) const override;
+
+  std::pair<unsigned, const TargetRegisterClass *>
+  getRegForInlineAsmConstraint(const TargetRegisterInfo *TRI,
+                               StringRef Constraint, MVT VT) const override;
+  TargetLowering::ConstraintType
+  getConstraintType(StringRef Constraint) const override;
+  TargetLowering::ConstraintWeight
+  getSingleConstraintMatchWeight(AsmOperandInfo &info,
+                                 const char *constraint) const override;
+
+  void LowerAsmOperandForConstraint(SDValue Op, std::string &Constraint,
+                                    std::vector<SDValue> &Ops,
+                                    SelectionDAG &DAG) const override;
+
+  SDValue PerformDAGCombine(SDNode *N, DAGCombinerInfo &DCI) const override;
+
+  SDValue LowerOperation(SDValue Op, SelectionDAG &DAG) const override;
+  SDValue LowerFormalArguments(SDValue Chain, CallingConv::ID CallConv,
+                               bool isVarArg,
+                               const SmallVectorImpl<ISD::InputArg> &Ins,
+                               const SDLoc &DL, SelectionDAG &DAG,
+                               SmallVectorImpl<SDValue> &InVals) const override;
+  SDValue LowerCall(CallLoweringInfo &CLI,
+                    SmallVectorImpl<SDValue> &InVals) const override;
+
+  bool CanLowerReturn(CallingConv::ID CallConv, MachineFunction &MF,
+                      bool isVarArg,
+                      const SmallVectorImpl<ISD::OutputArg> &Outs,
+                      LLVMContext &Context) const override;
+
+  SDValue LowerReturn(SDValue Chain, CallingConv::ID CallConv, bool IsVarArg,
+                      const SmallVectorImpl<ISD::OutputArg> &Outs,
+                      const SmallVectorImpl<SDValue> &OutVals, const SDLoc &DL,
+                      SelectionDAG &DAG) const override;
+
+  bool shouldInsertFencesForAtomic(const Instruction *I) const override {
+    return true;
+  }
+
+  MachineBasicBlock *
+  EmitInstrWithCustomInserter(MachineInstr &MI,
+                              MachineBasicBlock *BB) const override;
+
+private:
+  const XtensaSubtarget &Subtarget;
+
+  SDValue LowerBR_JT(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerImmediate(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerImmediateFP(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerGlobalAddress(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerGlobalTLSAddress(GlobalAddressSDNode *Node,
+                                SelectionDAG &DAG) const;
+  SDValue LowerBlockAddress(BlockAddressSDNode *Node, SelectionDAG &DAG) const;
+  SDValue LowerJumpTable(JumpTableSDNode *JT, SelectionDAG &DAG) const;
+  SDValue LowerConstantPool(ConstantPoolSDNode *CP, SelectionDAG &DAG) const;
+
+  SDValue LowerBR_CC(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerSETCC(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerSELECT_CC(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerRETURNADDR(SDValue Op, SelectionDAG &DAG) const;
+
+  SDValue LowerVASTART(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerVACOPY(SDValue Op, SelectionDAG &DAG) const;
+
+  SDValue LowerDYNAMIC_STACKALLOC(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerSTACKSAVE(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerSTACKRESTORE(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerFRAMEADDR(SDValue Op, SelectionDAG &DAG) const;
+
+  SDValue LowerShiftLeftParts(SDValue Op, SelectionDAG &DAG) const;
+  SDValue LowerShiftRightParts(SDValue Op, SelectionDAG &DAG, bool IsSRA) const;
+  SDValue LowerFunnelShift(SDValue Op, SelectionDAG &DAG) const;
+
+  SDValue LowerATOMIC_FENCE(SDValue Op, SelectionDAG &DAG) const;
+
+  SDValue getAddrPCRel(SDValue Op, SelectionDAG &DAG) const;
+
+  CCAssignFn *CCAssignFnForCall(CallingConv::ID CC, bool IsVarArg) const;
+
+  // Implement EmitInstrWithCustomInserter for individual operation types.
+  MachineBasicBlock *emitSelectCC(MachineInstr &MI,
+                                  MachineBasicBlock *BB) const;
+  MachineBasicBlock *emitAtomicSwap(MachineInstr &MI, MachineBasicBlock *BB,
+                                    int isByteOperand) const;
+  MachineBasicBlock *emitAtomicCmpSwap(MachineInstr &MI, MachineBasicBlock *BB,
+                                       int isByteOperand) const;
+  MachineBasicBlock *emitAtomicSwap(MachineInstr &MI,
+                                    MachineBasicBlock *BB) const;
+  MachineBasicBlock *emitAtomicRMW(MachineInstr &MI, MachineBasicBlock *BB,
+                                   bool isByteOperand, unsigned Opcode,
+                                   bool inv, bool minmax) const;
+  MachineBasicBlock *emitAtomicRMW(MachineInstr &MI, MachineBasicBlock *BB,
+                                   unsigned Opcode, bool inv,
+                                   bool minmax) const;
+
+  unsigned getInlineAsmMemConstraint(StringRef ConstraintCode) const override {
+    if (ConstraintCode == "R")
+      return InlineAsm::Constraint_R;
+    else if (ConstraintCode == "ZC")
+      return InlineAsm::Constraint_ZC;
+    return TargetLowering::getInlineAsmMemConstraint(ConstraintCode);
+  }
+};
+
+} // end namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSAISELLOWERING_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaInstrFormats.td
@@ -0,0 +1,237 @@
+//===- XtensaInstrFormats.td - Xtensa Instruction Formats -------*- tablegen -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===---------------------------------------------------------------------------===//
+
+// Base class for Xtensa 16 & 24 bit Formats
+class XtensaInst<int size, dag outs, dag ins, string asmstr, list<dag> pattern,
+                 InstrItinClass itin = NoItinerary>: Instruction
+{
+  let Namespace = "Xtensa";
+
+  let Size = size;
+
+  let OutOperandList = outs;
+  let InOperandList  = ins;
+
+  let AsmString   = asmstr;
+  let Pattern     = pattern;
+  let Itinerary   = itin;
+
+}
+
+// Base class for Xtensa 24 bit Format
+class XtensaInst24<dag outs, dag ins, string asmstr, list<dag> pattern,
+                   InstrItinClass itin = NoItinerary>:
+                   XtensaInst<3, outs, ins, asmstr, pattern, itin>
+{
+  field bits<24> Inst;
+  field bits<24> SoftFail = 0;
+}
+
+// Base class for Xtensa 16 bit Format
+class XtensaInst16<dag outs, dag ins, string asmstr, list<dag> pattern,
+                   InstrItinClass itin = NoItinerary>:
+                   XtensaInst<2, outs, ins, asmstr, pattern, itin>
+{
+  field bits<16> Inst;
+  field bits<16> SoftFail = 0;
+  let Predicates = [HasDensity];
+}
+
+class RRR_Inst<bits<4> op0, bits<4> op1, bits<4> op2, dag outs, dag ins,
+               string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+               XtensaInst24<outs, ins, asmstr, pattern, itin>
+{
+  bits<4> r;
+  bits<4> s;
+  bits<4> t;
+
+  let Inst{23-20} = op2;
+  let Inst{19-16} = op1;
+  let Inst{15-12} = r;
+  let Inst{11-8} = s;
+  let Inst{7-4} = t;
+  let Inst{3-0} = op0;
+}
+
+class RRI4_Inst<bits<4> op0, bits<4> op1, dag outs, dag ins,
+                string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+                XtensaInst24<outs, ins, asmstr, pattern, itin>
+{
+  bits<4> r;
+  bits<4> s;
+  bits<4> t;
+  bits<4> imm4;
+
+  let Inst{23-20} = imm4;
+  let Inst{19-16} = op1;
+  let Inst{15-12} = r;
+  let Inst{11-8} = s;
+  let Inst{7-4} = t;
+  let Inst{3-0} = op0;
+}
+
+class RRI8_Inst<bits<4> op0, dag outs, dag ins,
+                string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+                XtensaInst24<outs, ins, asmstr, pattern, itin>
+{
+  bits<4> r;
+  bits<4> s;
+  bits<4> t;
+  bits<8> imm8;
+
+  let Inst{23-16} = imm8;
+  let Inst{15-12} = r;
+  let Inst{11-8} = s;
+  let Inst{7-4} = t;
+  let Inst{3-0} = op0;
+}
+
+class RI16_Inst<bits<4> op0, dag outs, dag ins,
+                string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+                XtensaInst24<outs, ins, asmstr, pattern, itin>
+{
+  bits<4> t;
+  bits<16> imm16;
+
+  let Inst{23-8} = imm16;
+  let Inst{7-4} = t;
+  let Inst{3-0} = op0;
+}
+
+class RSR_Inst<bits<4> op0, bits<4> op1, bits<4> op2, dag outs, dag ins,
+               string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+               XtensaInst24<outs, ins, asmstr, pattern, itin>
+{
+  bits<8> sr;
+  bits<4> t;
+
+  let Inst{23-20} = op2;
+  let Inst{19-16} = op1;
+  let Inst{15-8} = sr;
+  let Inst{7-4} = t;
+  let Inst{3-0} = op0;
+}
+
+class CALL_Inst<bits<4> op0, dag outs, dag ins,
+                string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+                XtensaInst24<outs, ins, asmstr, pattern, itin>
+{
+  bits<18> offset;
+  bits<2> n;
+
+  let Inst{23-6} = offset;
+  let Inst{5-4} = n;
+  let Inst{3-0} = op0;
+}
+
+class CALLX_Inst<bits<4> op0, bits<4> op1, bits<4> op2, dag outs, dag ins,
+                 string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+                 XtensaInst24<outs, ins, asmstr, pattern, itin>
+{
+  bits<4> r;
+  bits<4> s;
+  bits<2> m;
+  bits<2> n;
+
+  let Inst{23-20} = op2;
+  let Inst{19-16} = op1;
+  let Inst{15-12} = r;
+  let Inst{11-8} = s;
+  let Inst{7-6} = m;
+  let Inst{5-4} = n;
+  let Inst{3-0} = op0;
+}
+
+class BRI8_Inst<bits<4> op0, dag outs, dag ins,
+                string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+                XtensaInst24<outs, ins, asmstr, pattern, itin>
+{
+  bits<8> imm8;
+  bits<4> r;
+  bits<4> s;
+  bits<2> m;
+  bits<2> n;
+
+  let Inst{23-16} = imm8;
+  let Inst{15-12} = r;
+  let Inst{11-8} = s;
+  let Inst{7-6} = m;
+  let Inst{5-4} = n;
+  let Inst{3-0} = op0;
+}
+
+class BRI12_Inst<bits<4> op0, bits<2> n, bits<2> m, dag outs, dag ins,
+                 string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+                 XtensaInst24<outs, ins, asmstr, pattern, itin>
+{
+  bits<12> imm12;
+  bits<4> s;
+
+
+  let Inst{23-12} = imm12;
+  let Inst{11-8} = s;
+  let Inst{7-6} = m;
+  let Inst{5-4} = n;
+  let Inst{3-0} = op0;
+}
+
+class RRRN_Inst<bits<4> op0, dag outs, dag ins,
+                string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+                XtensaInst16<outs, ins, asmstr, pattern, itin>
+{
+  bits<4> r;
+  bits<4> s;
+  bits<4> t;
+
+  let Inst{15-12} = r;
+  let Inst{11-8} = s;
+  let Inst{7-4} = t;
+  let Inst{3-0} = op0;
+}
+
+class RI7_Inst<bits<4> op0, bits<1> i, dag outs, dag ins,
+               string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+               XtensaInst16<outs, ins, asmstr, pattern, itin>
+{
+  bits<7> imm7;
+  bits<4> s;
+
+  let Inst{15-12} = imm7{3-0};
+  let Inst{11-8} = s;
+  let Inst{7} = i;
+  let Inst{6-4} = imm7{6-4};
+  let Inst{3-0} = op0;
+}
+
+class RI6_Inst<bits<4> op0, bits<1> i,  bits<1> z, dag outs, dag ins,
+               string asmstr, list<dag> pattern, InstrItinClass itin = NoItinerary>:
+               XtensaInst16<outs, ins, asmstr, pattern, itin>
+{
+  bits<6> imm6;
+  bits<4> s;
+
+  let Inst{15-12} = imm6{3-0};
+  let Inst{11-8} = s;
+  let Inst{7} = i;
+  let Inst{6} = z;
+  let Inst{5-4} = imm6{5-4};
+  let Inst{3-0} = op0;
+}
+
+// Pseudo instructions
+class Pseudo<dag outs, dag ins, string asmstr, list<dag> pattern>
+    : XtensaInst<2, outs, ins, asmstr, pattern>
+{
+  field bits<16> Inst;
+  field bits<16> SoftFail = 0;
+  let Inst = 0x0;
+  let isPseudo = 1;
+  let isCodeGenOnly = 1;
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaInstrInfo.cpp
@@ -0,0 +1,689 @@
+//===- XtensaInstrInfo.cpp - Xtensa Instruction Information ---------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains the Xtensa implementation of the TargetInstrInfo class.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaInstrInfo.h"
+#include "XtensaConstantPoolValue.h"
+#include "XtensaTargetMachine.h"
+#include "llvm/CodeGen/MachineConstantPool.h"
+#include "llvm/CodeGen/MachineInstrBuilder.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/CodeGen/RegisterScavenging.h"
+
+#define GET_INSTRINFO_CTOR_DTOR
+#include "XtensaGenInstrInfo.inc"
+
+using namespace llvm;
+
+static inline const MachineInstrBuilder &
+addFrameReference(const MachineInstrBuilder &MIB, int FI) {
+  MachineInstr *MI = MIB;
+  MachineFunction &MF = *MI->getParent()->getParent();
+  MachineFrameInfo &MFFrame = MF.getFrameInfo();
+  const MCInstrDesc &MCID = MI->getDesc();
+  MachineMemOperand::Flags Flags = MachineMemOperand::MONone;
+  if (MCID.mayLoad())
+    Flags |= MachineMemOperand::MOLoad;
+  if (MCID.mayStore())
+    Flags |= MachineMemOperand::MOStore;
+  int64_t Offset = 0;
+  unsigned Align = MFFrame.getObjectAlignment(FI);
+
+  MachineMemOperand *MMO =
+      MF.getMachineMemOperand(MachinePointerInfo::getFixedStack(MF, FI, Offset),
+                              Flags, MFFrame.getObjectSize(FI), Align);
+  return MIB.addFrameIndex(FI).addImm(Offset).addMemOperand(MMO);
+}
+
+XtensaInstrInfo::XtensaInstrInfo(XtensaSubtarget &sti)
+    : XtensaGenInstrInfo(Xtensa::ADJCALLSTACKDOWN, Xtensa::ADJCALLSTACKUP),
+      RI(sti), STI(sti) {}
+
+/// Adjust SP by Amount bytes.
+void XtensaInstrInfo::adjustStackPtr(unsigned SP, int64_t Amount,
+                                     MachineBasicBlock &MBB,
+                                     MachineBasicBlock::iterator I) const {
+  DebugLoc DL = I != MBB.end() ? I->getDebugLoc() : DebugLoc();
+
+  if (Amount == 0)
+    return;
+
+  MachineRegisterInfo &RegInfo = MBB.getParent()->getRegInfo();
+  const TargetRegisterClass *RC = &Xtensa::ARRegClass;
+
+  // create virtual reg to store immediate
+  unsigned Reg = RegInfo.createVirtualRegister(RC);
+
+  if (isInt<8>(Amount)) // addi sp, sp, amount
+    BuildMI(MBB, I, DL, get(Xtensa::ADDI), Reg).addReg(SP).addImm(Amount);
+  else { // Expand immediate that doesn't fit in 12-bit.
+    unsigned Reg1;
+    loadImmediate(MBB, I, &Reg1, Amount);
+    BuildMI(MBB, I, DL, get(Xtensa::ADD), Reg)
+        .addReg(SP)
+        .addReg(Reg1, RegState::Kill);
+  }
+
+  if (STI.isWinABI()) {
+    BuildMI(MBB, I, DL, get(Xtensa::MOVSP), SP).addReg(Reg, RegState::Kill);
+  } else {
+    BuildMI(MBB, I, DL, get(Xtensa::OR), SP)
+        .addReg(Reg, RegState::Kill)
+        .addReg(Reg, RegState::Kill);
+  }
+}
+
+void XtensaInstrInfo::copyPhysReg(MachineBasicBlock &MBB,
+                                  MachineBasicBlock::iterator MBBI,
+                                  const DebugLoc &DL, MCRegister DestReg,
+                                  MCRegister SrcReg, bool KillSrc) const {
+  unsigned Opcode;
+
+  // when we are copying a phys reg we want the bits for fp
+  if (Xtensa::ARRegClass.contains(DestReg, SrcReg)) {
+    BuildMI(MBB, MBBI, DL, get(Xtensa::OR), DestReg)
+        .addReg(SrcReg, getKillRegState(KillSrc))
+        .addReg(SrcReg, getKillRegState(KillSrc));
+    return;
+  } else if (STI.hasSingleFloat() && Xtensa::FPRRegClass.contains(SrcReg) &&
+             Xtensa::FPRRegClass.contains(DestReg))
+    Opcode = Xtensa::MOV_S;
+  else if (STI.hasSingleFloat() && Xtensa::FPRRegClass.contains(SrcReg) &&
+           Xtensa::ARRegClass.contains(DestReg))
+    Opcode = Xtensa::RFR;
+  else if (STI.hasSingleFloat() && Xtensa::ARRegClass.contains(SrcReg) &&
+           Xtensa::FPRRegClass.contains(DestReg))
+    Opcode = Xtensa::WFR;
+  else
+    llvm_unreachable("Impossible reg-to-reg copy");
+
+  BuildMI(MBB, MBBI, DL, get(Opcode), DestReg)
+      .addReg(SrcReg, getKillRegState(KillSrc));
+}
+
+void XtensaInstrInfo::storeRegToStackSlot(MachineBasicBlock &MBB,
+                                          MachineBasicBlock::iterator MBBI,
+                                          unsigned SrcReg, bool isKill,
+                                          int FrameIdx,
+                                          const TargetRegisterClass *RC,
+                                          const TargetRegisterInfo *TRI) const {
+  DebugLoc DL = MBBI != MBB.end() ? MBBI->getDebugLoc() : DebugLoc();
+  unsigned LoadOpcode, StoreOpcode;
+  getLoadStoreOpcodes(RC, LoadOpcode, StoreOpcode, FrameIdx);
+  addFrameReference(BuildMI(MBB, MBBI, DL, get(StoreOpcode))
+                        .addReg(SrcReg, getKillRegState(isKill)),
+                    FrameIdx);
+}
+
+void XtensaInstrInfo::loadRegFromStackSlot(
+    MachineBasicBlock &MBB, MachineBasicBlock::iterator MBBI, unsigned DestReg,
+    int FrameIdx, const TargetRegisterClass *RC,
+    const TargetRegisterInfo *TRI) const {
+  DebugLoc DL = MBBI != MBB.end() ? MBBI->getDebugLoc() : DebugLoc();
+  unsigned LoadOpcode, StoreOpcode;
+  getLoadStoreOpcodes(RC, LoadOpcode, StoreOpcode, FrameIdx);
+  addFrameReference(BuildMI(MBB, MBBI, DL, get(LoadOpcode), DestReg), FrameIdx);
+}
+
+void XtensaInstrInfo::getLoadStoreOpcodes(const TargetRegisterClass *RC,
+                                          unsigned &LoadOpcode,
+                                          unsigned &StoreOpcode,
+                                          int64_t offset) const {
+  if (RC == &Xtensa::ARRegClass) {
+    LoadOpcode = Xtensa::L32I;
+    StoreOpcode = Xtensa::S32I;
+  } else if (RC == &Xtensa::FPRRegClass) {
+    LoadOpcode = Xtensa::L32F;
+    StoreOpcode = Xtensa::S32F;
+  } else
+    llvm_unreachable("Unsupported regclass to load or store");
+}
+
+void XtensaInstrInfo::loadImmediate(MachineBasicBlock &MBB,
+                                    MachineBasicBlock::iterator MBBI,
+                                    unsigned *Reg, int64_t Value) const {
+  DebugLoc DL = MBBI != MBB.end() ? MBBI->getDebugLoc() : DebugLoc();
+  MachineRegisterInfo &RegInfo = MBB.getParent()->getRegInfo();
+  const TargetRegisterClass *RC = &Xtensa::ARRegClass;
+
+  // create virtual reg to store immediate
+  *Reg = RegInfo.createVirtualRegister(RC);
+  if (Value >= -2048 && Value <= 2047) {
+    BuildMI(MBB, MBBI, DL, get(Xtensa::MOVI), *Reg).addImm(Value);
+  } else if (Value >= -32768 && Value <= 32767) {
+    int Low = Value & 0xFF;
+    int High = Value & ~0xFF;
+
+    BuildMI(MBB, MBBI, DL, get(Xtensa::MOVI), *Reg).addImm(Low);
+    BuildMI(MBB, MBBI, DL, get(Xtensa::ADDMI), *Reg).addReg(*Reg).addImm(High);
+  } else if (Value >= -4294967296LL && Value <= 4294967295LL) {
+    // 32 bit arbirary constant
+    MachineConstantPool *MCP = MBB.getParent()->getConstantPool();
+    uint64_t UVal = ((uint64_t)Value) & 0xFFFFFFFFLL;
+    const Constant *CVal = ConstantInt::get(
+        Type::getInt32Ty(MBB.getParent()->getFunction().getContext()), UVal,
+        false);
+    unsigned Idx = MCP->getConstantPoolIndex(CVal, 2U);
+    //	MCSymbol MSym
+    BuildMI(MBB, MBBI, DL, get(Xtensa::L32R), *Reg).addConstantPoolIndex(Idx);
+  } else {
+    // use L32R to let assembler load immediate best
+    // TODO replace to L32R
+    llvm_unreachable("Unsupported load immediate value");
+  }
+}
+
+unsigned XtensaInstrInfo::getInstSizeInBytes(const MachineInstr &MI) const {
+  switch (MI.getOpcode()) {
+  case TargetOpcode::INLINEASM: { // Inline Asm: Variable size.
+    const MachineFunction *MF = MI.getParent()->getParent();
+    const char *AsmStr = MI.getOperand(0).getSymbolName();
+    return getInlineAsmLength(AsmStr, *MF->getTarget().getMCAsmInfo());
+  }
+  default:
+    return MI.getDesc().getSize();
+  }
+}
+
+bool XtensaInstrInfo::reverseBranchCondition(
+    SmallVectorImpl<MachineOperand> &Cond) const {
+  assert(Cond.size() <= 4 && "Invalid branch condition!");
+
+  switch (Cond[0].getImm()) {
+  case Xtensa::BEQ:
+    Cond[0].setImm(Xtensa::BNE);
+    return false;
+  case Xtensa::BNE:
+    Cond[0].setImm(Xtensa::BEQ);
+    return false;
+  case Xtensa::BLT:
+    Cond[0].setImm(Xtensa::BGE);
+    return false;
+  case Xtensa::BGE:
+    Cond[0].setImm(Xtensa::BLT);
+    return false;
+  case Xtensa::BLTU:
+    Cond[0].setImm(Xtensa::BGEU);
+    return false;
+  case Xtensa::BGEU:
+    Cond[0].setImm(Xtensa::BLTU);
+    return false;
+
+  case Xtensa::BEQI:
+    Cond[0].setImm(Xtensa::BNEI);
+    return false;
+  case Xtensa::BNEI:
+    Cond[0].setImm(Xtensa::BEQI);
+    return false;
+  case Xtensa::BGEI:
+    Cond[0].setImm(Xtensa::BLTI);
+    return false;
+  case Xtensa::BLTI:
+    Cond[0].setImm(Xtensa::BGEI);
+    return false;
+  case Xtensa::BGEUI:
+    Cond[0].setImm(Xtensa::BLTUI);
+    return false;
+  case Xtensa::BLTUI:
+    Cond[0].setImm(Xtensa::BGEUI);
+    return false;
+
+  case Xtensa::BEQZ:
+    Cond[0].setImm(Xtensa::BNEZ);
+    return false;
+  case Xtensa::BNEZ:
+    Cond[0].setImm(Xtensa::BEQZ);
+    return false;
+  case Xtensa::BLTZ:
+    Cond[0].setImm(Xtensa::BGEZ);
+    return false;
+  case Xtensa::BGEZ:
+    Cond[0].setImm(Xtensa::BLTZ);
+    return false;
+
+  case Xtensa::BF:
+    Cond[0].setImm(Xtensa::BT);
+    return false;
+  case Xtensa::BT:
+    Cond[0].setImm(Xtensa::BF);
+    return false;
+  default:
+    llvm_unreachable("Invalid branch condition!");
+  }
+}
+
+MachineBasicBlock *
+XtensaInstrInfo::getBranchDestBlock(const MachineInstr &MI) const {
+  unsigned OpCode = MI.getOpcode();
+  switch (OpCode) {
+  case Xtensa::BR_JT:
+  case Xtensa::JX:
+    return nullptr;
+  case Xtensa::J:
+    return MI.getOperand(0).getMBB();
+  case Xtensa::BEQ:
+  case Xtensa::BNE:
+  case Xtensa::BLT:
+  case Xtensa::BLTU:
+  case Xtensa::BGE:
+  case Xtensa::BGEU:
+    return MI.getOperand(2).getMBB();
+
+  case Xtensa::BEQI:
+  case Xtensa::BNEI:
+  case Xtensa::BLTI:
+  case Xtensa::BLTUI:
+  case Xtensa::BGEI:
+  case Xtensa::BGEUI:
+    return MI.getOperand(2).getMBB();
+
+  case Xtensa::BEQZ:
+  case Xtensa::BNEZ:
+  case Xtensa::BLTZ:
+  case Xtensa::BGEZ:
+    return MI.getOperand(1).getMBB();
+
+  case Xtensa::BT:
+  case Xtensa::BF:
+    return MI.getOperand(1).getMBB();
+
+  default:
+    llvm_unreachable("Unknown branch opcode");
+  }
+}
+
+bool XtensaInstrInfo::isBranchOffsetInRange(unsigned BranchOp,
+                                            int64_t BrOffset) const {
+  switch (BranchOp) {
+  case Xtensa::J:
+    BrOffset -= 4;
+    return isIntN(18, BrOffset);
+  case Xtensa::JX:
+    return true;
+  case Xtensa::BR_JT:
+    return true;
+  case Xtensa::BEQ:
+  case Xtensa::BNE:
+  case Xtensa::BLT:
+  case Xtensa::BLTU:
+  case Xtensa::BGE:
+  case Xtensa::BGEU:
+  case Xtensa::BEQI:
+  case Xtensa::BNEI:
+  case Xtensa::BLTI:
+  case Xtensa::BLTUI:
+  case Xtensa::BGEI:
+  case Xtensa::BGEUI:
+    BrOffset -= 4;
+    return isIntN(8, BrOffset);
+  case Xtensa::BEQZ:
+  case Xtensa::BNEZ:
+  case Xtensa::BLTZ:
+  case Xtensa::BGEZ:
+    BrOffset -= 4;
+    return isIntN(12, BrOffset);
+  case Xtensa::BT:
+  case Xtensa::BF:
+    BrOffset -= 4;
+    return isIntN(8, BrOffset);
+  default:
+    llvm_unreachable("Unknown branch opcode");
+  }
+}
+
+bool XtensaInstrInfo::analyzeBranch(MachineBasicBlock &MBB,
+                                    MachineBasicBlock *&TBB,
+                                    MachineBasicBlock *&FBB,
+                                    SmallVectorImpl<MachineOperand> &Cond,
+                                    bool AllowModify = false) const {
+  // Most of the code and comments here are boilerplate.
+
+  // Start from the bottom of the block and work up, examining the
+  // terminator instructions.
+  MachineBasicBlock::iterator I = MBB.end();
+  while (I != MBB.begin()) {
+    --I;
+    if (I->isDebugValue())
+      continue;
+
+    // Working from the bottom, when we see a non-terminator instruction, we're
+    // done.
+    if (!isUnpredicatedTerminator(*I))
+      break;
+
+    // A terminator that isn't a branch can't easily be handled by this
+    // analysis.
+    SmallVector<MachineOperand, 4> ThisCond;
+    ThisCond.push_back(MachineOperand::CreateImm(0));
+    const MachineOperand *ThisTarget;
+    if (!isBranch(I, ThisCond, ThisTarget))
+      return true;
+
+    // Can't handle indirect branches.
+    if (!ThisTarget->isMBB())
+      return true;
+
+    if (ThisCond[0].getImm() == Xtensa::J) {
+      // Handle unconditional branches.
+      if (!AllowModify) {
+        TBB = ThisTarget->getMBB();
+        continue;
+      }
+
+      // If the block has any instructions after a JMP, delete them.
+      while (std::next(I) != MBB.end())
+        std::next(I)->eraseFromParent();
+
+      Cond.clear();
+      FBB = 0;
+
+      // TBB is used to indicate the unconditinal destination.
+      TBB = ThisTarget->getMBB();
+      continue;
+    }
+
+    // Working from the bottom, handle the first conditional branch.
+    if (Cond.empty()) {
+      // FIXME: add X86-style branch swap
+      FBB = TBB;
+      TBB = ThisTarget->getMBB();
+      Cond.push_back(MachineOperand::CreateImm(ThisCond[0].getImm()));
+
+      // push remaining operands
+      for (unsigned int i = 0; i < (I->getNumExplicitOperands() - 1); i++)
+        Cond.push_back(I->getOperand(i));
+
+      continue;
+    }
+
+    // Handle subsequent conditional branches.
+    assert(Cond.size() <= 4);
+    assert(TBB);
+
+    // Only handle the case where all conditional branches branch to the same
+    // destination.
+    if (TBB != ThisTarget->getMBB())
+      return true;
+
+    // If the conditions are the same, we can leave them alone.
+    unsigned OldCond = Cond[0].getImm();
+    if (OldCond == ThisCond[0].getImm())
+      continue;
+  }
+
+  return false;
+}
+
+unsigned XtensaInstrInfo::removeBranch(MachineBasicBlock &MBB,
+                                       int *BytesRemoved) const {
+  // Most of the code and comments here are boilerplate.
+  MachineBasicBlock::iterator I = MBB.end();
+  unsigned Count = 0;
+  if (BytesRemoved)
+    *BytesRemoved = 0;
+
+  while (I != MBB.begin()) {
+    --I;
+    SmallVector<MachineOperand, 4> Cond;
+    Cond.push_back(MachineOperand::CreateImm(0));
+    const MachineOperand *Target;
+    if (!isBranch(I, Cond, Target))
+      break;
+    if (!Target->isMBB())
+      break;
+    // Remove the branch.
+    if (BytesRemoved)
+      *BytesRemoved += getInstSizeInBytes(*I);
+    I->eraseFromParent();
+    I = MBB.end();
+    ++Count;
+  }
+  return Count;
+}
+
+unsigned XtensaInstrInfo::insertBranch(
+    MachineBasicBlock &MBB, MachineBasicBlock *TBB, MachineBasicBlock *FBB,
+    ArrayRef<MachineOperand> Cond, const DebugLoc &DL, int *BytesAdded) const {
+  unsigned Count = 0;
+  if (BytesAdded)
+    *BytesAdded = 0;
+  if (FBB) {
+    // Need to build two branches then
+    // one to branch to TBB on Cond
+    // and a second one immediately after to unconditionally jump to FBB
+    Count = InsertBranchAtInst(MBB, MBB.end(), TBB, Cond, DL, BytesAdded);
+    auto &MI = *BuildMI(&MBB, DL, get(Xtensa::J)).addMBB(FBB);
+    Count++;
+    if (BytesAdded)
+      *BytesAdded += getInstSizeInBytes(MI);
+    return Count;
+  }
+  // This function inserts the branch at the end of the MBB
+  Count += InsertBranchAtInst(MBB, MBB.end(), TBB, Cond, DL, BytesAdded);
+  return Count;
+}
+
+unsigned XtensaInstrInfo::insertIndirectBranch(MachineBasicBlock &MBB,
+                                               MachineBasicBlock &DestBB,
+                                               const DebugLoc &DL,
+                                               int64_t BrOffset,
+                                               RegScavenger *RS) const {
+  assert(RS && "RegScavenger required for long branching");
+  assert(MBB.empty() &&
+         "new block should be inserted for expanding unconditional branch");
+  assert(MBB.pred_size() == 1);
+
+  MachineFunction *MF = MBB.getParent();
+  MachineRegisterInfo &MRI = MF->getRegInfo();
+  MachineConstantPool *ConstantPool = MF->getConstantPool();
+
+  if (!isInt<32>(BrOffset))
+    report_fatal_error(
+        "Branch offsets outside of the signed 32-bit range not supported");
+  XtensaConstantPoolValue *C =
+      XtensaConstantPoolMBB::Create(MF->getFunction().getContext(), &DestBB, 0);
+  unsigned Idx = ConstantPool->getConstantPoolIndex(C, 4);
+
+  // FIXME: A virtual register must be used initially, as the register
+  // scavenger won't work with empty blocks (SIInstrInfo::insertIndirectBranch
+  // uses the same workaround).
+  Register ScratchReg = MRI.createVirtualRegister(&Xtensa::ARRegClass);
+  auto II = MBB.end();
+
+  MachineInstr &L32R = *BuildMI(MBB, II, DL, get(Xtensa::L32R), ScratchReg)
+                            .addConstantPoolIndex(Idx);
+  BuildMI(MBB, II, DL, get(Xtensa::JX)).addReg(ScratchReg, RegState::Kill);
+  RS->enterBasicBlockEnd(MBB);
+  unsigned Scav = RS->scavengeRegisterBackwards(Xtensa::ARRegClass,
+                                                L32R.getIterator(), false, 0);
+  MRI.replaceRegWith(ScratchReg, Scav);
+  MRI.clearVirtRegs();
+  RS->setRegUsed(Scav);
+  return 3 + 3;
+}
+
+unsigned XtensaInstrInfo::InsertConstBranchAtInst(
+    MachineBasicBlock &MBB, MachineInstr *I, int64_t offset,
+    ArrayRef<MachineOperand> Cond, DebugLoc DL, int *BytesAdded) const {
+  // Shouldn't be a fall through.
+  assert(&MBB && "InsertBranch must not be told to insert a fallthrough");
+  assert(Cond.size() <= 4 &&
+         "Xtensa branch conditions have less than four components!");
+
+  if (Cond.empty() || (Cond[0].getImm() == Xtensa::J)) {
+    // Unconditional branch
+    MachineInstr *MI = BuildMI(MBB, I, DL, get(Xtensa::J)).addImm(offset);
+    if (BytesAdded && MI)
+      *BytesAdded += getInstSizeInBytes(*MI);
+    return 1;
+  }
+
+  unsigned Count = 0;
+  unsigned BR_C = Cond[0].getImm();
+  MachineInstr *MI = nullptr;
+  switch (BR_C) {
+  case Xtensa::BEQ:
+  case Xtensa::BNE:
+  case Xtensa::BLT:
+  case Xtensa::BLTU:
+  case Xtensa::BGE:
+  case Xtensa::BGEU:
+    MI = BuildMI(MBB, I, DL, get(BR_C))
+             .addImm(offset)
+             .addReg(Cond[1].getReg())
+             .addReg(Cond[2].getReg());
+    break;
+  case Xtensa::BEQI:
+  case Xtensa::BNEI:
+  case Xtensa::BLTI:
+  case Xtensa::BLTUI:
+  case Xtensa::BGEI:
+  case Xtensa::BGEUI:
+    MI = BuildMI(MBB, I, DL, get(BR_C))
+             .addImm(offset)
+             .addReg(Cond[1].getReg())
+             .addImm(Cond[2].getImm());
+    break;
+  case Xtensa::BEQZ:
+  case Xtensa::BNEZ:
+  case Xtensa::BLTZ:
+  case Xtensa::BGEZ:
+    MI = BuildMI(MBB, I, DL, get(BR_C)).addImm(offset).addReg(Cond[1].getReg());
+    break;
+  case Xtensa::BT:
+  case Xtensa::BF:
+    MI = BuildMI(MBB, I, DL, get(BR_C)).addImm(offset).addReg(Cond[1].getReg());
+    break;
+  default:
+    llvm_unreachable("Invalid branch type!");
+  }
+  if (BytesAdded && MI)
+    *BytesAdded += getInstSizeInBytes(*MI);
+  ++Count;
+  return Count;
+}
+
+unsigned XtensaInstrInfo::InsertBranchAtInst(MachineBasicBlock &MBB,
+                                             MachineBasicBlock::iterator I,
+                                             MachineBasicBlock *TBB,
+                                             ArrayRef<MachineOperand> Cond,
+                                             const DebugLoc &DL,
+                                             int *BytesAdded) const {
+  // Shouldn't be a fall through.
+  assert(TBB && "InsertBranch must not be told to insert a fallthrough");
+  assert(Cond.size() <= 4 &&
+         "Xtensa branch conditions have less than four components!");
+
+  if (Cond.empty() || (Cond[0].getImm() == Xtensa::J)) {
+    // Unconditional branch
+    MachineInstr *MI = BuildMI(MBB, I, DL, get(Xtensa::J)).addMBB(TBB);
+    if (BytesAdded && MI)
+      *BytesAdded += getInstSizeInBytes(*MI);
+    return 1;
+  }
+
+  unsigned Count = 0;
+  unsigned BR_C = Cond[0].getImm();
+  MachineInstr *MI = nullptr;
+  switch (BR_C) {
+  case Xtensa::BEQ:
+  case Xtensa::BNE:
+  case Xtensa::BLT:
+  case Xtensa::BLTU:
+  case Xtensa::BGE:
+  case Xtensa::BGEU:
+    MI = BuildMI(MBB, I, DL, get(BR_C))
+             .addReg(Cond[1].getReg())
+             .addReg(Cond[2].getReg())
+             .addMBB(TBB);
+    break;
+  case Xtensa::BEQI:
+  case Xtensa::BNEI:
+  case Xtensa::BLTI:
+  case Xtensa::BLTUI:
+  case Xtensa::BGEI:
+  case Xtensa::BGEUI:
+    MI = BuildMI(MBB, I, DL, get(BR_C))
+             .addReg(Cond[1].getReg())
+             .addImm(Cond[2].getImm())
+             .addMBB(TBB);
+    break;
+  case Xtensa::BEQZ:
+  case Xtensa::BNEZ:
+  case Xtensa::BLTZ:
+  case Xtensa::BGEZ:
+    MI = BuildMI(MBB, I, DL, get(BR_C)).addReg(Cond[1].getReg()).addMBB(TBB);
+    break;
+  case Xtensa::BT:
+  case Xtensa::BF:
+    MI = BuildMI(MBB, I, DL, get(BR_C)).addReg(Cond[1].getReg()).addMBB(TBB);
+    break;
+  default:
+    llvm_unreachable("Invalid branch type!");
+  }
+  if (BytesAdded && MI)
+    *BytesAdded += getInstSizeInBytes(*MI);
+  ++Count;
+  return Count;
+}
+
+bool XtensaInstrInfo::isBranch(const MachineBasicBlock::iterator &MI,
+                               SmallVectorImpl<MachineOperand> &Cond,
+                               const MachineOperand *&Target) const {
+  unsigned OpCode = MI->getOpcode();
+  switch (OpCode) {
+  case Xtensa::J:
+  case Xtensa::JX:
+  case Xtensa::BR_JT:
+    Cond[0].setImm(OpCode);
+    Target = &MI->getOperand(0);
+    return true;
+  case Xtensa::BEQ:
+  case Xtensa::BNE:
+  case Xtensa::BLT:
+  case Xtensa::BLTU:
+  case Xtensa::BGE:
+  case Xtensa::BGEU:
+    Cond[0].setImm(OpCode);
+    Target = &MI->getOperand(2);
+    return true;
+
+  case Xtensa::BEQI:
+  case Xtensa::BNEI:
+  case Xtensa::BLTI:
+  case Xtensa::BLTUI:
+  case Xtensa::BGEI:
+  case Xtensa::BGEUI:
+    Cond[0].setImm(OpCode);
+    Target = &MI->getOperand(2);
+    return true;
+
+  case Xtensa::BEQZ:
+  case Xtensa::BNEZ:
+  case Xtensa::BLTZ:
+  case Xtensa::BGEZ:
+    Cond[0].setImm(OpCode);
+    Target = &MI->getOperand(1);
+    return true;
+
+  case Xtensa::BT:
+  case Xtensa::BF:
+    Cond[0].setImm(OpCode);
+    Target = &MI->getOperand(1);
+    return true;
+
+  default:
+    assert(!MI->getDesc().isBranch() && "Unknown branch opcode");
+    return false;
+  }
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaInstrInfo.h
@@ -0,0 +1,106 @@
+//===-- XtensaInstrInfo.h - Xtensa Instruction Information ------*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains the Xtensa implementation of the TargetInstrInfo class.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSAINSTRINFO_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSAINSTRINFO_H
+
+#include "Xtensa.h"
+#include "XtensaRegisterInfo.h"
+#include "llvm/CodeGen/TargetInstrInfo.h"
+#include "llvm/CodeGen/TargetRegisterInfo.h"
+
+#define GET_INSTRINFO_HEADER
+
+#include "XtensaGenInstrInfo.inc"
+
+namespace llvm {
+
+class XtensaTargetMachine;
+class XtensaSubtarget;
+class XtensaInstrInfo : public XtensaGenInstrInfo {
+  const XtensaRegisterInfo RI;
+  XtensaSubtarget &STI;
+
+public:
+  XtensaInstrInfo(XtensaSubtarget &STI);
+
+  void adjustStackPtr(unsigned SP, int64_t Amount, MachineBasicBlock &MBB,
+                      MachineBasicBlock::iterator I) const;
+  unsigned getInstSizeInBytes(const MachineInstr &MI) const override;
+
+  // Return the XtensaRegisterInfo, which this class owns.
+  const XtensaRegisterInfo &getRegisterInfo() const { return RI; }
+
+  void copyPhysReg(MachineBasicBlock &MBB, MachineBasicBlock::iterator MBBI,
+                   const DebugLoc &DL, MCRegister DestReg, MCRegister SrcReg,
+                   bool KillSrc) const override;
+  void storeRegToStackSlot(MachineBasicBlock &MBB,
+                           MachineBasicBlock::iterator MBBI, unsigned SrcReg,
+                           bool isKill, int FrameIndex,
+                           const TargetRegisterClass *RC,
+                           const TargetRegisterInfo *TRI) const override;
+  void loadRegFromStackSlot(MachineBasicBlock &MBB,
+                            MachineBasicBlock::iterator MBBI, unsigned DestReg,
+                            int FrameIdx, const TargetRegisterClass *RC,
+                            const TargetRegisterInfo *TRI) const override;
+
+  // Get the load and store opcodes for a given register class and offset.
+  void getLoadStoreOpcodes(const TargetRegisterClass *RC, unsigned &LoadOpcode,
+                           unsigned &StoreOpcode, int64_t offset) const;
+
+  // Emit code before MBBI in MI to move immediate value Value into
+  // physical register Reg.
+  void loadImmediate(MachineBasicBlock &MBB, MachineBasicBlock::iterator MBBI,
+                     unsigned *Reg, int64_t Value) const;
+  bool
+  reverseBranchCondition(SmallVectorImpl<MachineOperand> &Cond) const override;
+  MachineBasicBlock *getBranchDestBlock(const MachineInstr &MI) const override;
+
+  bool isBranchOffsetInRange(unsigned BranchOpc,
+                             int64_t BrOffset) const override;
+  bool analyzeBranch(MachineBasicBlock &MBB, MachineBasicBlock *&TBB,
+                     MachineBasicBlock *&FBB,
+                     SmallVectorImpl<MachineOperand> &Cond,
+                     bool AllowModify) const override;
+  unsigned removeBranch(MachineBasicBlock &MBB,
+                        int *BytesRemoved = nullptr) const override;
+  unsigned insertBranch(MachineBasicBlock &MBB, MachineBasicBlock *TBB,
+                        MachineBasicBlock *FBB, ArrayRef<MachineOperand> Cond,
+                        const DebugLoc &DL,
+                        int *BytesAdded = nullptr) const override;
+  unsigned insertIndirectBranch(MachineBasicBlock &MBB,
+                                MachineBasicBlock &NewDestBB,
+                                const DebugLoc &DL, int64_t BrOffset = 0,
+                                RegScavenger *RS = nullptr) const override;
+  unsigned InsertBranchAtInst(MachineBasicBlock &MBB,
+                              MachineBasicBlock::iterator I,
+                              MachineBasicBlock *TBB,
+                              ArrayRef<MachineOperand> Cond, const DebugLoc &DL,
+                              int *BytesAdded) const;
+  unsigned InsertConstBranchAtInst(MachineBasicBlock &MBB, MachineInstr *I,
+                                   int64_t offset,
+                                   ArrayRef<MachineOperand> Cond, DebugLoc DL,
+                                   int *BytesAdded) const;
+  // Return true if MI is a conditional or unconditional branch.
+  // When returning true, set Cond to the mask of condition-code
+  // values on which the instruction will branch, and set Target
+  // to the operand that contains the branch target.  This target
+  // can be a register or a basic block.
+  bool isBranch(const MachineBasicBlock::iterator &MI,
+                SmallVectorImpl<MachineOperand> &Cond,
+                const MachineOperand *&Target) const;
+};
+} // end namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSAINSTRINFO_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaInstrInfo.td
@@ -0,0 +1,1627 @@
+//===- XtensaInstrInfo.td - Target Description for Xtensa Target -*- tablegen -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------------===//
+//
+// This file describes the Xtensa instructions in TableGen format.
+//
+//===----------------------------------------------------------------------------===//
+
+include "XtensaInstrFormats.td"
+include "XtensaOperands.td"
+include "XtensaOperators.td"
+
+//===----------------------------------------------------------------------===//
+// Arithmetic & Logical instructions
+//===----------------------------------------------------------------------===//
+
+class ArithLogic_RRR<bits<4> oper2, bits<4> oper1, string instrAsm,
+      SDPatternOperator opNode, bit isComm = 0>
+  : RRR_Inst<0x00, oper1, oper2, (outs AR:$r), (ins AR:$s, AR:$t),
+             instrAsm#"\t$r, $s, $t",
+            [(set AR:$r, (opNode AR:$s, AR:$t))]>
+{
+  let isCommutable = isComm;
+  let isReMaterializable = 0;
+}
+
+def ADD: ArithLogic_RRR<0x08, 0x00, "add", add, 1>;
+def SUB: ArithLogic_RRR<0x0C, 0x00, "sub", sub>;
+def AND: ArithLogic_RRR<0x01, 0x00, "and", and, 1>;
+def OR: ArithLogic_RRR<0x02, 0x00, "or", or, 1>;
+def XOR: ArithLogic_RRR<0x03, 0x00, "xor", xor, 1>;
+
+class ADDX<bits<4> oper, string instrAsm, list<dag> pattern>
+    : RRR_Inst<0x00, 0x00, oper, (outs AR:$r), (ins AR:$s, AR:$t),
+               instrAsm#"\t$r, $s, $t", pattern>;
+
+def ADDX2: ADDX<0x09, "addx2", [(set AR:$r, (add AR:$t, (shl AR:$s, (i32 1))))]>;
+def ADDX4: ADDX<0x0A, "addx4", [(set AR:$r, (add AR:$t, (shl AR:$s, (i32 2))))]>;
+def ADDX8: ADDX<0x0B, "addx8", [(set AR:$r, (add AR:$t, (shl AR:$s, (i32 3))))]>;
+
+class SUBX<bits<4> oper, string instrAsm, list<dag> pattern>
+    : RRR_Inst<0x00, 0x00, oper, (outs AR:$r), (ins AR:$s, AR:$t),
+               instrAsm#"\t$r, $s, $t", pattern>;
+
+def SUBX2: SUBX<0x0D, "subx2", [(set AR:$r, (sub (shl AR:$s, (i32 1)), AR:$t))]>;
+def SUBX4: SUBX<0x0E, "subx4", [(set AR:$r, (sub (shl AR:$s, (i32 2)), AR:$t))]>;
+def SUBX8: SUBX<0x0F, "subx8", [(set AR:$r, (sub (shl AR:$s, (i32 3)), AR:$t))]>;
+
+def ABS: RRR_Inst<0x00, 0x00, 0x06, (outs AR:$r), (ins AR:$t),
+                 "abs\t$r, $t", []>
+{
+  let s = 0x1;
+}
+
+def ADDI: RRI8_Inst<0x02, (outs AR:$t), (ins AR:$s, imm8:$imm8),
+                   "addi\t$t, $s, $imm8",
+                   [(set AR:$t, (add AR:$s, imm8:$imm8))]>
+{
+  let r = 0x0C;
+}
+
+def ADDMI: RRI8_Inst<0x02, (outs AR:$t), (ins AR:$s, imm8_sh8:$imm_sh8),
+                    "addmi\t$t, $s, $imm_sh8",
+                    [(set AR:$t, (add AR:$s, imm8_sh8:$imm_sh8))]>
+{
+  bits<16> imm_sh8;
+
+  let r = 0x0D;
+  let imm8 = imm_sh8{15-8};
+}
+
+def NEG: RRR_Inst<0x00, 0x00, 0x06, (outs AR:$r), (ins AR:$t),
+                 "neg\t$r, $t",
+                 [(set AR:$r, (ineg AR:$t))]>
+{
+  let s = 0x00;
+}
+
+//===----------------------------------------------------------------------===//
+// Move instructions
+//===----------------------------------------------------------------------===//
+def MOVI: RRI8_Inst<0x02, (outs AR:$t), (ins imm12m:$imm),
+                   "movi\t$t, $imm",
+                   [(set AR:$t, imm12m:$imm)]>
+{
+  bits<12> imm;
+
+  let imm8{7-0} = imm{7-0};
+  let s{3-0} = imm{11-8};
+  let r = 0xa;
+}
+
+def MOVEQZ : RRR_Inst<0x00, 0x03, 0x08, (outs AR:$r), (ins AR:$s, AR:$t),
+                     "moveqz\t$r, $s, $t", []>;
+def MOVNEZ : RRR_Inst<0x00, 0x03, 0x09, (outs AR:$r), (ins AR:$s, AR:$t),
+                     "movnez\t$r, $s, $t", []>;
+def MOVLTZ : RRR_Inst<0x00, 0x03, 0x0A, (outs AR:$r), (ins AR:$s, AR:$t),
+                     "movltz\t$r, $s, $t", []>;
+def MOVGEZ : RRR_Inst<0x00, 0x03, 0x0B, (outs AR:$r), (ins AR:$s, AR:$t),
+                     "movgez\t$r, $s, $t", []>;
+
+//===----------------------------------------------------------------------===//
+// Shift instructions
+//===----------------------------------------------------------------------===//
+
+let Uses = [SAR] in
+{
+  def SLL: RRR_Inst<0x00, 0x01, 0x0A, (outs AR:$r), (ins AR:$s),
+                   "sll\t$r, $s",
+                   [(set AR:$r, (Xtensa_shl AR:$s))]>
+  {
+    let t = 0x00;
+  }
+
+  def SRA: RRR_Inst<0x00, 0x01, 0x0B, (outs AR:$r), (ins AR:$t),
+                   "sra\t$r, $t",
+                   [(set AR:$r, (Xtensa_sra AR:$t))]>
+  {
+    let s = 0x00;
+  }
+
+  def SRC: RRR_Inst<0x00, 0x01, 0x08, (outs AR:$r), (ins AR:$s, AR:$t),
+                   "src\t$r, $s, $t",
+                   [(set AR:$r, (Xtensa_src AR:$s, AR:$t))]>;
+
+  def SRL: RRR_Inst<0x00, 0x01, 0x09, (outs AR:$r), (ins AR:$t),
+                   "srl\t$r, $t",
+                   [(set AR:$r, (Xtensa_srl AR:$t))]>
+  {
+    let s = 0x00;
+  }
+}
+
+let Defs = [SAR] in
+{
+  def SSL: RRR_Inst<0x00, 0x00, 0x04, (outs), (ins AR:$s),
+                   "ssl\t$s",
+                   [(Xtensa_ssl AR:$s)]>
+  {
+    let r = 0x01;
+    let t = 0x00;
+  }
+
+  def SSR: RRR_Inst<0x00, 0x00, 0x04, (outs), (ins AR:$s),
+                   "ssr\t$s", 
+                   [(Xtensa_ssr AR:$s)]>
+  {
+    let r = 0x00;
+    let t = 0x00;
+  }
+}
+
+def EXTUI: RRR_Inst<0x00, 0x04, 0x00, (outs AR:$r), (ins AR:$t, uimm5:$imm1, imm1_16:$imm2),
+                   "extui\t$r, $t, $imm1, $imm2",
+                   []>
+{
+  bits<5> imm1;
+  bits<4> imm2;
+
+  let s = imm1{3-0};
+  let Inst{16} = imm1{4};
+  let Inst{23-20} = imm2;
+}
+
+def SRAI: RRR_Inst<0x00, 0x01, 0x02, (outs AR:$r), (ins AR:$t, uimm5:$sa),
+                  "srai\t$r, $t, $sa",
+                  [(set AR:$r, (sra AR:$t, uimm5:$sa))]>
+{
+  bits<5> sa;
+
+  let Inst{20} = sa{4};
+  let s = sa{3-0};
+}
+
+def SRLI: RRR_Inst<0x00, 0x01, 0x04, (outs AR:$r), (ins AR:$t, uimm4:$sa),
+                  "srli\t$r, $t, $sa",
+                  [(set AR:$r, (srl AR:$t, uimm4:$sa))]>
+{
+  bits<4> sa;
+
+  let s = sa;
+}
+
+def SLLI: RRR_Inst<0x00, 0x01, 0x00, (outs AR:$r), (ins AR:$s, shimm1_31:$sa),
+                  "slli\t$r, $s, $sa",
+                  [(set AR:$r, (shl AR:$s, shimm1_31:$sa))]>
+{
+  bits<5> sa;
+
+  let Inst{20} = sa{4};
+  let t = sa{3-0};
+}
+
+def SSA8L : RRR_Inst<0x00, 0x00, 0x04, (outs), (ins AR:$s),
+     "ssa8l\t$s", []>
+{
+  let r = 0x2;
+  let t = 0x0;
+}
+
+def SSAI: RRR_Inst<0x00, 0x00, 0x04, (outs), (ins uimm5:$imm),
+                  "ssai\t$imm", []>
+{
+  bits<5> imm;
+
+  let r = 0x04;
+  let s = imm{3-0};
+  let t{3-1} = 0;
+  let t{0} = imm{4};
+}
+
+// Shift Pseudo instructions:
+// SSL/SSR + Shift combination
+let usesCustomInserter = 1 in
+{
+  def SLL_P: Pseudo<(outs AR:$r), (ins AR:$s, AR:$sa),
+                       "# SLL_P $r, $s, $sa",
+                       [(set AR:$r, (shl AR:$s, AR:$sa))]>;
+ 
+  def SRA_P: Pseudo<(outs AR:$r), (ins AR:$t, AR:$sa),
+                       "# SRA_P $r, $t, $sa",
+                       [(set AR:$r, (sra AR:$t, AR:$sa))]>;
+
+  def SRL_P: Pseudo<(outs AR:$r), (ins AR:$t, AR:$sa),
+                       "# SRL_P $r, $t, $sa",
+                       [(set AR:$r, (srl AR:$t, AR:$sa))]>;
+}
+
+//===----------------------------------------------------------------------===//
+// Load and store instructions
+//===----------------------------------------------------------------------===//
+
+// Load instructions
+let mayLoad = 1, usesCustomInserter = 1 in
+{
+
+  class Load_RRI8<bits<4> oper, string instrAsm, SDPatternOperator opNode,
+        ComplexPattern addrOp, Operand memOp>
+	  : RRI8_Inst<0x02, (outs AR:$t), (ins memOp:$addr),
+                  instrAsm#"\t$t, $addr",
+                 [(set AR:$t, (opNode addrOp:$addr))]>
+  {
+    bits<12> addr;
+
+    let r = oper;
+    let imm8{7-0} = addr{11-4};
+    let s{3-0} = addr{3-0};
+  }
+}
+
+def L8UI: Load_RRI8<0x00, "l8ui", zextloadi8, addr_ish1, mem8>;
+def L16SI: Load_RRI8<0x09, "l16si", sextloadi16, addr_ish2, mem16>;
+def L16UI: Load_RRI8<0x01, "l16ui", zextloadi16, addr_ish2, mem16>;
+def L32I: Load_RRI8<0x02, "l32i", load, addr_ish4, mem32>;
+
+// Store instructions
+let mayStore = 1, usesCustomInserter = 1 in
+{
+  class Store_II8<bits<4> oper, string instrAsm, SDPatternOperator opNode,
+        ComplexPattern addrOp, Operand memOp>
+	  : RRI8_Inst<0x02, (outs), (ins AR:$t, memOp:$addr),
+                  instrAsm#"\t$t, $addr",
+                 [(opNode AR:$t, addrOp:$addr)]>
+  {
+    bits<12> addr;
+
+    let r = oper;
+    let imm8{7-0} = addr{11-4};
+    let s{3-0} = addr{3-0};
+  }
+}
+
+def S8I: Store_II8<0x04, "s8i", truncstorei8, addr_ish1, mem8>;
+def S16I: Store_II8<0x05, "s16i", truncstorei16, addr_ish2, mem16>;
+def S32I: Store_II8<0x06, "s32i", store, addr_ish4, mem32>;
+
+def L32R: RI16_Inst<0x01,
+                   (outs AR:$t), (ins L32Rtarget:$label),
+				   "l32r\t$t, $label", []>
+{
+  bits<16> label;
+  let imm16 = label;
+}
+
+//pcrel addr loading using L32R
+def : Pat<(Xtensa_pcrel_wrapper tconstpool:$in), (L32R tconstpool:$in)>;
+
+// FrameIndexes are legalized when they are operands from load/store
+// instructions. The same not happens for stack address copies, so an
+// add op with mem ComplexPattern is used and the stack address copy
+// can be matched.
+// Setting of attribute mayLoad is trick to process instruction operands
+// in function XtensaRegisterInfo::eliminateFI
+
+let isCodeGenOnly = 1, mayLoad = 1 in
+{
+
+  def LEA_ADD : RRI8_Inst<0x02, (outs AR:$t), (ins mem32:$addr),
+       "addi\t$t, $addr",
+       [(set AR:$t, addr_ish4:$addr)]>
+  {
+   bits<12> addr;
+
+   let r = 0x0C;
+   let imm8{7-0} = addr{11-4};
+   let s{3-0} = addr{3-0};
+  }
+}
+
+// Xtensa missed L8I load operation, use pseudo operation
+let usesCustomInserter = 1 in
+def L8I_P: Pseudo<(outs AR:$t), (ins mem8:$addr),
+               "!L8I_P $t, $addr",
+                [(set AR:$t, (sextloadi8
+				addr_ish1:$addr))]>;
+
+//extending loads
+def : Pat<(i32 (extloadi1  addr_ish1:$addr)), (L8UI addr_ish1:$addr)>;
+def : Pat<(i32 (extloadi8  addr_ish1:$addr)), (L8UI addr_ish1:$addr)>;
+def : Pat<(i32 (extloadi16 addr_ish2:$addr)), (L16UI addr_ish2:$addr)>;
+
+//===----------------------------------------------------------------------===//
+// Conditional branch instructions
+//===----------------------------------------------------------------------===//
+let isBranch = 1, isTerminator = 1 in
+{
+  class Branch_RR<bits<4> oper, string instrAsm, CondCode CC>
+      : RRI8_Inst<0x07, (outs),
+                 (ins AR:$s, AR:$t, brtarget:$target),
+                  instrAsm#"\t$s, $t, $target",
+                 [(brcc CC, AR:$s, AR:$t,  bb:$target)]>
+  {
+    bits<8> target;
+
+    let r = oper;
+    let imm8 = target;
+  }
+
+  class Branch_RI<bits<4> oper, string instrAsm, CondCode CC>
+      : RRI8_Inst<0x06, (outs),
+                 (ins AR:$s, b4const:$imm, brtarget:$target),
+                  instrAsm#"\t$s, $imm, $target",
+                 [(brcc CC, AR:$s, b4const:$imm,  bb:$target)]>
+  {
+    bits<4> imm;
+    bits<8> target;
+
+    let t = oper;
+    let r = imm;
+    let imm8 = target;
+  }
+
+  class Branch_RIU<bits<4> oper, string instrAsm, CondCode CC>
+      : RRI8_Inst<0x06, (outs),
+                 (ins AR:$s, b4constu:$imm, brtarget:$target),
+                  instrAsm#"\t$s, $imm, $target",
+                 [(brcc CC, AR:$s, b4constu:$imm,  bb:$target)]>
+  {
+    bits<4> imm;
+    bits<8> target;
+
+    let t = oper;
+    let r = imm;
+    let imm8 = target;
+  }
+
+  class Branch_RZ<bits<2> n, bits<2> m, string instrAsm, CondCode CC>
+      : BRI12_Inst<0x06, n, m, (outs),
+                  (ins AR:$s, brtarget:$target),
+                   instrAsm#"\t$s, $target",
+                  [(brcc CC, AR:$s, (i32 0),  bb:$target)]>
+  {
+    bits<12> target;
+
+    let imm12 = target;
+  }
+}
+
+def BEQ: Branch_RR<0x01, "beq", SETEQ>;
+def BNE: Branch_RR<0x09, "bne", SETNE>;
+def BGE: Branch_RR<0x0A, "bge", SETGE>;
+def BLT: Branch_RR<0x02, "blt", SETLT>;
+def BGEU: Branch_RR<0x0B, "bgeu", SETUGE>;
+def BLTU: Branch_RR<0x03, "bltu", SETULT>;
+
+def BEQI: Branch_RI<0x02, "beqi", SETEQ>;
+def BNEI: Branch_RI<0x06, "bnei", SETNE>;
+def BGEI: Branch_RI<0x0E, "bgei", SETGE>;
+def BLTI: Branch_RI<0x0A, "blti", SETLT>;
+def BGEUI: Branch_RIU<0x0F, "bgeui", SETUGE>;
+def BLTUI: Branch_RIU<0x0B, "bltui", SETULT>;
+
+def BEQZ: Branch_RZ<0x01, 0x00, "beqz", SETEQ>;
+def BNEZ: Branch_RZ<0x01, 0x01, "bnez", SETNE>;
+def BGEZ: Branch_RZ<0x01, 0x03, "bgez", SETGE>;
+def BLTZ: Branch_RZ<0x01, 0x02, "bltz", SETLT>;
+
+def BALL: RRI8_Inst<0x07, (outs),
+                   (ins AR:$s, AR:$t, brtarget:$target),
+                   "ball\t$s, $t, $target", []>
+{
+  bits<8> target;
+
+  let r = 0x04;
+  let imm8 = target;
+}
+
+def BANY: RRI8_Inst<0x07, (outs),
+                   (ins AR:$s, AR:$t, brtarget:$target),
+                   "bany\t$s, $t, $target", []>
+{
+  bits<8> target;
+
+  let r = 0x08;
+  let imm8 = target;
+}
+
+def BBC: RRI8_Inst<0x07, (outs),
+                  (ins AR:$s, AR:$t, brtarget:$target),
+                  "bbc\t$s, $t, $target", []>
+{
+  bits<8> target;
+
+  let r = 0x05;
+  let imm8 = target;
+}
+
+def BBS: RRI8_Inst<0x07, (outs),
+                  (ins AR:$s, AR:$t, brtarget:$target),
+                  "bbs\t$s, $t, $target", []>
+{
+  bits<8> target;
+
+  let r = 0x0d;
+  let imm8 = target;
+}
+
+def BNALL: RRI8_Inst<0x07, (outs),
+                   (ins AR:$s, AR:$t, brtarget:$target),
+                   "bnall\t$s, $t, $target", []>
+{
+  bits<8> target;
+
+  let r = 0x0c;
+  let imm8 = target;
+}
+
+def BNONE: RRI8_Inst<0x07, (outs),
+                   (ins AR:$s, AR:$t, brtarget:$target),
+                   "bnone\t$s, $t, $target", []>
+{
+  bits<8> target;
+
+  let r = 0x00;
+  let imm8 = target;
+}
+
+def BBCI: RRI8_Inst<0x07, (outs),
+                   (ins AR:$s, uimm5:$imm, brtarget:$target),
+                   "bbci\t$s, $imm, $target", []>
+{
+  bits<8> target;
+  bits<5> imm;
+
+  let r{3-1} = 0x3;
+  let r{0} = imm{4};
+  let t{3-0} = imm{3-0};
+  let imm8 = target;
+}
+
+def BBSI: RRI8_Inst<0x07, (outs),
+                   (ins AR:$s, uimm5:$imm, brtarget:$target),
+                   "bbsi\t$s, $imm, $target", []>
+{
+  bits<8> target;
+  bits<5> imm;
+
+  let r{3-1} = 0x7;
+  let r{0} = imm{4};
+  let t{3-0} = imm{3-0};
+  let imm8 = target;
+}
+
+def : Pat<(brcc SETGT, AR:$s, AR:$t, bb:$target),
+          (BLT AR:$t, AR:$s, bb:$target)>;
+def : Pat<(brcc SETUGT, AR:$s, AR:$t, bb:$target),
+          (BLTU AR:$t, AR:$s, bb:$target)>;
+def : Pat<(brcc SETLE, AR:$s, AR:$t, bb:$target),
+          (BGE AR:$t, AR:$s, bb:$target)>;
+def : Pat<(brcc SETULE, AR:$s, AR:$t, bb:$target),
+          (BGEU AR:$t, AR:$s, bb:$target)>;
+
+def : Pat<(brcond (i32 (seteq AR:$s, AR:$t)), bb:$target),
+          (BEQ AR:$s, AR:$t, bb:$target)>;
+def : Pat<(brcond (i32 (setne AR:$s, AR:$t)), bb:$target),
+          (BNE AR:$s, AR:$t, bb:$target)>;
+def : Pat<(brcond (i32 (setge AR:$s, AR:$t)), bb:$target),
+          (BGE AR:$s, AR:$t, bb:$target)>;
+def : Pat<(brcond (i32 (setle AR:$s, AR:$t)), bb:$target),
+          (BLT AR:$s, AR:$t, bb:$target)>;
+def : Pat<(brcond (i32 (setuge AR:$s, AR:$t)), bb:$target),
+          (BGEU AR:$s, AR:$t, bb:$target)>;
+def : Pat<(brcond (i32 (setult AR:$s, AR:$t)), bb:$target),
+          (BLTU AR:$s, AR:$t, bb:$target)>;
+def : Pat<(brcond (i32 (setgt AR:$s, AR:$t)), bb:$target),
+          (BLT AR:$t, AR:$s, bb:$target)>;
+def : Pat<(brcond (i32 (setugt AR:$s, AR:$t)), bb:$target),
+          (BLTU AR:$t, AR:$s, bb:$target)>;
+def : Pat<(brcond (i32 (setle AR:$s, AR:$t)), bb:$target),
+          (BGE AR:$t, AR:$s, bb:$target)>;
+def : Pat<(brcond (i32 (setule AR:$s, AR:$t)), bb:$target),
+          (BGEU AR:$t, AR:$s, bb:$target)>;
+
+def : Pat<(brcond AR:$s, bb:$target), (BNEZ AR:$s, bb:$target)>;
+
+//===----------------------------------------------------------------------===//
+// Call and jump instructions
+//===----------------------------------------------------------------------===//
+
+let isBranch = 1, isTerminator = 1, isBarrier = 1 in
+{
+  def J: CALL_Inst<0x06, (outs), (ins jumptarget:$offset),
+                  "j\t$offset",
+                  [(br bb:$offset)]>
+  {
+    let n = 0x0;
+  }
+
+  def JX: CALLX_Inst<0x00, 0x00, 0x00, (outs), (ins AR:$s),
+                    "jx\t$s",
+                    [(brind AR:$s)]>
+  {
+    let m = 0x2;
+    let n = 0x2;
+    let r = 0;
+    let isIndirectBranch = 1;
+  }
+}
+
+let isCall = 1, Defs = [A0] in
+{
+  def CALL0: CALL_Inst<0x05, (outs), (ins pcrel32call:$offset),
+                      "call0\t$offset", []>
+  {
+    let n = 0;
+  }
+
+  let isIndirectBranch = 1 in
+  {
+    def CALLX0: CALLX_Inst<0x00, 0x00, 0x00, (outs), (ins AR:$s),
+                          "callx0\t$s", [(Xtensa_call AR:$s)]>
+    {
+      let m = 0x3;
+      let n = 0x0;
+      let r = 0;
+    }
+  }
+}
+
+let isReturn = 1, isTerminator = 1,
+    isBarrier = 1, hasCtrlDep = 1, Uses = [A0] in
+{
+
+  def RET: CALLX_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                     "ret", [(Xtensa_retflag)]>
+  {
+    let m = 0x2;
+    let n = 0x0;
+    let s = 0;
+    let r = 0;
+  }
+}
+
+// Call patterns
+def : Pat<(Xtensa_call (i32 tglobaladdr:$dst)),
+          (CALL0 tglobaladdr:$dst)>;
+def : Pat<(Xtensa_call (i32 texternalsym:$dst)),
+          (CALL0 texternalsym:$dst)>;
+def : Pat<(Xtensa_call AR:$dst),
+          (CALLX0 AR:$dst)>;
+
+let isBranch = 1, isTerminator = 1, isBarrier = 1, isIndirectBranch = 1, Size = 3 in
+{
+  def BR_JT: Pseudo<(outs), (ins AR:$s, i32imm:$jt),
+                     "!br_jt_p, $s, $jt",
+                    [(Xtensa_brjt AR:$s, tjumptable:$jt)]>;
+}
+
+//===----------------------------------------------------------------------===//
+// Mem barrier instructions
+//===----------------------------------------------------------------------===//
+
+def MEMW:  RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                   "memw", []>
+{
+  let r = 0x2;
+  let t = 0x0c;
+  let s = 0x0;
+  let hasSideEffects = 1;
+}
+
+def EXTW : RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+     "extw", []>
+{
+  let r = 0x2;
+  let s = 0x0;
+  let t = 0xd;
+}
+
+def : Pat<(Xtensa_mem_barrier), (MEMW)>;
+
+//===----------------------------------------------------------------------===//
+// Processor control instructions
+//===----------------------------------------------------------------------===//
+
+def DSYNC: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                   "dsync", []>
+{
+  let r = 0x2;
+  let s = 0x0;
+  let t = 0x3;
+}
+
+def ISYNC: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                   "isync", []>
+{
+  let r = 0x2;
+  let s = 0x0;
+  let t = 0x0;
+}
+
+def RSYNC: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                   "rsync", []>
+{
+  let r = 0x2;
+  let s = 0x0;
+  let t = 0x1;
+}
+
+def ESYNC: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                   "esync", []>
+{
+  let r = 0x2;
+  let s = 0x0;
+  let t = 0x2;
+}
+
+def NOP: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                 "nop",
+                 []>
+{
+  let r = 0x02;
+  let s = 0x00;
+  let t = 0x0f;
+}
+
+def WSR: RSR_Inst<0x00, 0x03, 0x01, (outs SR:$sr), (ins AR:$t),
+                 "wsr\t$t, $sr", []>;
+
+def RSR: RSR_Inst<0x00, 0x03, 0x00, (outs AR:$t), (ins SR:$sr),
+                 "rsr\t$t, $sr", []>;
+
+def XSR: RSR_Inst<0x00, 0x01, 0x06, (outs AR:$ard, SR:$srd), (ins AR:$t, SR:$sr),
+                 "xsr\t$t, $sr", []>
+{
+  let Constraints = "$ard = $t, $srd = $sr";
+}
+
+//===----------------------------------------------------------------------===//
+// User Registers read/write instructions
+//===----------------------------------------------------------------------===//
+
+def WUR: RRR_Inst<0x00, 0x03, 0x0F, (outs UR:$ur), (ins AR:$t),
+                 "wur\t$t, $ur", []>
+{
+  bits<8> ur;
+
+  let r = ur{7-4};
+  let s = ur{3-0};
+}
+
+def RUR: RRR_Inst<0x00, 0x03, 0x0E, (outs AR:$r), (ins UR:$ur),
+                 "rur\t$r, $ur", [(set AR:$r, (Xtensa_rur UR:$ur))]>
+{
+  bits<8> ur;
+
+  let s = ur{7-4};
+  let t = ur{3-0};
+}
+
+//===----------------------------------------------------------------------===//
+// External Registers read/write instructions
+//===----------------------------------------------------------------------===//
+
+def RER: RRR_Inst<0x00, 0x00, 0x04, (outs AR:$t), (ins AR:$s),
+                 "rer\t$t, $s", []>
+{
+  let r = 0x6;
+}
+
+def WER: RRR_Inst<0x00, 0x00, 0x04, (outs), (ins AR:$t, AR:$s),
+                 "wer\t$t, $s", []>
+{
+  let r = 0x7;
+  let hasSideEffects = 1;
+}
+
+//===----------------------------------------------------------------------===//
+// Stack allocation
+//===----------------------------------------------------------------------===//
+
+// ADJCALLSTACKDOWN/UP implicitly use/def SP because they may be expanded into
+// a stack adjustment and the codegen must know that they may modify the stack
+// pointer before prolog-epilog rewriting occurs.
+let Defs = [SP], Uses = [SP] in
+{
+  def ADJCALLSTACKDOWN: Pseudo<(outs), (ins i32imm:$amt1, i32imm:$amt2),
+                              "#ADJCALLSTACKDOWN",
+                              [(Xtensa_callseq_start timm:$amt1, timm:$amt2)]>;
+  def ADJCALLSTACKUP  : Pseudo<(outs), (ins i32imm:$amt1, i32imm:$amt2),
+                              "#ADJCALLSTACKUP",
+                              [(Xtensa_callseq_end timm:$amt1, timm:$amt2)]>;
+}
+
+//===----------------------------------------------------------------------===//
+// Generic select instruction
+//===----------------------------------------------------------------------===//
+let usesCustomInserter = 1 in
+{
+  def SELECT: Pseudo<(outs AR:$dst), (ins AR:$lhs, AR:$rhs, AR:$t, AR:$f, i32imm:$cond),
+                    "!select $dst, $lhs, $rhs, $t, $f, $cond",
+                    [(set AR:$dst, (Xtensa_select_cc AR:$lhs, AR:$rhs, AR:$t, AR:$f, imm:$cond))]>;
+}
+
+//===----------------------------------------------------------------------===//
+// Code Density instructions
+//===----------------------------------------------------------------------===//
+
+class ArithLogic_RRRN<bits<4> oper0, string instrAsm, 
+      SDPatternOperator opNode, bit isComm = 0>
+  : RRRN_Inst<oper0, (outs AR:$r), (ins AR:$s, AR:$t),
+              instrAsm#"\t$r, $s, $t",
+             [(set AR:$r, (opNode AR:$s, AR:$t))]>, Requires<[HasDensity]> 
+{
+  let isCommutable = isComm;
+  let isReMaterializable = 0;
+}
+
+def ADD_N: ArithLogic_RRRN<0x0a, "add.n", add, 1>;
+
+def ADDI_N: RRRN_Inst<0x0B, (outs AR:$r), (ins AR:$s, imm1n_15:$imm),
+                     "addi.n\t$r, $s, $imm",
+                     [(set AR:$r, (add AR:$s, imm1n_15:$imm))]>, Requires<[HasDensity]>
+{
+  bits<4> imm;
+
+  let t = imm;
+}
+
+def MOV_N: RRRN_Inst<0x0D, (outs AR:$t), (ins AR:$s),
+                    "mov.n\t$t, $s", []>, Requires<[HasDensity]>
+{
+  let r = 0;
+}
+
+def : InstAlias<"mov\t $t, $s", (OR AR:$t, AR:$s, AR:$s)>;
+
+def MOVI_N: RI7_Inst<0xc, 0x0, (outs AR:$s), (ins imm32n_95:$imm7),
+                    "movi.n\t$s, $imm7",
+                    [(set AR:$s, imm32n_95:$imm7)]>, Requires<[HasDensity]>;
+
+// Load instruction
+let mayLoad = 1, usesCustomInserter = 1 in
+{
+  def L32I_N: RRRN_Inst<0x8, (outs AR:$t), (ins mem32n:$addr), 
+                       "l32i.n\t$t, $addr", []>, Requires<[HasDensity]>
+  {
+    bits<8> addr;
+
+    let r{3-0} = addr{7-4};
+    let s{3-0} = addr{3-0};
+  }
+}
+
+// Store instruction
+let mayStore = 1, usesCustomInserter = 1 in
+{
+  def S32I_N: RRRN_Inst<0x9, (outs), (ins  AR:$t, mem32n:$addr),
+                       "s32i.n\t$t, $addr", []>, Requires<[HasDensity]>
+  {
+    bits<8> addr;
+
+    let r{3-0} = addr{7-4};
+    let s{3-0} = addr{3-0};
+  }
+}
+
+//Return instruction
+let isReturn = 1, isTerminator = 1,
+    isBarrier = 1, hasCtrlDep = 1, Uses = [A0] in
+{
+  def RET_N: RRRN_Inst<0x0D, (outs), (ins),
+                "ret.n", [(Xtensa_retflag)]>, Requires<[HasDensity]>
+  {
+    let r = 0x0F;
+    let s = 0;
+    let t = 0;
+  }
+}
+
+//===----------------------------------------------------------------------===//
+// Windowed instructions
+//===----------------------------------------------------------------------===//
+
+def ENTRY: BRI12_Inst<0x06, 0x3, 0x0, (outs), (ins AR:$s, entry_imm12:$imm), 
+                     "entry\t$s, $imm", []>, Requires<[HasWindowed]>
+{
+  bits<15> imm;
+
+  let imm12{11-0} = imm{14-3};
+  let Defs = [SP];
+}
+
+//Call instructions
+let isCall = 1, Defs = [A0] in 
+{
+  def CALL4: CALL_Inst<0x05, (outs), (ins pcrel32call:$offset),
+                      "call4\t$offset", []>, Requires<[HasWindowed]>
+  {
+    let n = 1;
+  }
+
+  def CALL8: CALL_Inst<0x05, (outs), (ins pcrel32call:$offset),
+                      "call8\t$offset", []>, Requires<[HasWindowed]>
+  {
+    let n = 2;
+  }
+
+  def CALL12: CALL_Inst<0x05, (outs), (ins pcrel32call:$offset),
+                       "call12\t$offset", []>, Requires<[HasWindowed]>
+  {
+    let n = 3;
+  }
+
+  let isIndirectBranch = 1 in
+  {
+    def CALLX4: CALLX_Inst<0x00, 0x00, 0x00, (outs), (ins AR:$s), 
+                          "callx4\t$s", []>, Requires<[HasWindowed]>
+    {
+      let m = 0x3;
+      let n = 0x1;
+      let r = 0;
+    }
+
+    def CALLX8: CALLX_Inst<0x00, 0x00, 0x00, (outs), (ins AR:$s), 
+                          "callx8\t$s", []>, Requires<[HasWindowed]>
+    {
+      let m = 0x3;
+      let n = 0x2;
+      let r = 0;
+    }
+
+    def CALLX12: CALLX_Inst<0x00, 0x00, 0x00, (outs), (ins AR:$s), 
+                           "callx12\t$s", []>, Requires<[HasWindowed]>
+    {
+      let m = 0x3;
+      let n = 0x3;
+      let r = 0;
+    }
+  }
+}
+
+//Windowed call patterns
+def : Pat<(Xtensa_callw (i32 tglobaladdr:$dst)),
+          (CALL8 tglobaladdr:$dst)>;
+def : Pat<(Xtensa_callw (i32 texternalsym:$dst)),
+          (CALL8 texternalsym:$dst)>;
+def : Pat<(Xtensa_callw AR:$dst),
+          (CALLX8 AR:$dst)>;
+
+def MOVSP: RRR_Inst<0x00, 0x00, 0x00, (outs AR:$t), (ins AR:$s),
+                   "movsp\t$t, $s",
+                   [(set AR:$t, (Xtensa_movsp AR:$s))]>, Requires<[HasWindowed]>
+{
+  let r = 0x01;
+}
+
+//Return instructions
+let isReturn = 1, isTerminator = 1,
+    isBarrier = 1, hasCtrlDep = 1, Uses = [A0] in
+{
+  def RETW_N: RRRN_Inst<0x0D, (outs), (ins),
+                "retw.n", [(Xtensa_retWflag)]>, Requires<[HasWindowed, HasDensity]>
+  {
+    let r = 0x0F;
+    let s = 0;
+    let t = 1;
+  }
+
+  def RETW: CALLX_Inst<0x00, 0x00, 0x00, (outs), (ins), 
+            "retw", [(Xtensa_retWflag)]>, Requires<[HasWindowed]>
+  {
+    let m = 0x2;
+    let n = 0x1;
+    let s = 0;
+    let r = 0;
+  }
+}
+
+//Store 32-bit for Window Exceptions
+def S32E: RRI4_Inst<0x00, 0x09, (outs), (ins AR:$t, AR:$s, imm64n_4n:$imm),
+					"s32e\t$t, $s, $imm", []>, Requires<[HasWindowed]>
+{
+  bits<6> imm;
+
+  let r = imm{5-2};
+  let imm4 = 0x4;
+  let mayStore = 1;
+}
+
+def L32E: RRI4_Inst<0x00, 0x09, (outs), (ins AR:$t, AR:$s, imm64n_4n:$imm),
+					"l32e\t$t, $s, $imm", []>, Requires<[HasWindowed]>
+{
+  bits<6> imm;
+
+  let r = imm{5-2};
+  let imm4 = 0x0;
+  let mayLoad = 1;
+}
+
+//Return from window
+def RFWU: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                  "rfwu", []>, Requires<[HasWindowed]>
+{
+  bits<4> imm;
+
+  let r = 0x3;
+  let s = 0x5;
+  let t = 0x0;
+}
+
+def RFWO: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                  "rfwo", []>, Requires<[HasWindowed]>
+{
+  bits<4> imm;
+
+  let r = 0x3;
+  let s = 0x4;
+  let t = 0x0;
+}
+
+//Rotate window
+def ROTW: RRR_Inst<0x00, 0x00, 0x04, (outs), (ins imm8n_7:$imm),
+                  "rotw\t$imm", []>, Requires<[HasWindowed]>
+{
+  bits<4> imm;
+
+  let r = 0x8;
+  let s = 0x0;
+  let t = imm{3-0};
+}
+
+//===----------------------------------------------------------------------===//
+// Boolean Instructions
+//===----------------------------------------------------------------------===//
+
+def ALL4: RRR_Inst<0x00, 0x00, 0x00, (outs BR:$t), (ins BR:$s),
+                  "all4\t$t, $s", []>, Requires<[HasBoolean]>
+{
+  let r = 0x9;
+}
+
+def ALL8: RRR_Inst<0x00, 0x00, 0x00, (outs BR:$t), (ins BR:$s),
+                  "all8\t$t, $s", []>, Requires<[HasBoolean]>
+{
+  let r = 0xB;
+}
+
+def ANDB: RRR_Inst<0x00, 0x02, 0x00, (outs BR:$r), (ins BR:$s, BR:$t),
+                  "andb\t$r, $s, $t", []>, Requires<[HasBoolean]>;
+def ANDBC: RRR_Inst<0x00, 0x02, 0x01, (outs BR:$r), (ins BR:$s, BR:$t),
+                   "andbc\t$r, $s, $t", []>, Requires<[HasBoolean]>;
+
+def ANY4: RRR_Inst<0x00, 0x00, 0x00, (outs BR:$t), (ins BR:$s),
+                  "any4\t$t, $s", []>, Requires<[HasBoolean]>
+{
+  let r = 0x8;
+}
+
+def ANY8: RRR_Inst<0x00, 0x00, 0x00, (outs BR:$t), (ins BR:$s),
+                  "any8\t$t, $s", []>, Requires<[HasBoolean]>
+{
+  let r = 0xA;
+}
+
+let isBranch = 1, isTerminator = 1, Predicates = [HasBoolean] in 
+{
+  def BT: RRI8_Inst<0x06, (outs), (ins BR:$b, brtarget:$target), 
+                   "bt\t$b, $target", []>
+  {
+    bits<8> target;
+    bits<4> b;
+
+    let r = 0x1;
+    let s = b;
+    let t = 0x7; 
+    let imm8 = target;
+  }
+
+  def BF: RRI8_Inst<0x06, (outs), (ins BR:$b, brtarget:$target), 
+                   "bf\t$b, $target", []>
+  {
+    bits<8> target;
+    bits<4> b;
+
+    let r = 0x0;
+    let s = b;
+    let t = 0x7; 
+    let imm8 = target;
+  }
+}
+
+def MOVF: RRR_Inst<0x00, 0x03, 0x0C, (outs AR:$r), (ins AR:$s, BR:$t),
+                  "movf\t$r, $s, $t", []>, Requires<[HasBoolean]>;
+def MOVT: RRR_Inst<0x00, 0x03, 0x0D, (outs AR:$r), (ins AR:$s, BR:$t),
+                  "movt\t$r, $s, $t", []>, Requires<[HasBoolean]>;
+
+def ORB: RRR_Inst<0x00, 0x02, 0x02, (outs BR:$r), (ins BR:$s, BR:$t),
+                  "orb\t$r, $s, $t", []>, Requires<[HasBoolean]>;
+def ORBC: RRR_Inst<0x00, 0x02, 0x03, (outs BR:$r), (ins BR:$s, BR:$t),
+                  "orbc\t$r, $s, $t", []>, Requires<[HasBoolean]>;
+def XORB: RRR_Inst<0x00, 0x02, 0x04, (outs BR:$r), (ins BR:$s, BR:$t),
+                  "xorb\t$r, $s, $t", []>, Requires<[HasBoolean]>;
+
+def : Pat<(Xtensa_brcc_t BR:$b, bb:$target), (BT BR:$b, bb:$target)>;
+def : Pat<(Xtensa_brcc_f BR:$b, bb:$target), (BF BR:$b, bb:$target)>;
+
+//===----------------------------------------------------------------------===//
+// Floating-Point Instructions
+//===----------------------------------------------------------------------===//
+
+class FPArith_RRR<bits<4> oper2, bits<4> oper1, string instrAsm,
+                 SDPatternOperator opNode, bit isComm = 0>
+  : RRR_Inst<0x00, oper1, oper2, (outs FPR:$r), (ins FPR:$s, FPR:$t),
+             instrAsm#"\t$r, $s, $t",
+            [(set FPR:$r, (opNode FPR:$s, FPR:$t))]>
+{
+  let isCommutable = isComm;
+  let isReMaterializable = 0;
+  let Predicates = [HasSingleFloat];
+}
+
+def ADD_S: FPArith_RRR<0x00, 0x0A, "add.s", fadd, 1>;
+def SUB_S: FPArith_RRR<0x01, 0x0A, "sub.s", fsub>;
+def MUL_S: FPArith_RRR<0x02, 0x0A, "mul.s", fmul, 1>;
+
+def ABS_S: RRR_Inst<0x00, 0x0A, 0x0F, (outs FPR:$r), (ins FPR:$s),
+                   "abs.s\t$r, $s",
+                   [(set FPR:$r, (fabs FPR:$s))]>
+{
+  let t = 0x01;
+}
+
+def NEG_S: RRR_Inst<0x00, 0x0A, 0x0F, (outs FPR:$r), (ins FPR:$s),
+                   "neg.s\t$r, $s",
+                   [(set FPR:$r, (fneg FPR:$s))]>
+{
+  let t = 0x06;
+}
+
+def TRUNC_S: RRR_Inst<0x00, 0x0A, 0x09, (outs AR:$r), (ins FPR:$s),
+                     "trunc.s\t$r, $s, 0",
+                     [(set AR:$r, (fp_to_sint FPR:$s))]> 
+{
+  let t = 0x00;
+}
+
+def UTRUNC_S: RRR_Inst<0x00, 0x0A, 0x0e, (outs AR:$r), (ins FPR:$s),
+                      "utrunc.s\t$r, $s, 0",
+                      [(set AR:$r, (fp_to_uint FPR:$s))]>
+{
+  let t = 0x00;
+}
+
+def FLOAT_S: RRR_Inst<0x00, 0x0A, 0x0c, (outs FPR:$r), (ins AR:$s),
+                     "float.s\t$r, $s, 0",
+                     [(set FPR:$r, (sint_to_fp AR:$s))]>
+{
+  let t = 0x00;
+}
+
+def UFLOAT_S: RRR_Inst<0x00, 0x0A, 0x0D, (outs FPR:$r), (ins AR:$s),
+                      "ufloat.s\t$r, $s, 0",
+                      [(set FPR:$r, (uint_to_fp AR:$s))]>
+{
+  let t = 0x00;
+}
+
+def RFR: RRR_Inst<0x00, 0x0A, 0x0f, (outs AR:$r), (ins FPR:$s),
+                 "rfr\t$r, $s",
+                 [(set AR:$r, (bitconvert FPR:$s))]>
+{
+  let t = 0x04;
+}
+
+def WFR: RRR_Inst<0x00, 0x0A, 0x0f, (outs FPR:$r), (ins AR:$s),
+                 "wfr\t$r, $s",
+                 [(set FPR:$r, (bitconvert AR:$s))]>
+{
+  let t = 0x05;
+}
+
+// FP load instructions
+let mayLoad = 1, usesCustomInserter = 1, Predicates = [HasSingleFloat] in
+{
+  class LoadF_RRI8<bits<4> oper, string instrAsm, SDPatternOperator opNode,
+                  ComplexPattern addrOp,Operand memOp>: RRI8_Inst<0x03, (outs FPR:$t), (ins memOp:$addr),
+                   instrAsm#"\t$t, $addr",
+                  [(set FPR:$t, (opNode addrOp:$addr))]>
+  {
+    bits<12> addr;
+
+    let r = oper;
+    let imm8{7-0} = addr{11-4};
+    let s{3-0} = addr{3-0};
+  }
+}
+
+def L32F: LoadF_RRI8<0x00, "lsi", load, addr_ish4, mem32>, Requires<[]>;
+
+// FP store instructions
+let mayStore = 1, usesCustomInserter = 1, Predicates = [HasSingleFloat] in
+{
+  class StoreF_RRI8<bits<4> oper, string instrAsm, SDPatternOperator opNode,
+                   ComplexPattern addrOp, Operand memOp>: RRI8_Inst<0x03, (outs), (ins FPR:$t, memOp:$addr),
+                    instrAsm#"\t$t, $addr",
+                   [(opNode FPR:$t, addrOp:$addr)]>
+  {
+    bits<12> addr;
+
+    let r = oper;
+    let imm8{7-0} = addr{11-4};
+    let s{3-0} = addr{3-0};
+  }
+}
+
+def S32F: StoreF_RRI8<0x04, "ssi", store, addr_ish4, mem32>;
+
+// FP compare instructions
+let isCompare = 1, Predicates = [HasSingleFloat] in 
+{
+  class FCompare <bits<4> oper2, bits<4> oper1, string instrAsm,
+                 SDPatternOperator opNode, bit isComm = 0>
+    : RRR_Inst<0x00, oper1, oper2, (outs BR:$b), (ins FPR:$s, FPR:$t),
+               instrAsm#"\t$b, $s, $t",
+              [(set BR:$b, (opNode FPR:$s, FPR:$t))]>
+  {
+    let isCommutable = isComm;
+    let isReMaterializable = 0;
+	let Predicates = [HasSingleFloat];
+  }
+}
+
+def OEQ_S:  FCompare<0x02, 0x0b, "oeq.s", Xtensa_cmpoeq, 1>;
+def OLT_S:  FCompare<0x04, 0x0b, "olt.s", Xtensa_cmpolt, 1>;
+def OLE_S:  FCompare<0x06, 0x0b, "ole.s", Xtensa_cmpole, 1>;
+
+def UEQ_S:  FCompare<0x03, 0x0b, "ueq.s", Xtensa_cmpueq, 1>;
+def ULT_S:  FCompare<0x05, 0x0b, "ult.s", Xtensa_cmpult, 1>;
+def ULE_S:  FCompare<0x07, 0x0b, "ule.s", Xtensa_cmpule, 1>;
+def UN_S:   FCompare<0x01, 0x0b, "un.s",  Xtensa_cmpuo, 1>;
+
+//FP complex operations
+def MADD_S: RRR_Inst<0x00, 0x0A, 0x04, (outs FPR:$r), (ins FPR:$a, FPR:$s, FPR:$t),
+                    "madd.s\t$r, $s, $t",
+                    [(set FPR:$r, (Xtensa_madd FPR:$a, FPR:$s, FPR:$t))]>, Requires<[HasSingleFloat]>
+{
+  let isCommutable = 0;
+  let isReMaterializable = 0;
+  let Constraints = "$r = $a";
+}
+
+def MSUB_S: RRR_Inst<0x00, 0x0A, 0x05, (outs FPR:$r), (ins FPR:$a, FPR:$s, FPR:$t),
+                    "msub.s\t$r, $s, $t",
+                    [(set FPR:$r, (Xtensa_msub FPR:$a, FPR:$s, FPR:$t))]>, Requires<[HasSingleFloat]>
+{
+  let isCommutable = 0;
+  let isReMaterializable = 0;
+  let Constraints = "$r = $a";
+}
+
+//FP move operations
+def MOV_S: RRR_Inst<0x00, 0x0A, 0x0f, (outs FPR:$r), (ins FPR:$s),
+                   "mov.s\t$r, $s",
+                   [(set FPR:$r, (Xtensa_movs FPR:$s))]>, Requires<[HasSingleFloat]>
+{
+  let t = 0x00;
+}
+
+def CONST_S: RRR_Inst<0x00, 0x0a, 0x0f, (outs FPR:$r), (ins uimm4:$imm),
+                      "const.s\t$r, $imm", []>, Requires<[HasSingleFloat]>
+{
+  bits<4> imm;
+
+  let t = 0x03;
+  let s = imm{3-0};
+}
+
+def DIV0_S: RRR_Inst<0x00, 0x0A, 0x0F, (outs FPR:$r), (ins FPR:$s),
+					"div0.s\t$r, $s", []>, Requires<[HasSingleFloat]>
+{
+  let t = 0x7;
+}
+
+def MADDN_S: RRR_Inst<0x00, 0x0A, 0x06, (outs FPR:$r), (ins FPR:$s, FPR:$t),
+					 "maddn.s\t$r, $s, $t", []>, Requires<[HasSingleFloat]>
+{
+  let isCommutable = 0;
+}
+
+def MKDADJ_S: RRR_Inst<0x00, 0x0A, 0x0F, (outs FPR:$r), (ins FPR:$s),
+                      "mkdadj.s\t$r, $s", []>, Requires<[HasSingleFloat]>
+{
+  let t = 0x0D;
+}
+
+def MKSADJ_S: RRR_Inst<0x00, 0x0A, 0x0F, (outs FPR:$r), (ins FPR:$s),
+                      "mksadj.s\t$r, $s", []>, Requires<[HasSingleFloat]>
+{
+  let t = 0x0C;
+}
+
+def ADDEXP_S: RRR_Inst<0x00, 0x0A, 0x0F, (outs FPR:$r), (ins FPR:$s),
+                      "addexp.s\t$r, $s", []>, Requires<[HasSingleFloat]>
+{
+  let t = 0x0E;
+}
+
+def ADDEXPM_S: RRR_Inst<0x00, 0x0A, 0x0F, (outs FPR:$r), (ins FPR:$s),
+                       "addexpm.s\t$r, $s", []>, Requires<[HasSingleFloat]> 
+{
+  let t = 0x0F;
+}
+
+def DIVN_S: RRR_Inst<0x00, 0x0A, 0x07, (outs FPR:$r), (ins FPR:$s, FPR:$t),
+                     "divn.s\t$r, $s, $t", []>, Requires<[HasSingleFloat]>;
+
+def NEXP01_S: RRR_Inst<0x00, 0x0A, 0x0F, (outs FPR:$r), (ins FPR:$s),
+                      "nexp01.s\t$r, $s", []>, Requires<[HasSingleFloat]>
+{
+  let t = 0x0B;
+}
+
+def SQRT0_S: RRR_Inst<0x00, 0x0A, 0x0F, (outs FPR:$r), (ins FPR:$s),
+                      "sqrt0.s\t$r, $s", []>, Requires<[HasSingleFloat]>
+{
+  let t = 0x09;
+}
+
+// FP select operations
+let usesCustomInserter = 1 in
+{
+  def SELECT_CC_FP_INT: Pseudo<(outs AR:$dst), (ins FPR:$lhs, FPR:$rhs, AR:$t, AR:$f, i32imm:$cond),
+                              "!select_cc_fp_int $dst, $lhs, $rhs, $t, $f, $cond",
+                              [(set AR:$dst, (Xtensa_select_cc_fp FPR:$lhs, FPR:$rhs, AR:$t, AR:$f, imm:$cond))]>;
+  def SELECT_CC_INT_FP: Pseudo<(outs FPR:$dst), (ins AR:$lhs, AR:$rhs, FPR:$t, FPR:$f, i32imm:$cond),
+                              "!select_cc_int_fp $dst, $lhs, $rhs, $t, $f, $cond",
+                              [(set FPR:$dst, (Xtensa_select_cc_fp AR:$lhs, AR:$rhs, FPR:$t, FPR:$f, imm:$cond))]>;
+  def SELECT_CC_FP_FP: Pseudo<(outs FPR:$dst), (ins FPR:$lhs, FPR:$rhs, FPR:$t, FPR:$f, i32imm:$cond),
+                             "!select_cc_fp_fp $dst, $lhs, $rhs, $t, $f, $cond",
+                             [(set FPR:$dst, (Xtensa_select_cc_fp FPR:$lhs, FPR:$rhs, FPR:$t, FPR:$f, imm:$cond))]>;
+}
+
+//===----------------------------------------------------------------------===//
+// Loop Instructions
+//===----------------------------------------------------------------------===//
+
+def LOOP: RRI8_Inst<0x06, (outs), (ins AR:$s, mem8:$uimm8),
+                   "loop\t$$s, $uimm8", []>, Requires<[HasLoop]>
+{
+  bits<8> uimm8;
+
+  let r = 0x08;
+  let t = 0x07;
+  let imm8 = uimm8;
+}
+
+def LOOPGTZ: RRI8_Inst<0x06, (outs), (ins AR:$s, mem8:$uimm8),
+                      "loopgtz\t$$s, $uimm8", []>, Requires<[HasLoop]>
+{
+  bits<8> uimm8;
+
+  let r = 0x0A;
+  let t = 0x07;
+  let imm8 = uimm8;
+}
+
+def LOOPNEZ: RRI8_Inst<0x06, (outs), (ins AR:$s, mem8:$uimm8),
+                      "loopnez\t$$s, $uimm8", []>, Requires<[HasLoop]>
+{
+  bits<8> uimm8;
+
+  let r = 0x09;
+  let t = 0x07;
+  let imm8 = uimm8;
+}
+
+//===----------------------------------------------------------------------===//
+// SEXT Instructions
+//===----------------------------------------------------------------------===//
+
+def SEXT: RRR_Inst<0x00, 0x03, 0x02, (outs AR:$r), (ins AR:$s, seimm7_22:$imm),
+                  "sext\t$r, $s, $imm", []>, Requires<[HasSEXT]>
+{
+  bits<4> imm;
+
+  let t = imm;
+}
+
+//===----------------------------------------------------------------------===//
+// NSA Instructions
+//===----------------------------------------------------------------------===//
+
+def NSA : RRR_Inst<0x00, 0x00, 0x04, (outs AR:$t), (ins AR:$s),
+                  "nsa\t$t, $s", []>, Requires<[HasNSA]>
+{
+  let r = 0xE;
+}
+
+def NSAU : RRR_Inst<0x00, 0x00, 0x04, (outs AR:$t), (ins AR:$s),
+                   "nsau\t$t, $s", []>, Requires<[HasNSA]>
+{
+  let r = 0xF;
+}
+
+//===----------------------------------------------------------------------===//
+// Mul32 Instructions
+//===----------------------------------------------------------------------===//
+
+def MULL: ArithLogic_RRR<0x08, 0x02, "mull", mul, 1>, Requires<[HasMul32]>;
+def MULUH: ArithLogic_RRR<0x0A, 0x02, "muluh", mulhu, 1>, Requires<[HasMul32High]>;
+def MULSH: ArithLogic_RRR<0x0B, 0x02, "mulsh", mulhs, 1>, Requires<[HasMul32High]>;
+
+//===----------------------------------------------------------------------===//
+// Div32 Instructions
+//===----------------------------------------------------------------------===//
+
+def QUOS: ArithLogic_RRR<0x0D, 0x02, "quos", sdiv>, Requires<[HasDiv32]>;
+def QUOU: ArithLogic_RRR<0x0C, 0x02, "quou", udiv>, Requires<[HasDiv32]>;
+def REMS: ArithLogic_RRR<0x0F, 0x02, "rems", srem>, Requires<[HasDiv32]>;
+def REMU: ArithLogic_RRR<0x0E, 0x02, "remu", urem>, Requires<[HasDiv32]>;
+
+//===----------------------------------------------------------------------===//
+// S32C1I
+//===----------------------------------------------------------------------===//
+
+let mayStore = 1, mayLoad = 1, Predicates = [HasS32C1I] in
+{
+  def S32C1I: RRI8_Inst<0x02, (outs AR:$a), (ins AR:$t, mem32:$addr),
+                       "s32c1i\t$t, $addr", []>
+  {
+    bits<12> addr;
+
+    let r = 0x0e;
+    let Uses = [SCOMPARE1];
+    let Constraints = "$a = $t";
+    let imm8{7-0} = addr{11-4};
+    let s{3-0} = addr{3-0};
+  }
+}
+
+//===----------------------------------------------------------------------===//
+// Debug instructions
+//===----------------------------------------------------------------------===//
+
+let isBarrier = 1, isTerminator = 1 in
+{
+  def BREAK: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins uimm4:$s, uimm4:$t),
+                     "break\t$s, $t", []>, Requires<[HasDebug]>
+  {
+    let r = 0x04;
+  }
+
+  def BREAK_N: RRRN_Inst<0x0C, (outs), (ins uimm4:$imm),
+                       "break.n\t$imm", []>, Requires<[HasDensity, HasDebug]>
+  {
+    bits<4> imm;
+
+    let r = 0xf;
+	let s = imm;
+    let t = 0x2;
+  }
+}
+
+def: Pat<(trap), (BREAK (i32 1), (i32 15))>;
+
+//===----------------------------------------------------------------------===//
+// Exception feature instructions
+//===----------------------------------------------------------------------===//
+
+def EXCW: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                 "excw", []>, Requires<[HasException]>
+{
+  let r = 0x2;
+  let s = 0x0;
+  let t = 0x8;
+}
+
+def RFDE: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                  "rfde", []>, Requires<[HasException]>
+{
+  let r = 0x3;
+  let s = 0x2;
+  let t = 0x0;
+}
+
+
+def RFE: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                 "rfe", []>, Requires<[HasException]>
+{
+  let r = 0x3;
+  let s = 0x0;
+  let t = 0x0;
+}
+
+def SYSCALL: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins),
+                     "syscall", []>, Requires<[HasException]>
+{
+  let r = 0x5;
+  let s = 0x0;
+  let t = 0x0;
+}
+
+//===----------------------------------------------------------------------===//
+// Interrupt feature instructions
+//===----------------------------------------------------------------------===//
+
+def RSIL: RRR_Inst<0x00, 0x00, 0x00, (outs AR:$t), (ins uimm4:$imm),
+					"rsil\t$t, $imm", []>, Requires<[HasInterrupt]>
+{
+  bits<4> imm;
+
+  let r = 0x6;
+  let s = imm{3-0};
+}
+
+def WAITI: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins uimm4:$imm),
+					"waiti\t$imm", []>, Requires<[HasInterrupt]>
+{
+  bits<4> imm;
+
+  let r = 0x7;
+  let s = imm{3-0};
+  let t = 0;
+}
+
+def RFI: RRR_Inst<0x00, 0x00, 0x00, (outs), (ins uimm4:$imm),
+                 "rfi\t$imm", []>, Requires<[HasInterrupt]>
+{
+  bits<4> imm;
+
+  let r = 0x3;
+  let s = imm{3-0};
+  let t = 0x1;
+}
+
+//===----------------------------------------------------------------------===//
+// Region Protection feature instructions
+//===----------------------------------------------------------------------===//
+
+def WDTLB: RRR_Inst<0x00, 0x00, 0x05, (outs AR:$t), (ins AR:$s),
+					"wdtlb\t$t, $s", []>, Requires<[HasRegionProtection]>
+{
+  let r = 0xE;
+}
+
+def WITLB: RRR_Inst<0x00, 0x00, 0x05, (outs AR:$t), (ins AR:$s),
+					"witlb\t$t, $s", []>, Requires<[HasRegionProtection]>
+{
+  let r = 0x6;
+}
+
+//===----------------------------------------------------------------------===//
+// Atomic patterns
+//===----------------------------------------------------------------------===//
+
+def : Pat<(i32 (atomic_load_8  addr_ish1:$addr)), (L8UI addr_ish1:$addr)>;
+def : Pat<(i32 (atomic_load_16 addr_ish2:$addr)), (L16UI addr_ish2:$addr)>;
+def : Pat<(i32 (atomic_load_32 addr_ish4:$addr)), (L32I addr_ish4:$addr)>;
+
+def : Pat<(atomic_store_8  addr_ish1:$addr, AR:$t), (S8I AR:$t, addr_ish1:$addr)>;
+def : Pat<(atomic_store_16 addr_ish2:$addr, AR:$t), (S16I AR:$t, addr_ish2:$addr)>;
+def : Pat<(atomic_store_32 addr_ish4:$addr, AR:$t), (S32I AR:$t, addr_ish4:$addr)>;
+
+let usesCustomInserter = 1, Predicates = [HasS32C1I] in
+{
+	def ATOMIC_CMP_SWAP_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$cmp, AR:$swap),
+                                   "!atomic_cmp_swap_8_p, $dst, $ptr, $cmp, $swap",
+                                   [(set AR:$dst, (atomic_cmp_swap_8 AR:$ptr, AR:$cmp, AR:$swap))]>;
+	def ATOMIC_CMP_SWAP_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$cmp, AR:$swap),
+                                   "!atomic_cmp_swap_16_p, $dst, $ptr, $cmp, $swap",
+                                   [(set AR:$dst, (atomic_cmp_swap_16 AR:$ptr, AR:$cmp, AR:$swap))]>;
+	def ATOMIC_CMP_SWAP_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$cmp, AR:$swap),
+                                   "!atomic_cmp_swap_32_p, $dst, $ptr, $cmp, $swap",
+                                   [(set AR:$dst, (atomic_cmp_swap_32 AR:$ptr, AR:$cmp, AR:$swap))]>;
+
+	def ATOMIC_SWAP_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$swap),
+                               "!atomic_swap_8_p, $dst, $ptr, $swap",
+                               [(set AR:$dst, (atomic_swap_8 AR:$ptr, AR:$swap))]>;
+	def ATOMIC_SWAP_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$swap),
+                                "!atomic_swap_16_p, $dst, $ptr, $swap",
+                                [(set AR:$dst, (atomic_swap_16 AR:$ptr, AR:$swap))]>;
+	def ATOMIC_SWAP_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$swap),
+                                "!atomic_swap_32_p, $dst, $ptr, $swap",
+                                [(set AR:$dst, (atomic_swap_32 AR:$ptr, AR:$swap))]>;
+
+	def ATOMIC_LOAD_ADD_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_add_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_add_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_ADD_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                    "!atomic_load_add_16_p, $dst, $ptr, $arg",
+                                    [(set AR:$dst, (atomic_load_add_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_ADD_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                    "!atomic_load_add_32_p, $dst, $ptr, $arg",
+                                    [(set AR:$dst, (atomic_load_add_32 AR:$ptr, AR:$arg))]>;
+
+	def ATOMIC_LOAD_SUB_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_sub_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_sub_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_SUB_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_sub_16_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_sub_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_SUB_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_sub_32_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_sub_32 AR:$ptr, AR:$arg))]>;
+
+	def ATOMIC_LOAD_AND_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_and_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_and_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_AND_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_and_16_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_and_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_AND_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_and_32_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_and_32 AR:$ptr, AR:$arg))]>;
+
+	def ATOMIC_LOAD_OR_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_or_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_or_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_OR_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_or_16_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_or_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_OR_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_or_32_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_or_32 AR:$ptr, AR:$arg))]>;
+
+	def ATOMIC_LOAD_XOR_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_xor_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_xor_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_XOR_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_xor_16_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_xor_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_XOR_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_xor_32_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_xor_32 AR:$ptr, AR:$arg))]>;
+
+	def ATOMIC_LOAD_NAND_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_nand_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_nand_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_NAND_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_nand_16_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_nand_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_NAND_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_nand_32_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_nand_32 AR:$ptr, AR:$arg))]>;
+
+	def ATOMIC_LOAD_MIN_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_min_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_min_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_MIN_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_min_16_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_min_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_MIN_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_min_32_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_min_32 AR:$ptr, AR:$arg))]>;			
+										
+	def ATOMIC_LOAD_MAX_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_max_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_max_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_MAX_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_max_16_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_max_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_MAX_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_max_32_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_max_32 AR:$ptr, AR:$arg))]>;	
+
+	def ATOMIC_LOAD_UMIN_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_umin_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_umin_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_UMIN_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_umin_16_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_umin_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_UMIN_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_umin_32_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_umin_32 AR:$ptr, AR:$arg))]>;			
+										
+	def ATOMIC_LOAD_UMAX_8_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_umax_8_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_umax_8 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_UMAX_16_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_umax_16_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_umax_16 AR:$ptr, AR:$arg))]>;
+	def ATOMIC_LOAD_UMAX_32_P: Pseudo<(outs AR:$dst), (ins AR:$ptr, AR:$arg),
+                                   "!atomic_load_umax_32_p, $dst, $ptr, $arg",
+                                   [(set AR:$dst, (atomic_load_umax_32 AR:$ptr, AR:$arg))]>;	
+}
+
+//===----------------------------------------------------------------------===//
+// DSP Instructions
+//===----------------------------------------------------------------------===//
+include "XtensaDSPInstrInfo.td"
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaMCInstLower.cpp
@@ -0,0 +1,135 @@
+//===- XtensaMCInstLower.cpp - Convert Xtensa MachineInstr to MCInst ------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains code to lower Xtensa MachineInstrs to their corresponding
+// MCInst records.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaMCInstLower.h"
+#include "MCTargetDesc/XtensaMCExpr.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/CodeGen/MachineInstr.h"
+#include "llvm/IR/Mangler.h"
+#include "llvm/MC/MCExpr.h"
+#include "llvm/MC/MCInst.h"
+#include "llvm/MC/MCStreamer.h"
+
+using namespace llvm;
+
+XtensaMCInstLower::XtensaMCInstLower(MCContext &ctx,
+                                     XtensaAsmPrinter &asmPrinter)
+    : Ctx(ctx), Printer(asmPrinter) {}
+
+MCSymbol *
+XtensaMCInstLower::GetExternalSymbolSymbol(const MachineOperand &MO) const {
+  return Printer.GetExternalSymbolSymbol(MO.getSymbolName());
+}
+
+MCSymbol *
+XtensaMCInstLower::GetJumpTableSymbol(const MachineOperand &MO) const {
+  return Printer.GetJTISymbol(MO.getIndex());
+}
+
+MCSymbol *
+XtensaMCInstLower::GetConstantPoolIndexSymbol(const MachineOperand &MO) const {
+  // Create a symbol for the name.
+  return Printer.GetCPISymbol(MO.getIndex());
+}
+
+MCOperand
+XtensaMCInstLower::LowerSymbolOperand(const MachineOperand &MO,
+                                      MachineOperand::MachineOperandType MOTy,
+                                      unsigned Offset) const {
+  const MCSymbol *Symbol;
+  XtensaMCExpr::VariantKind Kind = XtensaMCExpr::VK_Xtensa_None;
+
+  switch (MOTy) {
+  case MachineOperand::MO_MachineBasicBlock:
+    Symbol = MO.getMBB()->getSymbol();
+    break;
+  case MachineOperand::MO_GlobalAddress:
+    Symbol = Printer.getSymbol(MO.getGlobal());
+    Offset += MO.getOffset();
+    break;
+  case MachineOperand::MO_BlockAddress:
+    Symbol = Printer.GetBlockAddressSymbol(MO.getBlockAddress());
+    Offset += MO.getOffset();
+    break;
+  case MachineOperand::MO_ExternalSymbol:
+    Symbol = GetExternalSymbolSymbol(MO);
+    Offset += MO.getOffset();
+    break;
+  case MachineOperand::MO_JumpTableIndex:
+    Symbol = GetJumpTableSymbol(MO);
+    break;
+  case MachineOperand::MO_ConstantPoolIndex:
+    Symbol = GetConstantPoolIndexSymbol(MO);
+    Offset += MO.getOffset();
+    break;
+  default:
+    llvm_unreachable("<unknown operand type>");
+  }
+
+  const MCExpr *ME =
+      MCSymbolRefExpr::create(Symbol, MCSymbolRefExpr::VK_None, Ctx);
+
+  ME = XtensaMCExpr::create(ME, Kind, Ctx);
+
+  if (Offset) {
+    // Assume offset is never negative.
+    assert(Offset > 0);
+
+    const MCConstantExpr *OffsetExpr = MCConstantExpr::create(Offset, Ctx);
+    ME = MCBinaryExpr::createAdd(ME, OffsetExpr, Ctx);
+  }
+
+  return MCOperand::createExpr(ME);
+}
+
+MCOperand XtensaMCInstLower::lowerOperand(const MachineOperand &MO,
+                                          unsigned Offset) const {
+  MachineOperand::MachineOperandType MOTy = MO.getType();
+
+  switch (MOTy) {
+  case MachineOperand::MO_Register:
+    // Ignore all implicit register operands.
+    if (MO.isImplicit())
+      break;
+    return MCOperand::createReg(MO.getReg());
+  case MachineOperand::MO_Immediate:
+    return MCOperand::createImm(MO.getImm() + Offset);
+  case MachineOperand::MO_RegisterMask:
+    break;
+  case MachineOperand::MO_MachineBasicBlock:
+  case MachineOperand::MO_GlobalAddress:
+  case MachineOperand::MO_ExternalSymbol:
+  case MachineOperand::MO_JumpTableIndex:
+  case MachineOperand::MO_ConstantPoolIndex:
+  case MachineOperand::MO_BlockAddress:
+    return LowerSymbolOperand(MO, MOTy, Offset);
+  default:
+    llvm_unreachable("unknown operand type");
+  }
+
+  return MCOperand();
+}
+
+void XtensaMCInstLower::lower(const MachineInstr *MI, MCInst &OutMI) const {
+  OutMI.setOpcode(MI->getOpcode());
+
+  for (unsigned i = 0, e = MI->getNumOperands(); i != e; ++i) {
+    const MachineOperand &MO = MI->getOperand(i);
+    MCOperand MCOp = lowerOperand(MO);
+
+    if (MCOp.isValid())
+      OutMI.addOperand(MCOp);
+  }
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaMCInstLower.h
@@ -0,0 +1,54 @@
+//===- XtensaMCInstLower.h - Lower MachineInstr to MCInst ------*- C++ -*--===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSAMCINSTLOWER_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSAMCINSTLOWER_H
+
+#include "XtensaAsmPrinter.h"
+#include "llvm/CodeGen/MachineOperand.h"
+#include "llvm/Support/Compiler.h"
+#include "llvm/Support/DataTypes.h"
+
+namespace llvm {
+class MCContext;
+class MCInst;
+class MCOperand;
+class MCSymbol;
+class MachineInstr;
+class MachineOperand;
+class XtensaAsmPrinter;
+
+class LLVM_LIBRARY_VISIBILITY XtensaMCInstLower {
+  MCContext &Ctx;
+  XtensaAsmPrinter &Printer;
+
+public:
+  XtensaMCInstLower(MCContext &ctx, XtensaAsmPrinter &asmPrinter);
+
+  // Lower MachineInstr MI to MCInst OutMI.
+  void lower(const MachineInstr *MI, MCInst &OutMI) const;
+
+  // Return an MCOperand for MO.  Return an empty operand if MO is implicit.
+  MCOperand lowerOperand(const MachineOperand &MO, unsigned Offset = 0) const;
+
+private:
+  MCSymbol *GetExternalSymbolSymbol(const MachineOperand &MO) const;
+
+  MCSymbol *GetJumpTableSymbol(const MachineOperand &MO) const;
+
+  MCSymbol *GetConstantPoolIndexSymbol(const MachineOperand &MO) const;
+
+  MCOperand LowerSymbolOperand(const MachineOperand &MO,
+                               MachineOperand::MachineOperandType MOTy,
+                               unsigned Offset) const;
+};
+} // end namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSAMCINSTLOWER_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaMachineFunctionInfo.cpp
@@ -0,0 +1,19 @@
+//===- XtensaMachineFunctionInfo.cpp - Private data used for Xtensa -------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaMachineFunctionInfo.h"
+//#include "MCTargetDesc/XtensaBaseInfo.h"
+#include "XtensaInstrInfo.h"
+#include "XtensaSubtarget.h"
+#include "llvm/CodeGen/MachineInstrBuilder.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/IR/Function.h"
+
+using namespace llvm;
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaMachineFunctionInfo.h
@@ -0,0 +1,56 @@
+//==- XtensaMachineFunctionInfo.h - Xtensa machine function info --*- C++ -*-=//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file declares Xtensa-specific per-machine-function information.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSAMACHINEFUNCTIONINFO_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSAMACHINEFUNCTIONINFO_H
+
+#include "llvm/CodeGen/MachineFrameInfo.h"
+#include "llvm/CodeGen/MachineFunction.h"
+#include "llvm/Target/TargetMachine.h"
+
+namespace llvm {
+
+class XtensaFunctionInfo : public MachineFunctionInfo {
+  MachineFunction &MF;
+
+  unsigned VarArgsFirstGPR;
+  int VarArgsStackOffset;
+  unsigned VarArgsFrameIndex;
+
+public:
+  explicit XtensaFunctionInfo(MachineFunction &MF)
+      : MF(MF), VarArgsFirstGPR(0), VarArgsStackOffset(0),
+        VarArgsFrameIndex(0) {
+    MF.setAlignment(Align(4));
+  }
+
+  unsigned getVarArgsFirstGPR() const { return VarArgsFirstGPR; }
+  void setVarArgsFirstGPR(unsigned GPR) { VarArgsFirstGPR = GPR; }
+
+  int getVarArgsStackOffset() const { return VarArgsStackOffset; }
+  void setVarArgsStackOffset(int Offset) { VarArgsStackOffset = Offset; }
+
+  // Get and set the frame index of the first stack vararg.
+  unsigned getVarArgsFrameIndex() const { return VarArgsFrameIndex; }
+  void setVarArgsFrameIndex(unsigned FI) { VarArgsFrameIndex = FI; }
+
+  // TODO: large frame size definition should be specified more precisely
+  bool isLargeFrame() {
+    return (MF.getFrameInfo().estimateStackSize(MF) > 512) ? true : false;
+  }
+};
+
+} // namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSAMACHINEFUNCTIONINFO_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaOperands.td
@@ -0,0 +1,258 @@
+//===- XtensaOperands.td - Xtensa instruction operands ----*- tblgen-*--===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===-------------------------------------------------------------------===//
+
+// Immediate operands with a shared generic render method.
+class ImmAsmOperand<string name> : AsmOperandClass
+{
+  let Name = name;
+  let RenderMethod = "addImmOperands";
+  let DiagnosticType = !strconcat("Invalid", name);
+}
+
+class Immediate<ValueType vt, code pred, string asmop>
+    : Operand<vt>, ImmLeaf<vt, pred>
+{
+  let PrintMethod = "print"##asmop;
+  let ParserMatchClass = !cast<AsmOperandClass>(asmop);
+}
+
+// imm8 predicate - Immediate in the range [-128,127]
+def Imm8_AsmOperand: ImmAsmOperand<"Imm8">;
+def imm8: Immediate<i32, [{ return Imm >= -128 && Imm <= 127; }], "Imm8_AsmOperand"> {
+  let EncoderMethod = "getImm8OpValue";
+  let DecoderMethod = "decodeImm8Operand";
+}
+
+// imm8_sh8 predicate - Immediate in the range [-32768,32512] with (bits[7-0] == 0)
+// imm8 value left shifted by 8 bits
+def Imm8_sh8_AsmOperand: ImmAsmOperand<"Imm8_sh8">;
+def imm8_sh8: Immediate<i32, [{ return Imm >= -32768 && Imm <= 32512 && ((Imm & 0xFF) == 0); }], "Imm8_sh8_AsmOperand"> {
+  let EncoderMethod = "getImm8_sh8OpValue";
+  let DecoderMethod = "decodeImm8_sh8Operand";
+}
+
+// imm8n_7 predicate - Immediate in the range [-8,7]
+def Imm8n_7_AsmOperand: ImmAsmOperand<"Imm8n_7">;
+def imm8n_7: Immediate<i32, [{ return Imm >= -8 && Imm <= 7; }], "Imm8n_7_AsmOperand"> {
+  let EncoderMethod = "getImm8n_7OpValue";
+  let DecoderMethod = "decodeImm8n_7Operand";
+}
+
+// imm64n_4n predicate - Immediate in the range [-64,-4]
+def Imm64n_4n_AsmOperand: ImmAsmOperand<"Imm64n_4n">;
+def imm64n_4n: Immediate<i32, [{ return Imm >= -64 && Imm <= -4; }], "Imm64n_4n_AsmOperand"> {
+  let EncoderMethod = "getImm64n_4nOpValue";
+  let DecoderMethod = "decodeImm64n_4nOperand";
+} 
+
+// imm12 predicate - Immediate in the range [-2048,2047]
+def Imm12_AsmOperand: ImmAsmOperand<"Imm12">;
+def imm12: Immediate<i32, [{ return Imm >= -2048 && Imm <= 2047; }], "Imm12_AsmOperand"> {
+  let EncoderMethod = "getImm12OpValue";
+  let DecoderMethod = "decodeImm12Operand";
+}
+
+// imm12m predicate - Immediate for MOV operation
+def Imm12m_AsmOperand: ImmAsmOperand<"Imm12m">;
+def imm12m: Immediate<i32, [{ return Imm >= -2048 && Imm <= 2047; }], "Imm12m_AsmOperand"> {
+  let EncoderMethod = "getImm12OpValue";
+  let DecoderMethod = "decodeImm12Operand";
+}
+
+// uimm4 predicate - Immediate in the range [0,15]
+def Uimm4_AsmOperand: ImmAsmOperand<"Uimm4">;
+def uimm4: Immediate<i32, [{ return Imm >= 0 && Imm <= 15; }], "Uimm4_AsmOperand"> {
+  let EncoderMethod = "getUimm4OpValue";
+  let DecoderMethod = "decodeUimm4Operand";
+}
+
+// uimm5 predicate - Immediate in the range [0,31]
+def Uimm5_AsmOperand: ImmAsmOperand<"Uimm5">;
+def uimm5: Immediate<i32, [{ return Imm >= 0 && Imm <= 31; }], "Uimm5_AsmOperand"> {
+  let EncoderMethod = "getUimm5OpValue";
+  let DecoderMethod = "decodeUimm5Operand";
+}
+
+// imm1_16 predicate - Immediate in the range [1,16]
+def Imm1_16_AsmOperand: ImmAsmOperand<"Imm1_16">;
+def imm1_16: Immediate<i32, [{ return Imm >= 1 && Imm <= 16; }], "Imm1_16_AsmOperand"> {
+  let EncoderMethod = "getImm1_16OpValue";
+  let DecoderMethod = "decodeImm1_16Operand";
+}
+
+// imm1n_15 predicate - Immediate in the range [-1,15], except 0
+def Imm1n_15_AsmOperand: ImmAsmOperand<"Imm1n_15">;
+def imm1n_15: Immediate<i32, [{ return Imm >= -1 && Imm <= 15 && Imm != 0; }], "Imm1n_15_AsmOperand"> {
+  let EncoderMethod = "getImm1n_15OpValue";
+  let DecoderMethod = "decodeImm1n_15Operand";
+}
+
+// imm32n_95 predicate - Immediate in the range [-32,95]
+def Imm32n_95_AsmOperand: ImmAsmOperand<"Imm32n_95">;
+def imm32n_95: Immediate<i32, [{ return Imm >= -32 && Imm <= 95; }], "Imm32n_95_AsmOperand"> {
+  let EncoderMethod = "getImm32n_95OpValue";
+  let DecoderMethod = "decodeImm32n_95Operand";
+}
+
+// shimm1_31 predicate - Immediate in the range [1,31]
+def Shimm1_31_AsmOperand: ImmAsmOperand<"Shimm1_31">;
+def shimm1_31: Immediate<i32, [{ return Imm >= 1 && Imm <= 31; }], "Shimm1_31_AsmOperand"> {
+  let EncoderMethod = "getShimm1_31OpValue";
+  let DecoderMethod = "decodeShimm1_31Operand";
+}
+
+// Memory offset 0..255 for 8-bit memory accesses
+def Offset8m8_AsmOperand: ImmAsmOperand<"Offset8m8">;
+def offset8m8: Immediate<i32,
+    [{ return Imm >= 0 && Imm <= 255; }],
+    "Offset8m8_AsmOperand">;
+
+// Memory offset 0..510 for 16-bit memory accesses
+def Offset8m16_AsmOperand: ImmAsmOperand<"Offset8m16">;
+def offset8m16: Immediate<i32,
+    [{ return Imm >= 0 && Imm <= 510 && (Imm & 0x1 == 0); }],
+    "Offset8m16_AsmOperand">;
+
+// Memory offset 0..1020 for 32-bit memory accesses
+def Offset8m32_AsmOperand: ImmAsmOperand<"Offset8m32">;
+def offset8m32: Immediate<i32,
+    [{ return Imm >= 0 && Imm <= 1020 && (Imm & 0x3 == 0); }],
+    "Offset8m32_AsmOperand">;
+
+// Memory offset 0..60 for 32-bit memory accesses
+def Offset4m32_AsmOperand: ImmAsmOperand<"Offset4m32">;
+def offset4m32: Immediate<i32,
+    [{ return Imm >= 0 && Imm <= 60 && (Imm & 0x3 == 0); }],
+    "Offset4m32_AsmOperand">;
+
+// entry_imm12 predicate - Immediate in the range [0,32760], ENTRY parameter
+def Entry_Imm12_AsmOperand: ImmAsmOperand<"entry_imm12">;
+def entry_imm12: Immediate<i32, [{ return Imm >= 0 && Imm <= 32760 && (Imm & 0x3 == 0); }], "Entry_Imm12_AsmOperand"> {
+  let EncoderMethod = "getEntry_Imm12OpValue";
+  let DecoderMethod = "decodeEntry_Imm12OpValue";
+}
+
+// b4const predicate - Branch Immediate 4-bit signed operand
+def B4const_AsmOperand: ImmAsmOperand<"B4const">;
+def b4const: Immediate<i32,
+  [{ switch (Imm)
+     {
+        case -1: case 1: case 2: case 3:  case 4:
+        case 5:  case 6: case 7: case 8: case 10: case 12:
+        case 16: case 32: case 64: case 128: case 256: return 1;
+        default: return 0;
+     }
+  }],
+  "B4const_AsmOperand"> {
+  let EncoderMethod = "getB4constOpValue";
+  let DecoderMethod = "decodeB4constOperand";
+}
+
+// b4constu predicate - Branch Immediate 4-bit unsigned operand
+def B4constu_AsmOperand: ImmAsmOperand<"B4constu">;
+def b4constu: Immediate<i32,
+  [{ switch (Imm)
+     {
+        case 32768: case 65536: case 2: case 3:  case 4:
+        case 5:  case 6: case 7: case 8: case 10: case 12:
+        case 16: case 32: case 64: case 128: case 256: return 1;
+        default: return 0;
+     }
+  }],
+  "B4constu_AsmOperand"> {
+  let EncoderMethod = "getB4constuOpValue";
+  let DecoderMethod = "decodeB4constuOperand";
+}
+
+// seimm7_22 predicate - Immediate in the range [7,22] for sign extend
+def Seimm7_22_AsmOperand: ImmAsmOperand<"seimm7_22">;
+def seimm7_22: Immediate<i32, [{ return Imm >= 7 && Imm <= 22; }], "Seimm7_22_AsmOperand"> {
+  let EncoderMethod = "getSeimm7_22OpValue";
+  let DecoderMethod = "decodeSeimm7_22Operand";
+}
+
+//===----------------------------------------------------------------------===//
+// Memory address operands
+//===----------------------------------------------------------------------===//
+
+class mem<Operand offset> : Operand<i32>
+{
+  let MIOperandInfo = (ops AR, offset);
+  let EncoderMethod = "getMemRegEncoding";
+  let OperandType = "OPERAND_MEMORY";
+  let PrintMethod = "printMemOperand";
+}
+
+def mem8: mem<offset8m8>
+{
+  let DecoderMethod = "decodeMem8Operand";
+}
+
+def mem16: mem<offset8m16>
+{
+  let DecoderMethod = "decodeMem16Operand";
+}
+
+def mem32: mem<offset8m32>
+{
+  let DecoderMethod = "decodeMem32Operand";
+}
+
+def mem32n: mem<offset4m32>
+{
+  let DecoderMethod = "decodeMem32nOperand";
+}
+
+//Add patterns for future use in stack addressing mode
+def addr_ish1: ComplexPattern<iPTR, 2, "selectMemRegAddrISH1", [frameindex]>;
+def addr_ish2: ComplexPattern<iPTR, 2, "selectMemRegAddrISH2", [frameindex]>;
+def addr_ish4: ComplexPattern<iPTR, 2, "selectMemRegAddrISH4", [frameindex]>;
+
+//===----------------------------------------------------------------------===//
+// Symbolic address operands
+//===----------------------------------------------------------------------===//
+def XtensaPCRelTargetAsmOperand : AsmOperandClass {
+  let Name = "PCRelTarget";
+  let ParserMethod = "parsePCRelTarget";
+  let PredicateMethod = "isImm";
+  let RenderMethod = "addImmOperands";
+}
+
+def  pcrel32call: Operand<iPTR>
+{
+  let PrintMethod = "printCallOperand";
+  let EncoderMethod = "getCallEncoding";
+  let DecoderMethod = "decodeCallOperand";
+  let ParserMatchClass = XtensaPCRelTargetAsmOperand;
+}
+
+def brtarget : Operand<OtherVT>
+{
+  let PrintMethod = "printBranchTarget";
+  let EncoderMethod = "getBranchTargetEncoding";
+  let DecoderMethod = "decodeBranchOperand";
+  let ParserMatchClass = XtensaPCRelTargetAsmOperand;
+}
+
+def jumptarget: Operand<OtherVT>
+{
+  let PrintMethod = "printJumpTarget";
+  let EncoderMethod = "getJumpTargetEncoding";
+  let DecoderMethod = "decodeJumpOperand";
+  let ParserMatchClass = XtensaPCRelTargetAsmOperand;
+}
+
+def L32Rtarget: Operand<i32>
+{
+  let PrintMethod = "printL32RTarget";
+  let EncoderMethod = "getL32RTargetEncoding";
+  let DecoderMethod = "decodeL32ROperand";
+  let ParserMatchClass = XtensaPCRelTargetAsmOperand;
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaOperators.td
@@ -0,0 +1,106 @@
+//===- XtensaOperators.td - Xtensa-specific operators ---------*- tblgen-*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+//===----------------------------------------------------------------------===//
+// Type profiles
+//===----------------------------------------------------------------------===//
+
+def SDT_XtensaCallSeqStart        : SDCallSeqStart<[SDTCisVT<0, i32>, SDTCisVT<1, i32>]>;
+def SDT_XtensaCallSeqEnd          : SDCallSeqEnd<[SDTCisVT<0, i32>, SDTCisVT<1, i32>]>;
+def SDT_XtensaCall                : SDTypeProfile<0, -1, [SDTCisPtrTy<0>]>;
+def SDT_XtensaWrapPtr             : SDTypeProfile<1, 1,
+                                                 [SDTCisSameAs<0, 1>,
+                                                  SDTCisPtrTy<0>]>;
+
+def SDT_XtensaSelectCC            : SDTypeProfile<1, 5,
+                                                 [SDTCisSameAs<0, 1>,
+                                                  SDTCisSameAs<2, 3>,
+                                                  SDTCisVT<5, i32>]>;
+
+def SDT_XtensaMOVSP               : SDTypeProfile<1, 1, [SDTCisSameAs<0, 1>, SDTCisVT<0, i32>]>;
+def SDT_XtensaBrCC                : SDTypeProfile<0, 2, [SDTCisVT<0, i1>, SDTCisVT<1, OtherVT>]>;
+def SDT_XtensaCmp                 : SDTypeProfile<1, 2, [SDTCisVT<0, i1>, SDTCisVT<1, f32>, SDTCisVT<2, f32>]>;
+def SDT_XtensaMADD                : SDTypeProfile<1, 3, [SDTCisSameAs<0, 1>, SDTCisSameAs<0, 2>, SDTCisSameAs<0, 3>, SDTCisVT<0, f32>]>;
+def SDT_XtensaMOVS                : SDTypeProfile<1, 1, [SDTCisSameAs<0, 1>, SDTCisVT<0, f32>]>;
+def SDT_XtensaSelectCCFP          : SDTypeProfile<1, 5, [SDTCisSameAs<0, 3>, SDTCisSameAs<1, 2>, SDTCisSameAs<3, 4>, SDTCisVT<5, i32>]>;
+def SDT_XtensaBrJT                : SDTypeProfile<0, 2,
+                                                 [SDTCisPtrTy<0>, SDTCisVT<1, i32>]>;
+
+def SDT_XtensaSHL                 : SDTypeProfile<1, 1, [SDTCisVT<0, i32>, SDTCisVT<1, i32>]>;
+def SDT_XtensaSRA                 : SDTypeProfile<1, 1, [SDTCisVT<0, i32>, SDTCisVT<1, i32>]>;
+def SDT_XtensaSRL                 : SDTypeProfile<1, 1, [SDTCisVT<0, i32>, SDTCisVT<1, i32>]>;
+def SDT_XtensaSRC                 : SDTypeProfile<1, 2, [SDTCisVT<0, i32>, SDTCisVT<1, i32>, 
+                                                         SDTCisVT<2, i32>]>;
+def SDT_XtensaSSL                 : SDTypeProfile<0, 1, [SDTCisVT<0, i32>]>;
+def SDT_XtensaSSR                 : SDTypeProfile<0, 1, [SDTCisVT<0, i32>]>;
+def SDT_XtensaMEMBARRIER         : SDTypeProfile<0, 0, []>;
+def SDT_XtensaRUR                : SDTypeProfile<1, 1, [SDTCisVT<0, i32>, SDTCisVT<1, i32>]>;
+
+//===----------------------------------------------------------------------===//
+// Node definitions
+//===----------------------------------------------------------------------===//
+
+def Xtensa_call: SDNode<"XtensaISD::CALL", SDT_XtensaCall,
+                       [SDNPHasChain, SDNPOutGlue, SDNPOptInGlue, SDNPVariadic]>;
+
+def Xtensa_retflag: SDNode<"XtensaISD::RET_FLAG", SDTNone,
+                          [SDNPHasChain, SDNPOptInGlue, SDNPVariadic]>;
+def Xtensa_retWflag: SDNode<"XtensaISD::RETW_FLAG", SDTNone,
+                          [SDNPHasChain, SDNPOptInGlue, SDNPVariadic]>;
+
+def Xtensa_callseq_start: SDNode<"ISD::CALLSEQ_START", SDT_XtensaCallSeqStart,
+                                [SDNPHasChain, SDNPSideEffect, SDNPOutGlue]>;
+def Xtensa_callseq_end  : SDNode<"ISD::CALLSEQ_END",   SDT_XtensaCallSeqEnd,
+                                [SDNPHasChain, SDNPSideEffect, SDNPOptInGlue,
+                                 SDNPOutGlue]>;
+
+def Xtensa_pcrel_wrapper: SDNode<"XtensaISD::PCREL_WRAPPER", SDT_XtensaWrapPtr, []>;
+
+def Xtensa_select : SDNode<"XtensaISD::SELECT", SDTSelect>;
+def Xtensa_select_cc: SDNode<"XtensaISD::SELECT_CC", SDT_XtensaSelectCC,
+                            [SDNPInGlue]>;
+def Xtensa_select_cc_fp: SDNode<"XtensaISD::SELECT_CC_FP", SDT_XtensaSelectCCFP,
+                            [SDNPInGlue]>;
+
+def Xtensa_movsp: SDNode<"XtensaISD::MOVSP", SDT_XtensaMOVSP,
+                            [SDNPInGlue]>;
+
+def Xtensa_brcc_t    : SDNode<"XtensaISD::BR_CC_T", SDT_XtensaBrCC,
+                             [SDNPHasChain, SDNPInGlue]>;
+def Xtensa_brcc_f    : SDNode<"XtensaISD::BR_CC_F", SDT_XtensaBrCC,
+                             [SDNPHasChain, SDNPInGlue]>;
+
+def Xtensa_cmpoeq     : SDNode<"XtensaISD::CMPOEQ", SDT_XtensaCmp, [SDNPOutGlue]>;
+def Xtensa_cmpolt     : SDNode<"XtensaISD::CMPOLT", SDT_XtensaCmp, [SDNPOutGlue]>;
+def Xtensa_cmpole     : SDNode<"XtensaISD::CMPOLE", SDT_XtensaCmp, [SDNPOutGlue]>;
+def Xtensa_cmpueq     : SDNode<"XtensaISD::CMPUEQ", SDT_XtensaCmp, [SDNPOutGlue]>;
+def Xtensa_cmpult     : SDNode<"XtensaISD::CMPULT", SDT_XtensaCmp, [SDNPOutGlue]>;
+def Xtensa_cmpule     : SDNode<"XtensaISD::CMPULE", SDT_XtensaCmp, [SDNPOutGlue]>;
+def Xtensa_cmpuo      : SDNode<"XtensaISD::CMPUO", SDT_XtensaCmp, [SDNPOutGlue]>;
+
+def Xtensa_madd: SDNode<"XtensaISD::MADD", SDT_XtensaMADD, [SDNPInGlue]>;
+def Xtensa_msub: SDNode<"XtensaISD::MSUB", SDT_XtensaMADD, [SDNPInGlue]>;
+def Xtensa_movs: SDNode<"XtensaISD::MOVS", SDT_XtensaMOVS, [SDNPInGlue]>; 
+
+def Xtensa_shl: SDNode<"XtensaISD::SHL", SDT_XtensaSHL, [SDNPInGlue]>;
+def Xtensa_sra: SDNode<"XtensaISD::SRA", SDT_XtensaSRA, [SDNPInGlue]>;
+def Xtensa_srl: SDNode<"XtensaISD::SRL", SDT_XtensaSRL, [SDNPInGlue]>;
+def Xtensa_src: SDNode<"XtensaISD::SRC", SDT_XtensaSRC, [SDNPInGlue]>;
+def Xtensa_ssl: SDNode<"XtensaISD::SSL", SDT_XtensaSSL, [SDNPOutGlue]>;
+def Xtensa_ssr: SDNode<"XtensaISD::SSR", SDT_XtensaSSR, [SDNPOutGlue]>;
+
+def Xtensa_brjt: SDNode<"XtensaISD::BR_JT", SDT_XtensaBrJT, [SDNPHasChain]>;
+def Xtensa_callw: SDNode<"XtensaISD::CALLW", SDT_XtensaCall,
+                        [SDNPHasChain, SDNPOutGlue, SDNPOptInGlue, SDNPVariadic]>;
+def Xtensa_mem_barrier: SDNode<"XtensaISD::MEMW", SDT_XtensaMEMBARRIER,
+                              [SDNPHasChain, SDNPSideEffect]>;
+
+def Xtensa_rur: SDNode<"XtensaISD::RUR", SDT_XtensaRUR,
+                      [SDNPInGlue]>;
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaRegisterInfo.cpp
@@ -0,0 +1,182 @@
+//===- XtensaRegisterInfo.cpp - Xtensa Register Information ---------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains the Xtensa implementation of the TargetRegisterInfo class.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaRegisterInfo.h"
+#include "XtensaInstrInfo.h"
+#include "XtensaSubtarget.h"
+#include "llvm/CodeGen/MachineInstrBuilder.h"
+#include "llvm/CodeGen/MachineRegisterInfo.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "llvm/Support/raw_ostream.h"
+
+#define DEBUG_TYPE "xtensa-reg-info"
+
+#define GET_REGINFO_TARGET_DESC
+#include "XtensaGenRegisterInfo.inc"
+
+using namespace llvm;
+
+XtensaRegisterInfo::XtensaRegisterInfo(const XtensaSubtarget &STI)
+    : XtensaGenRegisterInfo(Xtensa::A0), Subtarget(STI) {}
+
+const uint16_t *
+XtensaRegisterInfo::getCalleeSavedRegs(const MachineFunction *MF) const {
+  if (Subtarget.isWinABI())
+    return CSRWE_Xtensa_SaveList;
+  else
+    return CSR_Xtensa_SaveList;
+}
+
+const uint32_t *
+XtensaRegisterInfo::getCallPreservedMask(const MachineFunction &MF,
+                                         CallingConv::ID) const {
+  if (Subtarget.isWinABI())
+    return CSRWE_Xtensa_RegMask;
+  else
+    return CSR_Xtensa_RegMask;
+}
+
+BitVector XtensaRegisterInfo::getReservedRegs(const MachineFunction &MF) const {
+  BitVector Reserved(getNumRegs());
+  const TargetFrameLowering *TFI = MF.getSubtarget().getFrameLowering();
+
+  Reserved.set(Xtensa::A0);
+  if (TFI->hasFP(MF)) {
+    // Reserve frame pointer.
+    Reserved.set(getFrameRegister(MF));
+  }
+
+  // Reserve stack pointer.
+  Reserved.set(Xtensa::SP);
+  return Reserved;
+}
+
+void XtensaRegisterInfo::eliminateFI(MachineBasicBlock::iterator II,
+                                     unsigned OpNo, int FrameIndex,
+                                     uint64_t StackSize,
+                                     int64_t SPOffset) const {
+  MachineInstr &MI = *II;
+  MachineFunction &MF = *MI.getParent()->getParent();
+  MachineFrameInfo &MFI = MF.getFrameInfo();
+
+  const std::vector<CalleeSavedInfo> &CSI = MFI.getCalleeSavedInfo();
+  int MinCSFI = 0;
+  int MaxCSFI = -1;
+
+  if (CSI.size()) {
+    MinCSFI = CSI[0].getFrameIdx();
+    MaxCSFI = CSI[CSI.size() - 1].getFrameIdx();
+  }
+
+  // The following stack frame objects are always referenced relative to $sp:
+  //  1. Outgoing arguments.
+  //  2. Pointer to dynamically allocated stack space.
+  //  3. Locations for callee-saved registers.
+  //  4. Locations for eh data registers.
+  // Everything else is referenced relative to whatever register
+  // getFrameRegister() returns.
+  unsigned FrameReg;
+
+  if ((FrameIndex >= MinCSFI && FrameIndex <= MaxCSFI))
+    FrameReg = Xtensa::SP;
+  else
+    FrameReg = getFrameRegister(MF);
+
+  // Calculate final offset.
+  // - There is no need to change the offset if the frame object is one of the
+  //   following: an outgoing argument, pointer to a dynamically allocated
+  //   stack space or a $gp restore location,
+  // - If the frame object is any of the following, its offset must be adjusted
+  //   by adding the size of the stack:
+  //   incoming argument, callee-saved register location or local variable.
+  bool IsKill = false;
+  int64_t Offset;
+
+  Offset = SPOffset + (int64_t)StackSize;
+  Offset += MI.getOperand(OpNo + 1).getImm();
+
+  LLVM_DEBUG(errs() << "Offset     : " << Offset << "\n"
+                    << "<--------->\n");
+
+  bool Valid = false;
+  switch (MI.getOpcode()) {
+  case Xtensa::L8I_P:
+  case Xtensa::L8UI:
+  case Xtensa::S8I:
+    Valid = (Offset >= 0 && Offset <= 255);
+    break;
+  case Xtensa::L16SI:
+  case Xtensa::L16UI:
+  case Xtensa::S16I:
+    Valid = (Offset >= 0 && Offset <= 510);
+    break;
+  case Xtensa::LEA_ADD:
+    Valid = (Offset >= -128 && Offset <= 127);
+    break;
+  default:
+    Valid = (Offset >= 0 && Offset <= 1020);
+    break;
+  }
+
+  // If MI is not a debug value, make sure Offset fits in the 16-bit immediate
+  // field.
+  if (!MI.isDebugValue() && !Valid) {
+    MachineBasicBlock &MBB = *MI.getParent();
+    DebugLoc DL = II->getDebugLoc();
+    unsigned ADD = Xtensa::ADD;
+    unsigned Reg;
+    const XtensaInstrInfo &TII = *static_cast<const XtensaInstrInfo *>(
+        MBB.getParent()->getSubtarget().getInstrInfo());
+
+    TII.loadImmediate(MBB, II, &Reg, Offset);
+    BuildMI(MBB, II, DL, TII.get(ADD), Reg)
+        .addReg(FrameReg)
+        .addReg(Reg, RegState::Kill);
+
+    FrameReg = Reg;
+    Offset = 0;
+    IsKill = true;
+  }
+
+  MI.getOperand(OpNo).ChangeToRegister(FrameReg, false, false, IsKill);
+  MI.getOperand(OpNo + 1).ChangeToImmediate(Offset);
+}
+
+void XtensaRegisterInfo::eliminateFrameIndex(MachineBasicBlock::iterator II,
+                                             int SPAdj, unsigned FIOperandNum,
+                                             RegScavenger *RS) const {
+  MachineInstr &MI = *II;
+  MachineFunction &MF = *MI.getParent()->getParent();
+
+  LLVM_DEBUG(errs() << "\nFunction : " << MF.getName() << "\n";
+             errs() << "<--------->\n"
+                    << MI);
+
+  int FrameIndex = MI.getOperand(FIOperandNum).getIndex();
+  uint64_t stackSize = MF.getFrameInfo().getStackSize();
+  int64_t spOffset = MF.getFrameInfo().getObjectOffset(FrameIndex);
+
+  LLVM_DEBUG(errs() << "FrameIndex : " << FrameIndex << "\n"
+                    << "spOffset   : " << spOffset << "\n"
+                    << "stackSize  : " << stackSize << "\n");
+
+  eliminateFI(MI, FIOperandNum, FrameIndex, stackSize, spOffset);
+}
+
+Register XtensaRegisterInfo::getFrameRegister(const MachineFunction &MF) const {
+  const TargetFrameLowering *TFI = MF.getSubtarget().getFrameLowering();
+  return TFI->hasFP(MF) ? (Subtarget.isWinABI() ? Xtensa::A7 : Xtensa::A15)
+                        : Xtensa::SP;
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaRegisterInfo.h
@@ -0,0 +1,64 @@
+//===-- XtensaRegisterInfo.h - Xtensa Register Information Impl -*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file contains the Xtensa implementation of the TargetRegisterInfo class.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSAREGISTERINFO_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSAREGISTERINFO_H
+
+#include "Xtensa.h"
+#include "llvm/CodeGen/TargetRegisterInfo.h"
+
+#define GET_REGINFO_HEADER
+#include "XtensaGenRegisterInfo.inc"
+
+namespace llvm {
+class TargetRegisterClass;
+class XtensaInstrInfo;
+class XtensaSubtarget;
+
+struct XtensaRegisterInfo : public XtensaGenRegisterInfo {
+public:
+  const XtensaSubtarget &Subtarget;
+
+  XtensaRegisterInfo(const XtensaSubtarget &STI);
+
+  bool requiresRegisterScavenging(const MachineFunction &MF) const override {
+    return true;
+  }
+
+  bool requiresFrameIndexScavenging(const MachineFunction &MF) const override {
+    return true;
+  }
+
+  bool trackLivenessAfterRegAlloc(const MachineFunction &) const override {
+    return true;
+  }
+
+  const uint16_t *
+  getCalleeSavedRegs(const MachineFunction *MF = 0) const override;
+  const uint32_t *getCallPreservedMask(const MachineFunction &MF,
+                                       CallingConv::ID) const override;
+  BitVector getReservedRegs(const MachineFunction &MF) const override;
+  void eliminateFrameIndex(MachineBasicBlock::iterator MI, int SPAdj,
+                           unsigned FIOperandNum,
+                           RegScavenger *RS) const override;
+  Register getFrameRegister(const MachineFunction &MF) const override;
+
+private:
+  void eliminateFI(MachineBasicBlock::iterator II, unsigned OpNo,
+                   int FrameIndex, uint64_t StackSize, int64_t SPOffset) const;
+};
+
+} // end namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_REGISTERINFO_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaRegisterInfo.td
@@ -0,0 +1,287 @@
+//===- XtensaRegisterInfo.td - Xtensa Register defs -----------*- tablegen -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===-------------------------------------------------------------------------===//
+
+//===----------------------------------------------------------------------===//
+// Class definitions.
+//===----------------------------------------------------------------------===//
+
+class XtensaReg<string n> : Register<n> {
+  let Namespace = "Xtensa";
+}
+
+class XtensaRegWithSubRegs<string n, list<Register> subregs>
+  : RegisterWithSubRegs<n, subregs> {
+  let Namespace = "Xtensa";
+}
+
+//===----------------------------------------------------------------------===//
+// General-purpose registers
+//===----------------------------------------------------------------------===//
+
+// Xtensa general purpose regs
+class ARReg<bits<4> num, string n, list<string> alt = []> : XtensaReg<n> {
+    let HWEncoding{3-0} = num;
+    let AltNames = alt;
+}
+
+// Return Address
+def A0 : ARReg<0, "a0">, DwarfRegNum<[0]>;
+
+// Stack Pointer (callee-saved)
+def SP : ARReg<1, "a1", ["sp"]>, DwarfRegNum<[1]>;
+
+// Function Arguments
+def A2 : ARReg<2, "a2">, DwarfRegNum<[2]>;
+def A3 : ARReg<3, "a3">, DwarfRegNum<[3]>;
+def A4 : ARReg<4, "a4">, DwarfRegNum<[4]>;
+def A5 : ARReg<5, "a5">, DwarfRegNum<[5]>;
+def A6 : ARReg<6, "a6">, DwarfRegNum<[6]>;
+def A7 : ARReg<7, "a7">, DwarfRegNum<[7]>;
+
+// Static Chain
+def A8 : ARReg<8, "a8">, DwarfRegNum<[8]>;
+
+def A9 : ARReg<9, "a9">, DwarfRegNum<[9]>;
+def A10 : ARReg<10, "a10">, DwarfRegNum<[10]>;
+def A11 : ARReg<11, "a11">, DwarfRegNum<[11]>;
+
+// Callee-saved
+def A12 : ARReg<12, "a12">, DwarfRegNum<[12]>;
+def A13 : ARReg<13, "a13">, DwarfRegNum<[13]>;
+def A14 : ARReg<14, "a14">, DwarfRegNum<[14]>;
+
+// Stack-Frame Pointer (optional) - Callee-Saved
+def A15 : ARReg<15, "a15">, DwarfRegNum<[15]>;
+
+// Register class with allocation order
+def AR : RegisterClass<"Xtensa", [i32], 32, (add
+  A8, A9, A10, A11, A12, A13, A14, A15,
+  A7, A6, A5, A4, A3, A2, A0, SP)>;
+//===----------------------------------------------------------------------===//
+// Special-purpose registers
+//===----------------------------------------------------------------------===//
+class SRReg<bits<8> num, string n, list<string> alt = []> : XtensaReg<n> {
+  let HWEncoding{7-0} = num;
+  let AltNames = alt;
+}
+
+def LBEG : SRReg<0, "lbeg", ["LBEG", "0"]>;
+def LEND : SRReg<1, "lend", ["LEND", "1"]>;
+def LCOUNT : SRReg<2, "lcount", ["LCOUNT", "2"]>;
+
+// Shift Amount Register
+def SAR : SRReg<3, "sar", ["SAR","3"]>;
+
+def BREG : SRReg<4, "br", ["BR", "4"]>;
+def LITBASE : SRReg<5, "litbase", ["LITBASE", "5"]>;
+
+// Expected data value for S32C1I operation
+def SCOMPARE1 : SRReg<12, "scompare1", ["SCOMPARE1", "12"]>;
+
+def ACCLO : SRReg<16, "acclo", ["ACCLO", "16"]>;
+def ACCHI : SRReg<17, "acchi", ["ACCHI", "17"]>;
+def M0 : SRReg<32, "m0", ["M0", "32"]>;
+def M1 : SRReg<33, "m1", ["M1", "33"]>;
+def M2 : SRReg<34, "m2", ["M2", "34"]>;
+def M3 : SRReg<35, "m3", ["M3", "35"]>;
+def WINDOWBASE : SRReg<72, "windowbase", ["WINDOWBASE", "72"]>;
+def WINDOWSTART : SRReg<73, "windowstart", ["WINDOWSTART", "73"]>;
+
+// Instuction breakpoint enable register
+def IBREAKENABLE : SRReg<96, "ibreakenable", ["IBREAKENABLE", "96"]>;
+
+// Memory Control Register
+def MEMCTL : SRReg<97, "memctl", ["MEMCTL", "97"]>;
+
+def ATOMCTL : SRReg<99, "atomctl", ["ATOMCTL", "99"]>;
+
+def DDR : SRReg<104, "ddr", ["DDR", "104"]>;
+
+// Instuction break address register 0
+def IBREAKA0 : SRReg<128, "ibreaka0", ["IBREAKA0", "128"]>;
+
+// Instuction break address register 1
+def IBREAKA1 : SRReg<129, "ibreaka1", ["IBREAKA1", "129"]>;
+
+// Data break address register 0
+def DBREAKA0 : SRReg<144, "dbreaka0", ["DBREAKA0", "144"]>;
+
+// Data break address register 1
+def DBREAKA1 : SRReg<145, "dbreaka1", ["DBREAKA1", "145"]>;
+
+// Data breakpoint control register 0
+def DBREAKC0 : SRReg<160, "dbreakc0", ["DBREAKC0", "160"]>;
+
+// Data breakpoint control register 1
+def DBREAKC1 : SRReg<161, "dbreakc1", ["DBREAKC1", "161"]>;
+
+def CONFIGID0 : SRReg<176, "configid0", ["CONFIGID0", "176"]>;
+
+// Exception PC1
+def EPC1 : SRReg<177, "epc1", ["EPC1", "177"]>;
+
+// Exception PC2
+def EPC2 : SRReg<178, "epc2", ["EPC2", "178"]>;
+
+// Exception PC3
+def EPC3 : SRReg<179, "epc3", ["EPC3", "179"]>;
+
+// Exception PC4
+def EPC4 : SRReg<180, "epc4", ["EPC4", "180"]>;
+
+// Exception PC5
+def EPC5 : SRReg<181, "epc5", ["EPC5", "181"]>;
+
+// Exception PC6
+def EPC6 : SRReg<182, "epc6", ["EPC6", "182"]>;
+
+// Exception PC7
+def EPC7 : SRReg<183, "epc7", ["EPC7", "183"]>;
+
+def DEPC : SRReg<192, "depc", ["DEPC", "192"]>;
+def EPS2 : SRReg<194, "eps2", ["EPS2", "194"]>;
+def EPS3 : SRReg<195, "eps3", ["EPS3", "195"]>;
+def EPS4 : SRReg<196, "eps4", ["EPS4", "196"]>;
+def EPS5 : SRReg<197, "eps5", ["EPS5", "197"]>;
+def EPS6 : SRReg<198, "eps6", ["EPS6", "198"]>;
+def EPS7 : SRReg<199, "eps7", ["EPS7", "199"]>;
+def CONFIGID1 : SRReg<208, "configid1", ["CONFIGID1", "208"]>;
+def EXCSAVE1 : SRReg<209, "excsave1", ["EXCSAVE1", "209"]>;
+def EXCSAVE2 : SRReg<210, "excsave2", ["EXCSAVE2", "210"]>;
+def EXCSAVE3 : SRReg<211, "excsave3", ["EXCSAVE3", "211"]>;
+def EXCSAVE4 : SRReg<212, "excsave4", ["EXCSAVE4", "212"]>;
+def EXCSAVE5 : SRReg<213, "excsave5", ["EXCSAVE5", "213"]>;
+def EXCSAVE6 : SRReg<214, "excsave6", ["EXCSAVE6", "214"]>;
+def EXCSAVE7 : SRReg<215, "excsave7", ["EXCSAVE7", "215"]>;
+def CPENABLE : SRReg<224, "cpenable", ["CPENABLE", "224"]>;
+
+// Interrupt enable mask register
+def INTSET : SRReg<226, "interrupt", ["INTERRUPT", "226"]>;
+
+def INTCLEAR : SRReg<227, "intclear", ["INTCLEAR", "227"]>;
+
+def INTENABLE : SRReg<228, "intenable", ["INTENABLE", "228"]>;
+
+// Processor State
+def PS : SRReg<230, "ps", ["PS", "230"]>;
+
+// Vector base register
+def VECBASE : SRReg<231, "vecbase", ["VECBASE", "231"]>;
+
+def EXCCAUSE : SRReg<232, "exccause", ["EXCCAUSE", "232"]>;
+
+// Cause of last debug exception register
+def DEBUGCAUSE : SRReg<233, "debugcause", ["DEBUGCAUSE", "233"]>;
+
+// Processor Clock Count Register
+def CCOUNT : SRReg<234, "ccount", ["CCOUNT", "234"]>;
+
+// Processor ID Register
+def PRID : SRReg<235, "prid", ["PRID", "235"]>;
+
+def ICOUNT : SRReg<236, "icount", ["ICOUNT", "236"]>;
+def ICOUNTLEVEL : SRReg<237, "icountlevel", ["ICOUNTLEVEL", "237"]>;
+def EXCVADDR : SRReg<238, "excvaddr", ["EXCVADDR", "238"]>;
+
+// Cycle number to interrupt register 0
+def CCOMPARE0 : SRReg<240, "ccompare0", ["CCOMPARE0", "240"]>;
+
+// Cycle number to interrupt register 1
+def CCOMPARE1 : SRReg<241, "ccompare1", ["CCOMPARE1", "241"]>;
+
+// Cycle number to interrupt register 2
+def CCOMPARE2 : SRReg<242, "ccompare2", ["CCOMPARE2", "242"]>;
+
+def MISC0 : SRReg<244, "misc0", ["MISC0", "244"]>;
+def MISC1 : SRReg<245, "misc1", ["MISC1", "245"]>;
+def MISC2 : SRReg<246, "misc2", ["MISC2", "246"]>;
+def MISC3 : SRReg<247, "misc3", ["MISC3", "247"]>;
+
+def MR01 :  RegisterClass<"Xtensa", [i32], 32, (add M0, M1)>;
+def MR23 :  RegisterClass<"Xtensa", [i32], 32, (add M2, M3)>;
+def MR :  RegisterClass<"Xtensa", [i32], 32, (add MR01, MR23)>;
+
+def SR :  RegisterClass<"Xtensa", [i32], 32, (add 
+  LBEG, LEND, LCOUNT, SAR, BREG, LITBASE, SCOMPARE1, ACCLO, ACCHI, MR,
+  WINDOWBASE, WINDOWSTART, IBREAKENABLE, MEMCTL, ATOMCTL, DDR, IBREAKA0, IBREAKA1,
+  DBREAKA0, DBREAKA1, DBREAKC0, DBREAKC1, CONFIGID0, EPC1, EPC2, EPC3, EPC4, EPC5, 
+  EPC6, EPC7, DEPC, EPS2, EPS3, EPS4, EPS5, EPS6, EPS7, CONFIGID1, EXCSAVE1, EXCSAVE2,
+  EXCSAVE3, EXCSAVE4, EXCSAVE5, EXCSAVE6, EXCSAVE7, CPENABLE, INTSET, INTCLEAR, INTENABLE, PS,
+  VECBASE, EXCCAUSE, DEBUGCAUSE, CCOUNT, PRID, ICOUNT, ICOUNTLEVEL, EXCVADDR, CCOMPARE0, 
+  CCOMPARE1, CCOMPARE2, MISC0, MISC1, MISC2, MISC3)>;
+
+//===----------------------------------------------------------------------===//
+// USER registers
+//===----------------------------------------------------------------------===//
+class URReg<bits<8> num, string n, list<string> alt = []> : XtensaReg<n> {
+  let HWEncoding{7-0} = num;
+  let AltNames = alt;
+}
+
+def GPIO_OUT : URReg<0, "gpio_out", ["GPIO_OUT"]>;
+def EXPSTATE : URReg<230, "expstate", ["EXPSTATE"]>;
+
+// Thread Pointer register
+def THREADPTR : URReg<231, "threadptr", ["THREADPTR"]>;
+
+def FCR : URReg<232, "fcr", ["FCR"]>;
+def FSR : URReg<233, "fsr", ["FSR"]>;
+def F64R_LO : URReg<234, "f64r_lo", ["F64R_LO"]>;
+def F64R_HI : URReg<235, "f64r_hi", ["F64R_HI"]>;
+def F64S : URReg<236, "f64s", ["F64S"]>;
+
+def UR :  RegisterClass<"Xtensa", [i32], 32, (add GPIO_OUT, EXPSTATE, THREADPTR, FCR,
+  FSR, F64R_LO, F64R_HI, F64S)>; 
+
+//===----------------------------------------------------------------------===//
+// Floating-Point registers
+//===----------------------------------------------------------------------===//
+
+// Xtensa Floating-Point regs
+class FPReg<bits<4> num, string n> : XtensaReg<n> {
+  let HWEncoding{3-0} = num;
+}
+
+def F0 : FPReg<0, "f0">, DwarfRegNum<[19]>;
+def F1 : FPReg<1, "f1">, DwarfRegNum<[20]>;
+def F2 : FPReg<2, "f2">, DwarfRegNum<[21]>;
+def F3 : FPReg<3, "f3">, DwarfRegNum<[22]>;
+def F4 : FPReg<4, "f4">, DwarfRegNum<[23]>;
+def F5 : FPReg<5, "f5">, DwarfRegNum<[24]>;
+def F6 : FPReg<6, "f6">, DwarfRegNum<[25]>;
+def F7 : FPReg<7, "f7">, DwarfRegNum<[26]>;
+def F8 : FPReg<8, "f8">, DwarfRegNum<[27]>;
+def F9 : FPReg<9, "f9">, DwarfRegNum<[28]>;
+def F10 : FPReg<10, "f10">, DwarfRegNum<[29]>;
+def F11 : FPReg<11, "f11">, DwarfRegNum<[30]>;
+def F12 : FPReg<12, "f12">, DwarfRegNum<[31]>;
+def F13 : FPReg<13, "f13">, DwarfRegNum<[32]>;
+def F14 : FPReg<14, "f14">, DwarfRegNum<[33]>;
+def F15 : FPReg<15, "f15">, DwarfRegNum<[34]>;
+
+// Floating-Point register class with allocation order
+def FPR : RegisterClass<"Xtensa", [f32], 32, (add
+  F8, F9, F10, F11, F12, F13, F14, F15,
+  F7, F6, F5, F4, F3, F2, F1, F0)>;
+
+//===----------------------------------------------------------------------===//
+// Boolean registers
+//===----------------------------------------------------------------------===//
+class BReg<bits<4> num, string n> : XtensaReg<n> {
+  let HWEncoding{3-0} = num;
+}
+
+foreach i = 0-15 in {
+  def B#i  : BReg<i, "b"#i>,  DwarfRegNum<[i]>;
+}
+
+// Boolean register class
+def BR : RegisterClass<"Xtensa", [i1], 0, (add B0, B1,
+B2, B3, B4, B5, B6, B7, B8, B9, B10, B11, B12, B13, B14, B15)>;
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaSizeReductionPass.cpp
@@ -0,0 +1,266 @@
+//===- XtensaSizeReductionPass.cpp - Xtensa Size Reduction ----------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+#include "Xtensa.h"
+#include "XtensaInstrInfo.h"
+#include "XtensaSubtarget.h"
+#include "llvm/ADT/Statistic.h"
+#include "llvm/CodeGen//MachineInstrBuilder.h"
+#include "llvm/CodeGen/MachineFunctionPass.h"
+#include "llvm/Support/Debug.h"
+#include "llvm/Support/MathExtras.h"
+#include "llvm/Target/TargetMachine.h"
+
+using namespace llvm;
+
+#define DEBUG_TYPE "xtensa-size-reduce-pass"
+
+STATISTIC(NumReduced, "Number of 24-bit instructions reduced to 16-bit ones");
+
+class XtensaSizeReduce : public MachineFunctionPass {
+public:
+  static char ID;
+  XtensaSizeReduce() : MachineFunctionPass(ID) {}
+
+  const XtensaSubtarget *Subtarget;
+  static const XtensaInstrInfo *XtensaII;
+
+  bool runOnMachineFunction(MachineFunction &MF) override;
+
+  llvm::StringRef getPassName() const override {
+    return "Xtensa instruction size reduction pass";
+  }
+
+private:
+  /// Reduces width of instructions in the specified basic block.
+  bool ReduceMBB(MachineBasicBlock &MBB);
+
+  /// Attempts to reduce MI, returns true on success.
+  bool ReduceMI(const MachineBasicBlock::instr_iterator &MII);
+};
+
+char XtensaSizeReduce::ID = 0;
+const XtensaInstrInfo *XtensaSizeReduce::XtensaII;
+
+bool XtensaSizeReduce::ReduceMI(const MachineBasicBlock::instr_iterator &MII) {
+  MachineInstr *MI = &*MII;
+  MachineBasicBlock &MBB = *MI->getParent();
+  unsigned Opcode = MI->getOpcode();
+
+  switch (Opcode) {
+  case Xtensa::L32I: {
+    MachineOperand Op0 = MI->getOperand(0);
+    MachineOperand Op1 = MI->getOperand(1);
+    MachineOperand Op2 = MI->getOperand(2);
+
+    int64_t Imm = Op2.getImm();
+    if (Imm >= 0 && Imm <= 60) {
+      // Replace L32I to L32I.N
+      DebugLoc dl = MI->getDebugLoc();
+      const MCInstrDesc &NewMCID = XtensaII->get(Xtensa::L32I_N);
+      MachineInstrBuilder MIB = BuildMI(MBB, MI, dl, NewMCID);
+      MIB.add(Op0);
+      MIB.add(Op1);
+      MIB.add(Op2);
+      // Transfer MI flags.
+      MIB.setMIFlags(MI->getFlags());
+      LLVM_DEBUG(dbgs() << "       to 16-bit: " << *MIB);
+      NumReduced++;
+      MBB.erase_instr(MI);
+      return true;
+    }
+  } break;
+
+  case Xtensa::S32I: {
+    MachineOperand Op0 = MI->getOperand(0);
+    MachineOperand Op1 = MI->getOperand(1);
+    MachineOperand Op2 = MI->getOperand(2);
+
+    int64_t Imm = Op2.getImm();
+    if (Imm >= 0 && Imm <= 60) {
+      // Replace S32I to S32I.N
+      DebugLoc dl = MI->getDebugLoc();
+      const MCInstrDesc &NewMCID = XtensaII->get(Xtensa::S32I_N);
+      MachineInstrBuilder MIB = BuildMI(MBB, MI, dl, NewMCID);
+      MIB.add(Op0);
+      MIB.add(Op1);
+      MIB.add(Op2);
+      // Transfer MI flags.
+      MIB.setMIFlags(MI->getFlags());
+      LLVM_DEBUG(dbgs() << "       to 16-bit: " << *MIB);
+      NumReduced++;
+      MBB.erase_instr(MI);
+      return true;
+    }
+
+  } break;
+
+  case Xtensa::MOVI: {
+    MachineOperand Op0 = MI->getOperand(0);
+    MachineOperand Op1 = MI->getOperand(1);
+
+    int64_t Imm = Op1.getImm();
+    if (Imm >= -32 && Imm <= 95) {
+      // Replace MOVI to MOVI.N
+      DebugLoc dl = MI->getDebugLoc();
+      const MCInstrDesc &NewMCID = XtensaII->get(Xtensa::MOVI_N);
+      MachineInstrBuilder MIB = BuildMI(MBB, MI, dl, NewMCID);
+      MIB.add(Op0);
+      MIB.add(Op1);
+      // Transfer MI flags.
+      MIB.setMIFlags(MI->getFlags());
+      LLVM_DEBUG(dbgs() << "       to 16-bit: " << *MIB);
+      NumReduced++;
+      MBB.erase_instr(MI);
+      return true;
+    }
+
+  } break;
+
+  case Xtensa::ADD: {
+    MachineOperand Op0 = MI->getOperand(0);
+    MachineOperand Op1 = MI->getOperand(1);
+    MachineOperand Op2 = MI->getOperand(2);
+
+    // Replace ADD to ADD.N
+    DebugLoc dl = MI->getDebugLoc();
+    const MCInstrDesc &NewMCID = XtensaII->get(Xtensa::ADD_N);
+    MachineInstrBuilder MIB = BuildMI(MBB, MI, dl, NewMCID);
+    MIB.add(Op0);
+    MIB.add(Op1);
+    MIB.add(Op2);
+    // Transfer MI flags.
+    MIB.setMIFlags(MI->getFlags());
+    LLVM_DEBUG(dbgs() << "       to 16-bit: " << *MIB);
+    NumReduced++;
+    MBB.erase_instr(MI);
+    return true;
+
+  } break;
+
+  case Xtensa::ADDI: {
+    MachineOperand Op0 = MI->getOperand(0);
+    MachineOperand Op1 = MI->getOperand(1);
+    MachineOperand Op2 = MI->getOperand(2);
+
+    int64_t Imm = Op2.getImm();
+    if ((Imm >= 1 && Imm <= 15) || (Imm == -1)) {
+      // Replace ADDI to ADDI.N
+      DebugLoc dl = MI->getDebugLoc();
+      const MCInstrDesc &NewMCID = XtensaII->get(Xtensa::ADDI_N);
+      MachineInstrBuilder MIB = BuildMI(MBB, MI, dl, NewMCID);
+      MIB.add(Op0);
+      MIB.add(Op1);
+      MIB.add(Op2);
+      // Transfer MI flags.
+      MIB.setMIFlags(MI->getFlags());
+      LLVM_DEBUG(dbgs() << "       to 16-bit: " << *MIB);
+      NumReduced++;
+      MBB.erase_instr(MI);
+      return true;
+    }
+  } break;
+
+  case Xtensa::OR: {
+    MachineOperand Op0 = MI->getOperand(0);
+    MachineOperand Op1 = MI->getOperand(1);
+    MachineOperand Op2 = MI->getOperand(2);
+
+    if (Op1.getReg() != Op2.getReg())
+      break;
+
+    // Replace OR R1, R2, R2 to MOV.N R1, R2
+    DebugLoc dl = MI->getDebugLoc();
+    const MCInstrDesc &NewMCID = XtensaII->get(Xtensa::MOV_N);
+    MachineInstrBuilder MIB = BuildMI(MBB, MI, dl, NewMCID);
+    MIB.add(Op0);
+    MIB.add(Op1);
+    // Transfer MI flags.
+    MIB.setMIFlags(MI->getFlags());
+    LLVM_DEBUG(dbgs() << "       to 16-bit: " << *MIB);
+    NumReduced++;
+    MBB.erase_instr(MI);
+    return true;
+  } break;
+
+  case Xtensa::RET: {
+    // Replace RET to RET.N
+    DebugLoc dl = MI->getDebugLoc();
+    const MCInstrDesc &NewMCID = XtensaII->get(Xtensa::RET_N);
+    MachineInstrBuilder MIB = BuildMI(MBB, MI, dl, NewMCID);
+    // Transfer MI flags.
+    MIB.setMIFlags(MI->getFlags());
+    LLVM_DEBUG(dbgs() << "       to 16-bit: " << *MIB);
+    NumReduced++;
+    MBB.erase_instr(MI);
+    return true;
+  } break;
+
+  case Xtensa::RETW: {
+    // Replace RETW to RETW.N
+    DebugLoc dl = MI->getDebugLoc();
+    const MCInstrDesc &NewMCID = XtensaII->get(Xtensa::RETW_N);
+    MachineInstrBuilder MIB = BuildMI(MBB, MI, dl, NewMCID);
+    // Transfer MI flags.
+    MIB.setMIFlags(MI->getFlags());
+    LLVM_DEBUG(dbgs() << "       to 16-bit: " << *MIB);
+    NumReduced++;
+    MBB.erase_instr(MI);
+    return true;
+  } break;
+
+  default:
+    break;
+  }
+
+  return false;
+}
+
+bool XtensaSizeReduce::ReduceMBB(MachineBasicBlock &MBB) {
+  bool Modified = false;
+  MachineBasicBlock::instr_iterator MII = MBB.instr_begin(),
+                                    E = MBB.instr_end();
+  MachineBasicBlock::instr_iterator NextMII;
+
+  // Iterate through the instructions in the basic block
+  for (; MII != E; MII = NextMII) {
+    NextMII = std::next(MII);
+    MachineInstr *MI = &*MII;
+
+    // Don't reduce bundled instructions or pseudo operations
+    if (MI->isBundle() || MI->isTransient())
+      continue;
+
+    // Try to reduce 24-bit instruction into 16-bit instruction
+    Modified |= ReduceMI(MII);
+  }
+
+  return Modified;
+}
+
+bool XtensaSizeReduce::runOnMachineFunction(MachineFunction &MF) {
+
+  Subtarget = &static_cast<const XtensaSubtarget &>(MF.getSubtarget());
+  XtensaII = static_cast<const XtensaInstrInfo *>(Subtarget->getInstrInfo());
+  bool Modified = false;
+
+  if (!Subtarget->hasDensity())
+    return Modified;
+
+  MachineFunction::iterator I = MF.begin(), E = MF.end();
+
+  for (; I != E; ++I)
+    Modified |= ReduceMBB(*I);
+  return Modified;
+}
+
+FunctionPass *llvm::createXtensaSizeReductionPass() {
+  return new XtensaSizeReduce();
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaSubtarget.cpp
@@ -0,0 +1,72 @@
+//===- XtensaSubtarget.cpp - Xtensa Subtarget Information -----------------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file implements the Xtensa specific subclass of TargetSubtargetInfo.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaSubtarget.h"
+#include "llvm/IR/GlobalValue.h"
+#include "llvm/Support/Debug.h"
+
+#define DEBUG_TYPE "xtensa-subtarget"
+
+#define GET_SUBTARGETINFO_TARGET_DESC
+#define GET_SUBTARGETINFO_CTOR
+#include "XtensaGenSubtargetInfo.inc"
+
+using namespace llvm;
+
+XtensaSubtarget &
+XtensaSubtarget::initializeSubtargetDependencies(StringRef CPU, StringRef FS) {
+  std::string CPUName = CPU;
+  if (CPUName.empty()) {
+    // set default cpu name
+    CPUName = "esp32";
+  }
+
+  HasDensity = false;
+  HasSingleFloat = false;
+  HasWindowed = false;
+  HasBoolean = false;
+  HasLoop = false;
+  HasSEXT = false;
+  HasNSA = false;
+  HasMul32 = false;
+  HasMul32High = false;
+  HasDiv32 = false;
+  HasMAC16 = false;
+  HasDFPAccel = false;
+  HasS32C1I = false;
+  HasTHREADPTR = false;
+  HasExtendedL32R = false;
+  HasATOMCTL = false;
+  HasMEMCTL = false;
+  HasDebug = false;
+  HasException = false;
+  HasHighPriInterrupts = false;
+  HasCoprocessor = false;
+  HasInterrupt = false;
+  HasRelocatableVector = false;
+  HasTimerInt = false;
+  HasPRID = false;
+  HasRegionProtection = false;
+  HasMiscSR = false;
+
+  // Parse features string.
+  ParseSubtargetFeatures(CPUName, FS);
+  return *this;
+}
+
+XtensaSubtarget::XtensaSubtarget(const Triple &TT, const std::string &CPU,
+                                 const std::string &FS, const TargetMachine &TM)
+    : XtensaGenSubtargetInfo(TT, CPU, FS), TargetTriple(TT),
+      InstrInfo(initializeSubtargetDependencies(CPU, FS)), TLInfo(TM, *this),
+      TSInfo(), FrameLowering() {}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaSubtarget.h
@@ -0,0 +1,198 @@
+//===-- XtensaSubtarget.h - Define Subtarget for the Xtensa ----*- C++ -*--===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file declares the Xtensa specific subclass of TargetSubtargetInfo.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSASUBTARGET_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSASUBTARGET_H
+
+#include "XtensaFrameLowering.h"
+#include "XtensaISelLowering.h"
+#include "XtensaInstrInfo.h"
+#include "XtensaRegisterInfo.h"
+#include "llvm/CodeGen/SelectionDAGTargetInfo.h"
+#include "llvm/CodeGen/TargetSubtargetInfo.h"
+#include "llvm/IR/DataLayout.h"
+#include "llvm/Target/TargetMachine.h"
+
+#define GET_SUBTARGETINFO_HEADER
+#include "XtensaGenSubtargetInfo.inc"
+
+namespace llvm {
+class StringRef;
+
+class XtensaSubtarget : public XtensaGenSubtargetInfo {
+private:
+  Triple TargetTriple;
+  XtensaInstrInfo InstrInfo;
+  XtensaTargetLowering TLInfo;
+  SelectionDAGTargetInfo TSInfo;
+  XtensaFrameLowering FrameLowering;
+
+  // Enabled Xtensa Density extension
+  bool HasDensity;
+
+  // Enabled Xtensa Single FP instructions
+  bool HasSingleFloat;
+
+  // Enabled Xtensa Windowed Register option
+  bool HasWindowed;
+
+  // Enabled Xtensa Boolean extension
+  bool HasBoolean;
+
+  // Enabled Xtensa Loop extension
+  bool HasLoop;
+
+  // Enable Xtensa Sign Extend option
+  bool HasSEXT;
+
+  // Enable Xtensa NSA option
+  bool HasNSA;
+
+  // Enable Xtensa Mul32 option
+  bool HasMul32;
+
+  // Enable Xtensa Mul32High option
+  bool HasMul32High;
+
+  // Enable Xtensa Div32 option
+  bool HasDiv32;
+
+  // Enabled Xtensa MAC16 instructions
+  bool HasMAC16;
+
+  // Enable Xtensa Xtensa Double Precision FP acceleration
+  bool HasDFPAccel;
+
+  // Enable Xtensa S32C1I option
+  bool HasS32C1I;
+
+  // Enable Xtensa THREADPTR option
+  bool HasTHREADPTR;
+
+  // Enable Xtensa Extended L32R option
+  bool HasExtendedL32R;
+
+  // Enable Xtensa ATOMCTL option
+  bool HasATOMCTL;
+
+  // Enable Xtensa ATOMCTL option
+  bool HasMEMCTL;
+
+  // Enable Xtensa Debug option
+  bool HasDebug;
+
+  // Enable Xtensa Exceptions option
+  bool HasException;
+
+  // Enable Xtensa High Priority Interrupt option
+  bool HasHighPriInterrupts;
+
+  // Enable Xtensa Coprocessor option
+  bool HasCoprocessor;
+
+  // Enable Xtensa Interrupt option
+  bool HasInterrupt;
+
+  // Enable Xtensa Relocatable Vector option
+  bool HasRelocatableVector;
+
+  // Enable Xtensa Timer Interrupt option
+  bool HasTimerInt;
+
+  // Enable Xtensa Processor ID option
+  bool HasPRID;
+
+  // Enable Xtensa Region Protection option
+  bool HasRegionProtection;
+
+  // Enable Xtensa Miscellaneous Special Reigsiters option
+  bool HasMiscSR;
+
+  XtensaSubtarget &initializeSubtargetDependencies(StringRef CPU, StringRef FS);
+
+public:
+  XtensaSubtarget(const Triple &TT, const std::string &CPU,
+                  const std::string &FS, const TargetMachine &TM);
+
+  const TargetFrameLowering *getFrameLowering() const { return &FrameLowering; }
+  const XtensaInstrInfo *getInstrInfo() const { return &InstrInfo; }
+  const XtensaRegisterInfo *getRegisterInfo() const {
+    return &InstrInfo.getRegisterInfo();
+  }
+
+  const XtensaTargetLowering *getTargetLowering() const { return &TLInfo; }
+  const SelectionDAGTargetInfo *getSelectionDAGInfo() const { return &TSInfo; }
+
+  bool isWinABI() const { return hasWindowed(); }
+
+  bool hasDensity() const { return HasDensity; }
+
+  bool hasSingleFloat() const { return HasSingleFloat; }
+
+  bool hasWindowed() const { return HasWindowed; }
+
+  bool hasBoolean() const { return HasBoolean; }
+
+  bool hasLoop() const { return HasLoop; }
+
+  bool hasSEXT() const { return HasSEXT; }
+
+  bool hasNSA() const { return HasNSA; }
+
+  bool hasMul32() const { return HasMul32; }
+
+  bool hasMul32High() const { return HasMul32High; }
+
+  bool hasDiv32() const { return HasDiv32; }
+
+  bool hasMAC16() const { return HasMAC16; }
+
+  bool hasDFPAccel() const { return HasDFPAccel; }
+
+  bool hasS32C1I() const { return HasS32C1I; }
+
+  bool hasTHREADPTR() const { return HasTHREADPTR; }
+
+  bool hasExtendedL32R() const { return HasExtendedL32R; }
+
+  bool hasATOMCTL() const { return HasATOMCTL; }
+
+  bool hasMEMCTL() const { return HasMEMCTL; }
+
+  bool hasDebug() const { return HasDebug; }
+
+  bool hasException() const { return HasException; }
+
+  bool hasHighPriInterrupts() const { return HasHighPriInterrupts; }
+
+  bool hasCoprocessor() const { return HasCoprocessor; }
+
+  bool hasInterrupt() const { return HasInterrupt; }
+
+  bool hasRelocatableVector() const { return HasRelocatableVector; }
+
+  bool hasTimerInt() const { return HasTimerInt; }
+
+  bool hasPRID() const { return HasPRID; }
+
+  bool hasRegionProtection() const { return HasRegionProtection; }
+
+  bool hasMiscSR() const { return HasMiscSR; }
+
+  // Automatically generated by tblgen.
+  void ParseSubtargetFeatures(StringRef CPU, StringRef FS);
+};
+} // end namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSASUBTARGET_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaTargetMachine.cpp
@@ -0,0 +1,105 @@
+//===- XtensaTargetMachine.cpp - Define TargetMachine for Xtensa ----------===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// Implements the info about Xtensa target spec.
+//
+//===----------------------------------------------------------------------===//
+
+#include "XtensaTargetMachine.h"
+#include "llvm/CodeGen/Passes.h"
+#include "llvm/CodeGen/TargetLoweringObjectFileImpl.h"
+#include "llvm/CodeGen/TargetPassConfig.h"
+#include "llvm/IR/LegacyPassManager.h"
+#include "llvm/Support/TargetRegistry.h"
+#include "llvm/Transforms/IPO/PassManagerBuilder.h"
+#include "llvm/Transforms/Scalar.h"
+
+using namespace llvm;
+
+extern "C" LLVM_EXTERNAL_VISIBILITY void LLVMInitializeXtensaTarget() {
+  // Register the target.
+  RegisterTargetMachine<XtensaTargetMachine> A(TheXtensaTarget);
+}
+
+static std::string computeDataLayout(const Triple &TT, StringRef CPU,
+                                     const TargetOptions &Options,
+                                     bool isLittle) {
+  std::string Ret = "e-m:e-p:32:32-i8:8:32-i16:16:32-i64:64-n32";
+
+  return Ret;
+}
+
+static Reloc::Model getEffectiveRelocModel(bool JIT,
+                                           Optional<Reloc::Model> RM) {
+  if (!RM.hasValue() || JIT)
+    return Reloc::Static;
+  return *RM;
+}
+
+XtensaTargetMachine::XtensaTargetMachine(const Target &T, const Triple &TT,
+                                         StringRef CPU, StringRef FS,
+                                         const TargetOptions &Options,
+                                         Optional<Reloc::Model> RM,
+                                         Optional<CodeModel::Model> CM,
+                                         CodeGenOpt::Level OL, bool JIT,
+                                         bool isLittle)
+    : LLVMTargetMachine(T, computeDataLayout(TT, CPU, Options, isLittle), TT,
+                        CPU, FS, Options, getEffectiveRelocModel(JIT, RM),
+                        getEffectiveCodeModel(CM, CodeModel::Small), OL),
+      TLOF(std::make_unique<TargetLoweringObjectFileELF>()),
+      Subtarget(TT, CPU, FS, *this) {
+  initAsmInfo();
+}
+
+XtensaTargetMachine::XtensaTargetMachine(const Target &T, const Triple &TT,
+                                         StringRef CPU, StringRef FS,
+                                         const TargetOptions &Options,
+                                         Optional<Reloc::Model> RM,
+                                         Optional<CodeModel::Model> CM,
+                                         CodeGenOpt::Level OL, bool JIT)
+    : XtensaTargetMachine(T, TT, CPU, FS, Options, RM, CM, OL, JIT, true) {}
+
+const XtensaSubtarget *
+XtensaTargetMachine::getSubtargetImpl(const Function &F) const {
+  return &Subtarget;
+}
+
+namespace {
+/// Xtensa Code Generator Pass Configuration Options.
+class XtensaPassConfig : public TargetPassConfig {
+public:
+  XtensaPassConfig(XtensaTargetMachine &TM, PassManagerBase &PM)
+      : TargetPassConfig(TM, PM) {}
+
+  XtensaTargetMachine &getXtensaTargetMachine() const {
+    return getTM<XtensaTargetMachine>();
+  }
+
+  void addIRPasses() override;
+  bool addInstSelector() override;
+  void addPreEmitPass() override;
+};
+} // end anonymous namespace
+
+bool XtensaPassConfig::addInstSelector() {
+  addPass(createXtensaISelDag(getXtensaTargetMachine(), getOptLevel()));
+  return false;
+}
+
+void XtensaPassConfig::addIRPasses() { addPass(createAtomicExpandPass()); }
+
+void XtensaPassConfig::addPreEmitPass() {
+  addPass(createXtensaSizeReductionPass());
+  addPass(&BranchRelaxationPassID);
+}
+
+TargetPassConfig *XtensaTargetMachine::createPassConfig(PassManagerBase &PM) {
+  return new XtensaPassConfig(*this, PM);
+}
--- /dev/null
+++ llvm-10.0.1.src~patched/lib/Target/Xtensa/XtensaTargetMachine.h
@@ -0,0 +1,55 @@
+//===-- XtensaTargetMachine.h - Define TargetMachine for Xtensa -*- C++ -*-===//
+//
+//                     The LLVM Compiler Infrastructure
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+//
+// This file declares the Xtensa specific subclass of TargetMachine.
+//
+//===----------------------------------------------------------------------===//
+
+#ifndef LLVM_LIB_TARGET_XTENSA_XTENSATARGETMACHINE_H
+#define LLVM_LIB_TARGET_XTENSA_XTENSATARGETMACHINE_H
+
+#include "XtensaSubtarget.h"
+#include "llvm/Target/TargetMachine.h"
+
+namespace llvm {
+
+class TargetFrameLowering;
+
+extern Target TheXtensaTarget;
+
+class XtensaTargetMachine : public LLVMTargetMachine {
+  std::unique_ptr<TargetLoweringObjectFile> TLOF;
+
+public:
+  XtensaTargetMachine(const Target &T, const Triple &TT, StringRef CPU,
+                      StringRef FS, const TargetOptions &Options,
+                      Optional<Reloc::Model> RM, Optional<CodeModel::Model> CM,
+                      CodeGenOpt::Level OL, bool JIT, bool isLittle);
+
+  XtensaTargetMachine(const Target &T, const Triple &TT, StringRef CPU,
+                      StringRef FS, const TargetOptions &Options,
+                      Optional<Reloc::Model> RM, Optional<CodeModel::Model> CM,
+                      CodeGenOpt::Level OL, bool JIT);
+
+  // Override TargetMachine.
+  const XtensaSubtarget *getSubtargetImpl() const { return &Subtarget; }
+  const XtensaSubtarget *getSubtargetImpl(const Function &F) const override;
+  // Override LLVMTargetMachine
+  TargetPassConfig *createPassConfig(PassManagerBase &PM) override;
+  TargetLoweringObjectFile *getObjFileLowering() const override {
+    return TLOF.get();
+  }
+
+protected:
+  XtensaSubtarget Subtarget;
+};
+} // end namespace llvm
+
+#endif /* LLVM_LIB_TARGET_XTENSA_XTENSATARGETMACHINE_H */
--- /dev/null
+++ llvm-10.0.1.src~patched/test/CodeGen/Xtensa/funnel-shift.ll
@@ -0,0 +1,22 @@
+; RUN: llc -O1 -mtriple=xtensa -mcpu=esp32 %s -o - | FileCheck %s
+
+define dso_local i32 @test_fshr(i32 %value, i32 %shift) nounwind {
+; CHECK-LABEL: @test_fshr
+; CHECK: ssr a3
+; CHECK: src a2, a2, a2
+entry:
+  %0 = tail call i32 @llvm.fshr.i32(i32 %value, i32 %value, i32 %shift)
+  ret i32 %0
+}
+
+define dso_local i32 @test_fshl(i32 %value, i32 %shift) nounwind {
+; CHECK-LABEL: @test_fshl
+; CHECK: ssl a3
+; CHECK: src a2, a2, a2
+entry:
+  %0 = tail call i32 @llvm.fshl.i32(i32 %value, i32 %value, i32 %shift)
+  ret i32 %0
+}
+
+declare i32 @llvm.fshr.i32(i32, i32, i32) nounwind
+declare i32 @llvm.fshl.i32(i32, i32, i32) nounwind
--- /dev/null
+++ llvm-10.0.1.src~patched/test/CodeGen/Xtensa/lit.local.cfg
@@ -0,0 +1,2 @@
+if not 'Xtensa' in config.root.targets:
+    config.unsupported = True
--- /dev/null
+++ llvm-10.0.1.src~patched/test/CodeGen/Xtensa/mac16_intrinsics.ll
@@ -0,0 +1,319 @@
+; RUN: llc -O1 -mtriple=xtensa -mcpu=esp32 %s -o - | FileCheck %s
+
+define void @test_xtensa_umul(i32 %a, i32 %b) nounwind {
+; CHECK-LABEL: test_xtensa_umul
+; CHECK: umul.aa.ll	a2, a3
+  call void @llvm.xtensa.umul.aa.ll(i32 %a, i32 %b)
+; CHECK: umul.aa.lh	a2, a3
+  call void @llvm.xtensa.umul.aa.lh(i32 %a, i32 %b)
+; CHECK: umul.aa.hl	a2, a3
+  call void @llvm.xtensa.umul.aa.hl(i32 %a, i32 %b)
+; CHECK: umul.aa.hh	a2, a3
+  call void @llvm.xtensa.umul.aa.hh(i32 %a, i32 %b)
+  ret void
+}
+
+define void @test_xtensa_mul(i32 %a, i32 %b) nounwind {
+; CHECK-LABEL: test_xtensa_mul
+; CHECK: mul.aa.ll	a2, a3
+  call void @llvm.xtensa.mul.aa.ll(i32 %a, i32 %b)
+; CHECK: mul.aa.lh	a2, a3
+  call void @llvm.xtensa.mul.aa.lh(i32 %a, i32 %b)
+; CHECK: mul.aa.hl	a2, a3
+  call void @llvm.xtensa.mul.aa.hl(i32 %a, i32 %b)
+; CHECK: mul.aa.hh	a2, a3
+  call void @llvm.xtensa.mul.aa.hh(i32 %a, i32 %b)
+; CHECK: mul.ad.ll	a2, m2
+  call void @llvm.xtensa.mul.ad.ll(i32 %a, i32 2)
+; CHECK: mul.ad.lh	a2, m2
+  call void @llvm.xtensa.mul.ad.lh(i32 %a, i32 2)
+; CHECK: mul.ad.hl	a2, m2
+  call void @llvm.xtensa.mul.ad.hl(i32 %a, i32 2)
+; CHECK: mul.ad.hh	a2, m2
+  call void @llvm.xtensa.mul.ad.hh(i32 %a, i32 2)
+; CHECK: mul.da.ll	m1, a3
+  call void @llvm.xtensa.mul.da.ll(i32 1, i32 %b)
+; CHECK: mul.da.lh	m1, a3
+  call void @llvm.xtensa.mul.da.lh(i32 1, i32 %b)
+; CHECK: mul.da.hl	m1, a3
+  call void @llvm.xtensa.mul.da.hl(i32 1, i32 %b)
+; CHECK: mul.da.hh	m1, a3
+  call void @llvm.xtensa.mul.da.hh(i32 1, i32 %b)
+; CHECK: mul.dd.ll	m1, m2
+  call void @llvm.xtensa.mul.dd.ll(i32 1, i32 2)
+; CHECK: mul.dd.lh	m1, m2
+  call void @llvm.xtensa.mul.dd.lh(i32 1, i32 2)
+; CHECK: mul.dd.hl	m1, m2
+  call void @llvm.xtensa.mul.dd.hl(i32 1, i32 2)
+; CHECK: mul.dd.hh	m1, m2
+  call void @llvm.xtensa.mul.dd.hh(i32 1, i32 2)
+  ret void
+}
+
+define void @test_xtensa_mula(i32 %a, i32 %b) nounwind {
+; CHECK-LABEL: test_xtensa_mula
+; CHECK: mula.aa.ll	a2, a3
+  call void @llvm.xtensa.mula.aa.ll(i32 %a, i32 %b)
+; CHECK: mula.aa.lh	a2, a3
+  call void @llvm.xtensa.mula.aa.lh(i32 %a, i32 %b)
+; CHECK: mula.aa.hl	a2, a3
+  call void @llvm.xtensa.mula.aa.hl(i32 %a, i32 %b)
+; CHECK: mula.aa.hh	a2, a3
+  call void @llvm.xtensa.mula.aa.hh(i32 %a, i32 %b)
+; CHECK: mula.ad.ll	a2, m2
+  call void @llvm.xtensa.mula.ad.ll(i32 %a, i32 2)
+; CHECK: mula.ad.lh	a2, m2
+  call void @llvm.xtensa.mula.ad.lh(i32 %a, i32 2)
+; CHECK: mula.ad.hl	a2, m2
+  call void @llvm.xtensa.mula.ad.hl(i32 %a, i32 2)
+; CHECK: mula.ad.hh	a2, m2
+  call void @llvm.xtensa.mula.ad.hh(i32 %a, i32 2)
+; CHECK: mula.da.ll	m1, a3
+  call void @llvm.xtensa.mula.da.ll(i32 1, i32 %b)
+; CHECK: mula.da.lh	m1, a3
+  call void @llvm.xtensa.mula.da.lh(i32 1, i32 %b)
+; CHECK: mula.da.hl	m1, a3
+  call void @llvm.xtensa.mula.da.hl(i32 1, i32 %b)
+; CHECK: mula.da.hh	m1, a3
+  call void @llvm.xtensa.mula.da.hh(i32 1, i32 %b)
+; CHECK: mula.dd.ll	m1, m2
+  call void @llvm.xtensa.mula.dd.ll(i32 1, i32 2)
+; CHECK: mula.dd.lh	m1, m2
+  call void @llvm.xtensa.mula.dd.lh(i32 1, i32 2)
+; CHECK: mula.dd.hl	m1, m2
+  call void @llvm.xtensa.mula.dd.hl(i32 1, i32 2)
+; CHECK: mula.dd.hh	m1, m2
+  call void @llvm.xtensa.mula.dd.hh(i32 1, i32 2)
+  ret void
+}
+
+define void @test_xtensa_muls(i32 %a, i32 %b) nounwind {
+; CHECK-LABEL: test_xtensa_muls
+; CHECK: muls.aa.ll	a2, a3
+  call void @llvm.xtensa.muls.aa.ll(i32 %a, i32 %b)
+; CHECK: muls.aa.lh	a2, a3
+  call void @llvm.xtensa.muls.aa.lh(i32 %a, i32 %b)
+; CHECK: muls.aa.hl	a2, a3
+  call void @llvm.xtensa.muls.aa.hl(i32 %a, i32 %b)
+; CHECK: muls.aa.hh	a2, a3
+  call void @llvm.xtensa.muls.aa.hh(i32 %a, i32 %b)
+; CHECK: muls.ad.ll	a2, m2
+  call void @llvm.xtensa.muls.ad.ll(i32 %a, i32 2)
+; CHECK: muls.ad.lh	a2, m2
+  call void @llvm.xtensa.muls.ad.lh(i32 %a, i32 2)
+; CHECK: muls.ad.hl	a2, m2
+  call void @llvm.xtensa.muls.ad.hl(i32 %a, i32 2)
+; CHECK: muls.ad.hh	a2, m2
+  call void @llvm.xtensa.muls.ad.hh(i32 %a, i32 2)
+; CHECK: muls.da.ll	m1, a3
+  call void @llvm.xtensa.muls.da.ll(i32 1, i32 %b)
+; CHECK: muls.da.lh	m1, a3
+  call void @llvm.xtensa.muls.da.lh(i32 1, i32 %b)
+; CHECK: muls.da.hl	m1, a3
+  call void @llvm.xtensa.muls.da.hl(i32 1, i32 %b)
+; CHECK: muls.da.hh	m1, a3
+  call void @llvm.xtensa.muls.da.hh(i32 1, i32 %b)
+; CHECK: muls.dd.ll	m1, m2
+  call void @llvm.xtensa.muls.dd.ll(i32 1, i32 2)
+; CHECK: muls.dd.lh	m1, m2
+  call void @llvm.xtensa.muls.dd.lh(i32 1, i32 2)
+; CHECK: muls.dd.hl	m1, m2
+  call void @llvm.xtensa.muls.dd.hl(i32 1, i32 2)
+; CHECK: muls.dd.hh	m1, m2
+  call void @llvm.xtensa.muls.dd.hh(i32 1, i32 2)
+  ret void
+}
+
+define void @test_xtensa_mula_ld(i32 %pa.coerce, i32 %b) nounwind {
+; CHECK-LABEL: test_xtensa_mula_ld
+entry:
+  %0 = inttoptr i32 %pa.coerce to i8*
+; CHECK: 	mula.da.ll.lddec	 m1, a{{[0-9]+}}, m0, a3
+  call void @llvm.xtensa.mula.da.ll.lddec(i32 1, i8* %0, i32 0, i32 %b)
+; CHECK: 	mula.da.lh.lddec	 m1, a{{[0-9]+}}, m0, a3
+  call void @llvm.xtensa.mula.da.lh.lddec(i32 1, i8* %0, i32 0, i32 %b)
+; CHECK: 	mula.da.hl.lddec	 m1, a{{[0-9]+}}, m0, a3
+  call void @llvm.xtensa.mula.da.hl.lddec(i32 1, i8* %0, i32 0, i32 %b)
+; CHECK: 	mula.da.hh.lddec	 m1, a{{[0-9]+}}, m0, a3
+  call void @llvm.xtensa.mula.da.hh.lddec(i32 1, i8* %0, i32 0, i32 %b)
+; CHECK: 	mula.dd.ll.lddec	 m1, a{{[0-9]+}}, m0, m2
+  call void @llvm.xtensa.mula.dd.ll.lddec(i32 1, i8* %0, i32 0, i32 2)
+; CHECK: 	mula.dd.lh.lddec	 m1, a{{[0-9]+}}, m0, m2
+  call void @llvm.xtensa.mula.dd.lh.lddec(i32 1, i8* %0, i32 0, i32 2)
+; CHECK: 	mula.dd.hl.lddec	 m1, a{{[0-9]+}}, m0, m2
+  call void @llvm.xtensa.mula.dd.hl.lddec(i32 1, i8* %0, i32 0, i32 2)
+; CHECK: 	mula.dd.hh.lddec	 m1, a{{[0-9]+}}, m0, m2
+  call void @llvm.xtensa.mula.dd.hh.lddec(i32 1, i8* %0, i32 0, i32 2)
+; CHECK: 	mula.da.ll.ldinc	 m1, a{{[0-9]+}}, m0, a3
+  call void @llvm.xtensa.mula.da.ll.ldinc(i32 1, i8* %0, i32 0, i32 %b)
+; CHECK: 	mula.da.lh.ldinc	 m1, a{{[0-9]+}}, m0, a3
+  call void @llvm.xtensa.mula.da.lh.ldinc(i32 1, i8* %0, i32 0, i32 %b)
+; CHECK: 	mula.da.hl.ldinc	 m1, a{{[0-9]+}}, m0, a3
+  call void @llvm.xtensa.mula.da.hl.ldinc(i32 1, i8* %0, i32 0, i32 %b)
+; CHECK: 	mula.da.hh.ldinc	 m1, a{{[0-9]+}}, m0, a3
+  call void @llvm.xtensa.mula.da.hh.ldinc(i32 1, i8* %0, i32 0, i32 %b)
+; CHECK: 	mula.dd.ll.ldinc	 m1, a{{[0-9]+}}, m0, m2
+  call void @llvm.xtensa.mula.dd.ll.ldinc(i32 1, i8* %0, i32 0, i32 2)
+; CHECK: 	mula.dd.lh.ldinc	 m1, a{{[0-9]+}}, m0, m2
+  call void @llvm.xtensa.mula.dd.lh.ldinc(i32 1, i8* %0, i32 0, i32 2)
+; CHECK: 	mula.dd.hl.ldinc	 m1, a{{[0-9]+}}, m0, m2
+  call void @llvm.xtensa.mula.dd.hl.ldinc(i32 1, i8* %0, i32 0, i32 2)
+; CHECK:	mula.dd.hh.ldinc	 m1, a{{[0-9]+}}, m0, m2
+  call void @llvm.xtensa.mula.dd.hh.ldinc(i32 1, i8* %0, i32 0, i32 2)
+  ret void
+}
+
+define void @test_xtensa_ld(i32 %pa.coerce) nounwind {
+; CHECK-LABEL: test_xtensa_ld
+entry:
+  %0 = inttoptr i32 %pa.coerce to i8*
+; CHECK:	lddec	 m0, a{{[0-9]+}}
+  call void @llvm.xtensa.lddec(i32 0, i8* %0)
+; CHECK:	ldinc	 m0, a{{[0-9]+}}
+  call void @llvm.xtensa.ldinc(i32 0, i8* %0)
+  ret void
+}
+
+define void @test_xtensa_wsr(i32 %a) {
+; CHECK-LABEL: test_xtensa_wsr
+; CHECK: wsr	a2, acclo
+  call void @llvm.xtensa.wsr.acclo(i32 %a)
+; CHECK: wsr	a2, acchi
+  call void @llvm.xtensa.wsr.acchi(i32 %a)
+; CHECK: wsr	a2, m0
+  call void @llvm.xtensa.wsr.m0(i32 %a)
+; CHECK: wsr	a2, m1
+  call void @llvm.xtensa.wsr.m1(i32 %a)
+; CHECK: wsr	a2, m2
+  call void @llvm.xtensa.wsr.m2(i32 %a)
+; CHECK: wsr	a2, m3
+  call void @llvm.xtensa.wsr.m3(i32 %a)
+  ret void
+}
+
+define void @test_xtensa_xsr(i32 %a.coerce) {
+; CHECK-LABEL: test_xtensa_xsr
+entry:
+  %0 = inttoptr i32 %a.coerce to i8*
+; CHECK: xsr	a{{[0-9]+}}, acclo
+  call void @llvm.xtensa.xsr.acclo(i8* %0)
+; CHECK: xsr	a{{[0-9]+}}, acchi
+  call void @llvm.xtensa.xsr.acchi(i8* %0)
+; CHECK: xsr	a{{[0-9]+}}, m0
+  call void @llvm.xtensa.xsr.m0(i8* %0)
+; CHECK: xsr	a{{[0-9]+}}, m1
+  call void @llvm.xtensa.xsr.m1(i8* %0)
+; CHECK: xsr	a{{[0-9]+}}, m2
+  call void @llvm.xtensa.xsr.m2(i8* %0)
+; CHECK: xsr	a{{[0-9]+}}, m3
+  call void @llvm.xtensa.xsr.m3(i8* %0)
+  ret void
+}
+
+define void @test_xtensa_rsr() {
+; CHECK-LABEL: test_xtensa_rsr
+entry:
+; CHECK: rsr	a{{[0-9]+}}, acclo
+  %0 = call i32 @llvm.xtensa.rsr.acclo()
+; CHECK: rsr	a{{[0-9]+}}, acchi
+  %1 = call i32 @llvm.xtensa.rsr.acchi()
+; CHECK: rsr	a{{[0-9]+}}, m0
+  %2 = call i32 @llvm.xtensa.rsr.m0()
+; CHECK: rsr	a{{[0-9]+}}, m1
+  %3 = call i32 @llvm.xtensa.rsr.m1()
+; CHECK: rsr	a{{[0-9]+}}, m2
+  %4 = call i32 @llvm.xtensa.rsr.m2()
+; CHECK: rsr	a{{[0-9]+}}, m3
+  %5 = call i32 @llvm.xtensa.rsr.m3()
+  ret void
+}
+
+declare void @llvm.xtensa.umul.aa.ll(i32, i32) nounwind
+declare void @llvm.xtensa.umul.aa.lh(i32, i32) nounwind
+declare void @llvm.xtensa.umul.aa.hl(i32, i32) nounwind
+declare void @llvm.xtensa.umul.aa.hh(i32, i32) nounwind
+declare void @llvm.xtensa.mul.aa.ll(i32, i32) nounwind
+declare void @llvm.xtensa.mul.aa.lh(i32, i32) nounwind
+declare void @llvm.xtensa.mul.aa.hl(i32, i32) nounwind
+declare void @llvm.xtensa.mul.aa.hh(i32, i32) nounwind
+declare void @llvm.xtensa.mul.ad.ll(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.mul.ad.lh(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.mul.ad.hl(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.mul.ad.hh(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.mul.da.ll(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mul.da.lh(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mul.da.hl(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mul.da.hh(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mul.dd.ll(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mul.dd.lh(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mul.dd.hl(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mul.dd.hh(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.aa.ll(i32, i32) nounwind
+declare void @llvm.xtensa.mula.aa.lh(i32, i32) nounwind
+declare void @llvm.xtensa.mula.aa.hl(i32, i32) nounwind
+declare void @llvm.xtensa.mula.aa.hh(i32, i32) nounwind
+declare void @llvm.xtensa.mula.ad.ll(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.ad.lh(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.ad.hl(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.ad.hh(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.da.ll(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.da.lh(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.da.hl(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.da.hh(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.dd.ll(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.dd.lh(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.dd.hl(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.dd.hh(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.muls.aa.ll(i32, i32) nounwind
+declare void @llvm.xtensa.muls.aa.lh(i32, i32) nounwind
+declare void @llvm.xtensa.muls.aa.hl(i32, i32) nounwind
+declare void @llvm.xtensa.muls.aa.hh(i32, i32) nounwind
+declare void @llvm.xtensa.muls.ad.ll(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.muls.ad.lh(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.muls.ad.hl(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.muls.ad.hh(i32, i32 immarg) nounwind
+declare void @llvm.xtensa.muls.da.ll(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.muls.da.lh(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.muls.da.hl(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.muls.da.hh(i32 immarg, i32) nounwind
+declare void @llvm.xtensa.muls.dd.ll(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.muls.dd.lh(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.muls.dd.hl(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.muls.dd.hh(i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.da.ll.lddec(i32 immarg, i8*, i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.da.lh.lddec(i32 immarg, i8*, i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.da.hl.lddec(i32 immarg, i8*, i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.da.hh.lddec(i32 immarg, i8*, i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.dd.ll.lddec(i32 immarg, i8*, i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.dd.lh.lddec(i32 immarg, i8*, i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.dd.hl.lddec(i32 immarg, i8*, i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.dd.hh.lddec(i32 immarg, i8*, i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.da.ll.ldinc(i32 immarg, i8*, i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.da.lh.ldinc(i32 immarg, i8*, i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.da.hl.ldinc(i32 immarg, i8*, i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.da.hh.ldinc(i32 immarg, i8*, i32 immarg, i32) nounwind
+declare void @llvm.xtensa.mula.dd.ll.ldinc(i32 immarg, i8*, i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.dd.lh.ldinc(i32 immarg, i8*, i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.dd.hl.ldinc(i32 immarg, i8*, i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.mula.dd.hh.ldinc(i32 immarg, i8*, i32 immarg, i32 immarg) nounwind
+declare void @llvm.xtensa.lddec(i32 immarg, i8*) nounwind
+declare void @llvm.xtensa.ldinc(i32 immarg, i8*) nounwind
+declare i32 @llvm.xtensa.rsr.acclo() nounwind
+declare i32 @llvm.xtensa.rsr.acchi() nounwind
+declare i32 @llvm.xtensa.rsr.m0() nounwind
+declare i32 @llvm.xtensa.rsr.m1() nounwind
+declare i32 @llvm.xtensa.rsr.m2() nounwind
+declare i32 @llvm.xtensa.rsr.m3() nounwind
+declare void @llvm.xtensa.xsr.acclo(i8*) nounwind
+declare void @llvm.xtensa.xsr.acchi(i8*) nounwind
+declare void @llvm.xtensa.xsr.m0(i8*) nounwind
+declare void @llvm.xtensa.xsr.m1(i8*) nounwind
+declare void @llvm.xtensa.xsr.m2(i8*) nounwind
+declare void @llvm.xtensa.xsr.m3(i8*) nounwind
+declare void @llvm.xtensa.wsr.acclo(i32) nounwind
+declare void @llvm.xtensa.wsr.acchi(i32) nounwind
+declare void @llvm.xtensa.wsr.m0(i32) nounwind
+declare void @llvm.xtensa.wsr.m1(i32) nounwind
+declare void @llvm.xtensa.wsr.m2(i32) nounwind
+declare void @llvm.xtensa.wsr.m3(i32) nounwind
+
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/elf-header.s
@@ -0,0 +1,31 @@
+# RUN: llvm-mc %s -filetype=obj -triple=xtensa | llvm-readobj -h \
+# RUN:     | FileCheck -check-prefix=Xtensa %s
+
+# Xtensa: Format: ELF32-Xtensa
+# Xtensa: Arch: xtensa
+# Xtensa: AddressSize: 32bit
+# Xtensa: ElfHeader {
+# Xtensa:   Ident {
+# Xtensa:     Magic: (7F 45 4C 46)
+# Xtensa:     Class: 32-bit (0x1)
+# Xtensa:     DataEncoding: LittleEndian (0x1)
+# Xtensa:     FileVersion: 1
+# Xtensa:     OS/ABI: SystemV (0x0)
+# Xtensa:     ABIVersion: 0
+# Xtensa:     Unused: (00 00 00 00 00 00 00)
+# Xtensa:   }
+# Xtensa:   Type: Relocatable (0x1)
+# Xtensa:   Machine: EM_XTENSA (0x5E)
+# Xtensa:   Version: 1
+# Xtensa:   Entry: 0x0
+# Xtensa:   ProgramHeaderOffset: 0x0
+# Xtensa:   SectionHeaderOffset: 0x5C
+# Xtensa:   Flags [ (0x0)
+# Xtensa:   ]
+# Xtensa:   HeaderSize: 52
+# Xtensa:   ProgramHeaderEntrySize: 0
+# Xtensa:   ProgramHeaderCount: 0
+# Xtensa:   SectionHeaderEntrySize: 40
+# Xtensa:   SectionHeaderCount: 4
+# Xtensa:   StringTableSectionIndex: 1
+# Xtensa: }
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/fixups-diagnostics.s
@@ -0,0 +1,14 @@
+# RUN: not llvm-mc -triple xtensa -filetype obj < %s -o /dev/null 2>&1 | FileCheck %s
+
+  .align 4
+
+  beq a0, a1, LBL1 # CHECK: :[[@LINE]]:3: error: fixup value out of range
+LBL0:
+  beqz a0, LBL2 # CHECK: :[[@LINE]]:3: error: fixup value out of range
+
+  call0 LBL0 # CHECK: :[[@LINE]]:3: error: fixup value must be 4-byte aligned
+
+  .space 1<<8
+LBL1:
+  .space 1<<12
+LBL2:
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/fixups.s
@@ -0,0 +1,54 @@
+# RUN: llvm-mc -triple xtensa < %s -show-encoding \
+# RUN:     | FileCheck -check-prefix=CHECK-FIXUP %s
+# RUN: llvm-mc -filetype=obj -triple xtensa < %s \
+# RUN:     | llvm-objdump -d - | FileCheck -check-prefix=CHECK-INSTR %s
+
+
+# Checks that fixups that can be resolved within the same object file are
+# applied correctly
+.align 4
+LBL0:
+
+.fill 12
+
+beq a0, a1, LBL0
+# CHECK-FIXUP: fixup A - offset: 0, value: LBL0, kind: fixup_xtensa_branch_8
+# CHECK-INSTR: beq a0, a1, . -12
+
+beq a0, a1, LBL1
+# CHECK-FIXUP: fixup A - offset: 0, value: LBL1, kind: fixup_xtensa_branch_8
+# CHECK-INSTR: beq a0, a1, . +24
+
+beqz a2, LBL0
+# CHECK-FIXUP: fixup A - offset: 0, value: LBL0, kind: fixup_xtensa_branch_12
+# CHECK-INSTR: beqz a2, . -18
+
+beqz a2, LBL1
+# CHECK-FIXUP: fixup A - offset: 0, value: LBL1, kind: fixup_xtensa_branch_12
+# CHECK-INSTR: beqz a2, . +18
+
+call0 LBL0
+# CHECK-FIXUP: fixup A - offset: 0, value: LBL0, kind: fixup_xtensa_call_18
+# CHECK-INSTR: call0 . -24
+
+call0 LBL2
+# CHECK-FIXUP: fixup A - offset: 0, value: LBL2, kind: fixup_xtensa_call_18
+# CHECK-INSTR: call0 . +2056
+
+j LBL0
+# CHECK-FIXUP: fixup A - offset: 0, value: LBL0, kind: fixup_xtensa_jump_18
+# CHECK-INSTR: j . -30
+
+j LBL2
+# CHECK-FIXUP: fixup A - offset: 0, value: LBL2, kind: fixup_xtensa_jump_18
+# CHECK-INSTR: j . +2047
+
+l32r a1, LBL0
+# CHECK-FIXUP: fixup A - offset: 0, value: LBL0, kind: fixup_xtensa_l32r_16
+# CHECK-INSTR: l32r a1, . -36
+
+LBL1:
+
+.fill 2041
+
+LBL2:
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/lit.local.cfg
@@ -0,0 +1,2 @@
+if not 'Xtensa' in config.root.targets:
+    config.unsupported = True
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/relocations.s
@@ -0,0 +1,177 @@
+# RUN: llvm-mc -triple xtensa < %s -show-encoding \
+# RUN:     | FileCheck -check-prefix=INSTR -check-prefix=FIXUP %s
+# RUN: llvm-mc -filetype=obj -triple xtensa < %s \
+# RUN:     | llvm-readobj -r | FileCheck -check-prefix=RELOC %s
+
+# Check prefixes:
+# RELOC - Check the relocation in the object.
+# FIXUP - Check the fixup on the instruction.
+# INSTR - Check the instruction is handled properly by the ASMPrinter
+
+.long func
+# RELOC: R_XTENSA_32 func
+
+ ball a1, a3, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  ball    a1, a3, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bany a8, a13, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bany    a8, a13, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bbc a8, a7, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bbc     a8, a7, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bbci a3, 16, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bbci    a3, 16, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bbs a12, a5, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bbs     a12, a5, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bbsi a3, 16, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bbsi    a3, 16, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bnall a7, a3, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bnall   a7, a3, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bnone a2, a4, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bnone   a2, a4, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ beq a1, a2, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  beq     a1, a2, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ beq a11, a5, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  beq     a11, a5, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ beqi a1, 256, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  beqi    a1, 256, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ beqi a11, -1, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  beqi    a11, -1, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ beqz a8, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  beqz    a8, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_12
+
+ bge a14, a2, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bge     a14, a2, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bgei a11, -1, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bgei    a11, -1, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bgei a11, 128, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bgei    a11, 128, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bgeu a14, a2, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bgeu    a14, a2, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bgeui a9, 32768, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bgeui   a9, 32768, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bgeui a7, 65536, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bgeui   a7, 65536, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bgeui a7, 64, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bgeui   a7, 64, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bgez a8, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bgez    a8, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_12
+
+ blt a14, a2, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  blt     a14, a2, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ blti a12, -1, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  blti    a12, -1, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ blti a0, 32, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  blti    a0, 32, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bgeu a13, a1, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bgeu    a13, a1, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bltui a7, 16, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bltui   a7, 16, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bltz a6, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bltz    a6, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_12
+
+ bne a3, a4, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bne     a3, a4, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bnei a5, 12, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bnei    a5, 12, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_8
+
+ bnez a5, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  bnez    a5, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_branch_12
+
+ call0  func
+# RELOC: R_XTENSA_SLOT0_OP
+# INST:  call0   func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_call_18
+
+ j func
+# RELOC: R_XTENSA_SLOT0_OP
+# INSTR: j func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_jump_18
+
+ l32r a6, func
+# RELOC: R_XTENSA_SLOT0_OP
+# INSTR: l32r    a6, func
+# FIXUP: fixup A - offset: 0, value: func, kind: fixup_xtensa_l32r_16
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/xtensa-invalid.s
@@ -0,0 +1,73 @@
+# RUN: not llvm-mc  -triple xtensa < %s 2>&1 | FileCheck %s
+
+# Out of range immediates
+
+LBL0:
+
+# imm8
+addi a1, a2, 300
+# CHECK:      error: expected immediate in range [-128, 127]
+
+# imm8
+addi a1, a2, -129
+# CHECK:      error: expected immediate in range [-128, 127]
+
+# imm1_16
+extui  a1, a2, 5, 17
+# CHECK:      error: expected immediate in range [1, 16]
+
+# imm8_sh8
+addmi a1, a2, 33
+# CHECK:      error: expected immediate in range [-32768, 32512], first 8 bits should be zero
+
+# shimm1_31
+slli a1, a2, 0
+# CHECK:      error: expected immediate in range [1, 31]
+
+# uimm4
+srli a1, a2, 16
+# CHECK:      error: expected immediate in range [0, 15]
+
+# uimm5
+ssai 32
+# CHECK:      error: expected immediate in range [0, 31]
+
+# imm64n_4n
+ssai 32
+# CHECK:      error: expected immediate in range [0, 31]
+
+# offset8m8
+s8i a1, a2, 300
+# CHECK:      error: expected immediate in range [0, 255]
+
+# offset16m8
+l16si a1, a2, 512
+# CHECK:      error: expected immediate in range [0, 510], first bit should be zero
+
+# offset32m8
+l32i a1, a2, 1024
+# CHECK:      error: expected immediate in range [0, 1020], first 2 bits should be zero
+
+# b4const
+beqi a1, 257, LBL0
+# CHECK:      error: expected b4const immediate
+
+# b4constu
+bgeui a9, 32000, LBL0
+# CHECK:      error: expected b4constu immediate
+
+# Invalid number of operands
+addi a1, a2 # CHECK: :[[@LINE]]:1: error: too few operands for instruction
+addi a1, a2, 4, 4 # CHECK: :[[@LINE]]:17: error: invalid operand for instruction
+
+# Invalid mnemonics
+aaa a10, a12 # CHECK: :[[@LINE]]:1: error: unrecognized instruction mnemonic
+
+# Invalid register names
+addi a101, sp, 10 # CHECK: :[[@LINE]]:6: error: invalid operand for instruction
+wsr.uregister a2 # CHECK: :[[@LINE]]:1: error: invalid register name
+or r2, sp, a3 # CHECK: :[[@LINE]]:4: error: invalid operand for instruction
+
+# Invalid operand types
+and sp, a2, 10 # CHECK: :[[@LINE]]:13: error: invalid operand for instruction
+addi sp, a1, a2 # CHECK: :[[@LINE]]:14: error: expected immediate in range [-128, 127]
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/xtensa-valid-dbg.s
@@ -0,0 +1,9 @@
+# RUN: llvm-mc %s -triple=xtensa -mattr=+debug -show-encoding \
+# RUN:     | FileCheck -check-prefixes=CHECK,CHECK-INST %s
+
+.align	4
+LBL0:
+
+# CHECK-INST:  break     1, 2
+# CHECK: encoding: [0x20,0x41,0x00]
+ break 1, 2
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/xtensa-valid-exc.s
@@ -0,0 +1,21 @@
+# RUN: llvm-mc %s -triple=xtensa -mattr=+exception -show-encoding \
+# RUN:     | FileCheck -check-prefixes=CHECK,CHECK-INST %s
+
+.align	4
+LBL0:
+
+# CHECK-INST: excw
+# CHECK: encoding: [0x80,0x20,0x00]
+ excw
+ 
+# CHECK-INST: rfde
+# CHECK: encoding: [0x00,0x32,0x00]
+ rfde
+
+# CHECK-INST: rfe
+# CHECK: encoding: [0x00,0x30,0x00]
+ rfe
+
+# CHECK-INST: syscall
+# CHECK: encoding: [0x00,0x50,0x00]
+ syscall
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/xtensa-valid-int.s
@@ -0,0 +1,18 @@
+# RUN: llvm-mc %s -triple=xtensa -mattr=+interrupt -show-encoding \
+# RUN:     | FileCheck -check-prefixes=CHECK,CHECK-INST %s
+
+
+.align	4
+LBL0:
+
+# CHECK-INST:  rfi	1
+# CHECK: encoding: [0x10,0x31,0x00]
+ rfi 1
+
+# CHECK-INST:  rsil	a3, 1
+# CHECK: encoding: [0x30,0x61,0x00]
+ rsil a3, 1
+ 
+# CHECK-INST:  waiti	1
+# CHECK: encoding: [0x00,0x71,0x00]
+ waiti 1
\ No newline at end of file
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/xtensa-valid-mac16.s
@@ -0,0 +1,234 @@
+# RUN: llvm-mc %s -triple=xtensa -mattr=+mac16 -show-encoding \
+# RUN:     | FileCheck -check-prefixes=CHECK,CHECK-INST %s
+
+.align	4
+LBL0:
+
+# CHECK-INST: umul.aa.ll	a2, a3
+# CHECK: encoding: [0x34,0x02,0x70]
+	umul.aa.ll	a2, a3
+# CHECK-INST: umul.aa.lh	a2, a3
+# CHECK: encoding: [0x34,0x02,0x72]
+	umul.aa.lh	a2, a3
+# CHECK-INST: umul.aa.hl	a2, a3
+# CHECK: encoding: [0x34,0x02,0x71]
+	umul.aa.hl	a2, a3
+# CHECK-INST: umul.aa.hh	a2, a3
+# CHECK: encoding: [0x34,0x02,0x73]
+	umul.aa.hh	a2, a3
+
+# CHECK-INST: mul.aa.ll	a2, a3
+# CHECK: encoding: [0x34,0x02,0x74]
+	mul.aa.ll	a2, a3
+# CHECK-INST: mul.aa.lh	a2, a3
+# CHECK: encoding: [0x34,0x02,0x76]
+	mul.aa.lh	a2, a3
+# CHECK-INST: mul.aa.hl	a2, a3
+# CHECK: encoding: [0x34,0x02,0x75]
+	mul.aa.hl	a2, a3
+# CHECK-INST: mul.aa.hh	a2, a3
+# CHECK: encoding: [0x34,0x02,0x77]
+	mul.aa.hh	a2, a3
+	
+# CHECK-INST: mul.ad.ll	a2, m2
+# CHECK: encoding: [0x04,0x02,0x34]
+	mul.ad.ll	a2, m2
+# CHECK-INST: mul.ad.lh	a2, m2
+# CHECK: encoding: [0x04,0x02,0x36]
+	mul.ad.lh	a2, m2
+# CHECK-INST: mul.ad.hl	a2, m2
+# CHECK: encoding: [0x04,0x02,0x35]
+	mul.ad.hl	a2, m2
+# CHECK-INST: mul.ad.hh	a2, m2
+# CHECK: encoding: [0x04,0x02,0x37]
+	mul.ad.hh	a2, m2
+	
+# CHECK-INST: mul.da.ll	m1, a3
+# CHECK: encoding: [0x34,0x40,0x64]
+	mul.da.ll	m1, a3
+# CHECK-INST: mul.da.lh	m1, a3
+# CHECK: encoding: [0x34,0x40,0x66]
+	mul.da.lh	m1, a3
+# CHECK-INST: mul.da.hl	m1, a3
+# CHECK: encoding: [0x34,0x40,0x65]
+	mul.da.hl	m1, a3
+# CHECK-INST: mul.da.hh	m1, a3
+# CHECK: encoding: [0x34,0x40,0x67]
+	mul.da.hh	m1, a3
+	
+# CHECK-INST: mul.dd.ll	m1, m2
+# CHECK: encoding: [0x04,0x40,0x24]
+	mul.dd.ll	m1, m2
+# CHECK-INST: mul.dd.lh	m1, m2
+# CHECK: encoding: [0x04,0x40,0x26]
+	mul.dd.lh	m1, m2
+# CHECK-INST: mul.dd.hl	m1, m2
+# CHECK: encoding: [0x04,0x40,0x25]
+	mul.dd.hl	m1, m2
+# CHECK-INST: mul.dd.hh	m1, m2
+# CHECK: encoding: [0x04,0x40,0x27]
+	mul.dd.hh	m1, m2
+
+# CHECK-INST: mula.aa.ll	a2, a3
+# CHECK: encoding: [0x34,0x02,0x78]
+	mula.aa.ll	a2, a3
+# CHECK-INST: mula.aa.lh	a2, a3
+# CHECK: encoding: [0x34,0x02,0x7a]
+	mula.aa.lh	a2, a3
+# CHECK-INST: mula.aa.hl	a2, a3
+# CHECK: encoding: [0x34,0x02,0x79]
+	mula.aa.hl	a2, a3
+# CHECK-INST: mula.aa.hh	a2, a3
+# CHECK: encoding: [0x34,0x02,0x7b]
+	mula.aa.hh	a2, a3
+
+# CHECK-INST: mula.ad.ll	a2, m2
+# CHECK: encoding: [0x04,0x02,0x38]
+	mula.ad.ll	a2, m2
+# CHECK-INST: mula.ad.lh	a2, m2
+# CHECK: encoding: [0x04,0x02,0x3a]
+	mula.ad.lh	a2, m2
+# CHECK-INST: mula.ad.hl	a2, m2
+# CHECK: encoding: [0x04,0x02,0x39]
+	mula.ad.hl	a2, m2
+# CHECK-INST: mula.ad.hh	a2, m2
+# CHECK: encoding: [0x04,0x02,0x3b]
+	mula.ad.hh	a2, m2
+
+# CHECK-INST: mula.da.ll	m1, a3
+# CHECK: encoding: [0x34,0x40,0x68]
+	mula.da.ll	m1, a3
+# CHECK-INST: mula.da.lh	m1, a3
+# CHECK: encoding: [0x34,0x40,0x6a]
+	mula.da.lh	m1, a3
+# CHECK-INST: mula.da.hl	m1, a3
+# CHECK: encoding: [0x34,0x40,0x69]
+	mula.da.hl	m1, a3
+# CHECK-INST: mula.da.hh	m1, a3
+# CHECK: encoding: [0x34,0x40,0x6b]
+	mula.da.hh	m1, a3
+
+# CHECK-INST: mula.dd.ll	m1, m2
+# CHECK: encoding: [0x04,0x40,0x28]
+	mula.dd.ll	m1, m2
+# CHECK-INST: mula.dd.lh	m1, m2
+# CHECK: encoding: [0x04,0x40,0x2a]
+	mula.dd.lh	m1, m2
+# CHECK-INST: mula.dd.hl	m1, m2
+# CHECK: encoding: [0x04,0x40,0x29]
+	mula.dd.hl	m1, m2
+# CHECK-INST: mula.dd.hh	m1, m2
+# CHECK: encoding: [0x04,0x40,0x2b]
+	mula.dd.hh	m1, m2
+
+# CHECK-INST: muls.aa.ll	a2, a3
+# CHECK: encoding: [0x34,0x02,0x7c]
+	muls.aa.ll	a2, a3
+# CHECK-INST: muls.aa.lh	a2, a3
+# CHECK: encoding: [0x34,0x02,0x7e]
+	muls.aa.lh	a2, a3
+# CHECK-INST: muls.aa.hl	a2, a3
+# CHECK: encoding: [0x34,0x02,0x7d]
+	muls.aa.hl	a2, a3
+# CHECK-INST: muls.aa.hh	a2, a3
+# CHECK: encoding: [0x34,0x02,0x7f]
+	muls.aa.hh	a2, a3
+
+# CHECK-INST: muls.ad.ll	a2, m2
+# CHECK: encoding: [0x04,0x02,0x3c]
+	muls.ad.ll	a2, m2
+# CHECK-INST: muls.ad.lh	a2, m2
+# CHECK: encoding: [0x04,0x02,0x3e]
+	muls.ad.lh	a2, m2
+# CHECK-INST: muls.ad.hl	a2, m2
+# CHECK: encoding: [0x04,0x02,0x3d]
+	muls.ad.hl	a2, m2
+# CHECK-INST: muls.ad.hh	a2, m2
+# CHECK: encoding: [0x04,0x02,0x3f]
+	muls.ad.hh	a2, m2
+
+# CHECK-INST: muls.da.ll	m1, a3
+# CHECK: encoding: [0x34,0x40,0x6c]
+	muls.da.ll	m1, a3
+# CHECK-INST: muls.da.lh	m1, a3
+# CHECK: encoding: [0x34,0x40,0x6e]
+	muls.da.lh	m1, a3
+# CHECK-INST: muls.da.hl	m1, a3
+# CHECK: encoding: [0x34,0x40,0x6d]
+	muls.da.hl	m1, a3
+# CHECK-INST: muls.da.hh	m1, a3
+# CHECK: encoding: [0x34,0x40,0x6f]
+	muls.da.hh	m1, a3
+
+# CHECK-INST: muls.dd.ll	m1, m2
+# CHECK: encoding: [0x04,0x40,0x2c]
+	muls.dd.ll	m1, m2
+# CHECK-INST: muls.dd.lh	m1, m2
+# CHECK: encoding: [0x04,0x40,0x2e]
+	muls.dd.lh	m1, m2
+# CHECK-INST: muls.dd.hl	m1, m2
+# CHECK: encoding: [0x04,0x40,0x2d]
+	muls.dd.hl	m1, m2
+# CHECK-INST: muls.dd.hh	m1, m2
+# CHECK: encoding: [0x04,0x40,0x2f]
+	muls.dd.hh	m1, m2
+
+# CHECK-INST: mula.da.ll.lddec	 m1, a8, m0, a3
+# CHECK: encoding: [0x34,0x18,0x58]
+	mula.da.ll.lddec	 m1, a8, m0, a3
+# CHECK-INST: mula.da.hl.lddec	 m1, a8, m0, a3
+# CHECK: encoding: [0x34,0x18,0x59]
+	mula.da.hl.lddec	 m1, a8, m0, a3
+# CHECK-INST: mula.da.lh.lddec	 m1, a8, m0, a3
+# CHECK: encoding: [0x34,0x18,0x5a]
+	mula.da.lh.lddec	 m1, a8, m0, a3
+# CHECK-INST: mula.da.hh.lddec	 m1, a8, m0, a3
+# CHECK: encoding: [0x34,0x18,0x5b]
+	mula.da.hh.lddec	 m1, a8, m0, a3
+
+# CHECK-INST: mula.dd.ll.lddec	 m1, a8, m0, m2
+# CHECK: encoding: [0x04,0x18,0x18]
+	mula.dd.ll.lddec	 m1, a8, m0, m2
+# CHECK-INST: mula.dd.hl.lddec	 m1, a8, m0, m2
+# CHECK: encoding: [0x04,0x18,0x19]
+	mula.dd.hl.lddec	 m1, a8, m0, m2
+# CHECK-INST: mula.dd.lh.lddec	 m1, a8, m0, m2
+# CHECK: encoding: [0x04,0x18,0x1a]
+	mula.dd.lh.lddec	 m1, a8, m0, m2
+# CHECK-INST: mula.dd.hh.lddec	 m1, a8, m0, m2
+# CHECK: encoding: [0x04,0x18,0x1b]
+	mula.dd.hh.lddec	 m1, a8, m0, m2
+
+# CHECK-INST: mula.da.ll.ldinc	 m1, a8, m0, a3
+# CHECK: encoding: [0x34,0x18,0x48]
+	mula.da.ll.ldinc	 m1, a8, m0, a3
+# CHECK-INST: mula.da.hl.ldinc	 m1, a8, m0, a3
+# CHECK: encoding: [0x34,0x18,0x49]
+	mula.da.hl.ldinc	 m1, a8, m0, a3
+# CHECK-INST: mula.da.lh.ldinc	 m1, a8, m0, a3
+# CHECK: encoding: [0x34,0x18,0x4a]
+	mula.da.lh.ldinc	 m1, a8, m0, a3
+# CHECK-INST: mula.da.hh.ldinc	 m1, a8, m0, a3
+# CHECK: encoding: [0x34,0x18,0x4b]
+	mula.da.hh.ldinc	 m1, a8, m0, a3
+
+# CHECK-INST: mula.dd.ll.ldinc	 m1, a8, m0, m2
+# CHECK: encoding: [0x04,0x18,0x08]
+	mula.dd.ll.ldinc	 m1, a8, m0, m2
+# CHECK-INST: mula.dd.hl.ldinc	 m1, a8, m0, m2
+# CHECK: encoding: [0x04,0x18,0x09]
+	mula.dd.hl.ldinc	 m1, a8, m0, m2
+# CHECK-INST: mula.dd.lh.ldinc	 m1, a8, m0, m2
+# CHECK: encoding: [0x04,0x18,0x0a]
+	mula.dd.lh.ldinc	 m1, a8, m0, m2
+# CHECK-INST: mula.dd.hh.ldinc	 m1, a8, m0, m2
+# CHECK: encoding: [0x04,0x18,0x0b]
+	mula.dd.hh.ldinc	 m1, a8, m0, m2
+
+# CHECK-INST: lddec	 m0, a8
+# CHECK: encoding: [0x04,0x08,0x90]
+	lddec	 m0, a8
+# CHECK-INST: ldinc	 m0, a8
+# CHECK: encoding: [0x04,0x08,0x80]
+	ldinc	 m0, a8
+
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/xtensa-valid-regprotect.s
@@ -0,0 +1,14 @@
+# RUN: llvm-mc %s -triple=xtensa -mattr=+regprotect -show-encoding \
+# RUN:     | FileCheck -check-prefixes=CHECK,CHECK-INST %s
+
+
+.align	4
+LBL0:
+
+# CHECK-INST:  wdtlb	a3, a4
+# CHECK: encoding: [0x30,0xe4,0x50]
+ wdtlb a3, a4
+
+# CHECK-INST:  witlb	a3, a4
+# CHECK: encoding: [0x30,0x64,0x50]
+ witlb a3, a4
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/xtensa-valid-ur.s
@@ -0,0 +1,19 @@
+# RUN: llvm-mc %s -triple=xtensa -mattr=+threadptr -show-encoding \
+# RUN:     | FileCheck -check-prefixes=CHECK,CHECK-INST %s
+
+.align	4
+LBL0:
+
+# CHECK-INST: rur     a3, threadptr
+# CHECK: encoding: [0x70,0x3e,0xe3]
+ rur a3, threadptr
+# CHECK-INST: rur     a3, threadptr
+# CHECK: encoding: [0x70,0x3e,0xe3]
+ rur.threadptr a3
+
+# CHECK-INST: wur     a3, threadptr
+# CHECK: encoding: [0x30,0xe7,0xf3]
+ wur a3, threadptr
+# CHECK-INST: wur     a3, threadptr
+# CHECK: encoding: [0x30,0xe7,0xf3]
+ wur.threadptr a3
--- /dev/null
+++ llvm-10.0.1.src~patched/test/MC/Xtensa/xtensa-valid.s
@@ -0,0 +1,330 @@
+# RUN: llvm-mc %s -triple=xtensa -show-encoding \
+# RUN:     | FileCheck -check-prefixes=CHECK,CHECK-INST %s
+
+
+.align	4
+LBL0:
+
+# CHECK-INST:  abs     a5, a6
+# CHECK: encoding: [0x60,0x51,0x60]
+ abs a5, a6
+
+# CHECK-INST:  add   a3, a9, a4
+# CHECK: encoding: [0x40,0x39,0x80]
+ add a3, a9, a4
+# CHECK-INST:  add a15, a9, a1
+# CHECK: encoding: [0x10,0xf9,0x80]
+ add a15, a9, sp
+
+# CHECK-INST:  addi a8, a1, -128
+# CHECK: encoding: [0x82,0xc1,0x80]
+ addi a8, sp, -128
+# CHECK-INST:  addi a8, a1,  -12
+# CHECK: encoding: [0x82,0xc1,0xf4]
+ addi a8, a1,  -12
+
+# CHECK-INST:  addmi a1, a2, 32512
+# CHECK: encoding: [0x12,0xd2,0x7f]
+ addmi a1, a2, 32512
+
+# CHECK-INST:  addx2   a2, a1, a5
+# CHECK: encoding: [0x50,0x21,0x90]
+ addx2 a2, sp, a5
+# CHECK-INST:  addx4   a3, a1, a6
+# CHECK: encoding: [0x60,0x31,0xa0]
+ addx4 a3, sp, a6
+# CHECK-INST:  addx8   a4, a1, a7
+# CHECK: encoding: [0x70,0x41,0xb0]
+ addx8 a4, sp, a7
+
+# CHECK-INST:  ball    a1, a3, LBL0
+# CHECK: encoding: [0x37,0x41,A]
+ ball a1, a3, LBL0
+# CHECK-INST:  bany    a8, a13, LBL0
+# CHECK: encoding: [0xd7,0x88,A]
+ bany a8, a13, LBL0
+# CHECK-INST:  bbc     a8, a7, LBL0
+# CHECK: encoding: [0x77,0x58,A]
+ bbc a8, a7, LBL0
+# CHECK-INST:  bbci    a3, 16, LBL0
+# CHECK: encoding: [0x07,0x73,A]
+ bbci a3, 16, LBL0
+# CHECK-INST:  bbs     a12, a5, LBL0
+# CHECK: encoding: [0x57,0xdc,A]
+ bbs a12, a5, LBL0
+# CHECK-INST:  bbsi    a3, 16, LBL0
+# CHECK: encoding: [0x07,0xf3,A]
+ bbsi a3, 16, LBL0
+# CHECK-INST:  bnall   a7, a3, LBL0
+# CHECK: encoding: [0x37,0xc7,A]
+ bnall a7, a3, LBL0
+# CHECK-INST:  bnone   a2, a4, LBL0
+# CHECK: encoding: [0x47,0x02,A]
+ bnone a2, a4, LBL0
+
+# CHECK-INST:  beq     a1, a2, LBL0
+# CHECK: encoding: [0x27,0x11,A]
+ beq a1, a2, LBL0
+# CHECK-INST:  beq     a11, a5, LBL0
+# CHECK: encoding: [0x57,0x1b,A]
+ beq a11, a5, LBL0
+# CHECK-INST:  beqi    a1, 256, LBL0
+# CHECK: encoding: [0x26,0xf1,A]
+ beqi a1, 256, LBL0
+# CHECK-INST:  beqi    a11, -1, LBL0
+# CHECK: encoding: [0x26,0x0b,A]
+ beqi a11, -1, LBL0
+# CHECK-INST:  beqz    a8, LBL0
+# CHECK: encoding: [0x16,0bAAAA1000,A]
+ beqz a8, LBL0
+# CHECK-INST:  bge     a14, a2, LBL0
+# CHECK: encoding: [0x27,0xae,A]
+ bge a14, a2, LBL0
+# CHECK-INST:  bgei    a11, -1, LBL0
+# CHECK: encoding: [0xe6,0x0b,A]
+ bgei a11, -1, LBL0
+# CHECK-INST:  bgei    a11, 128, LBL0
+# CHECK: encoding: [0xe6,0xeb,A]
+ bgei a11, 128, LBL0
+# CHECK-INST:  bgeu    a14, a2, LBL0
+# CHECK: encoding: [0x27,0xbe,A]
+ bgeu a14, a2, LBL0
+# CHECK-INST:  bgeui   a9, 32768, LBL0
+# CHECK: encoding: [0xf6,0x09,A]
+ bgeui a9, 32768, LBL0
+# CHECK-INST:  bgeui   a7, 65536, LBL0
+# CHECK: encoding: [0xf6,0x17,A]
+ bgeui a7, 65536, LBL0
+# CHECK-INST:  bgeui   a7, 64, LBL0
+# CHECK: encoding: [0xf6,0xd7,A]
+ bgeui a7, 64, LBL0
+# CHECK-INST:  bgez    a8, LBL0
+# CHECK: encoding: [0xd6,0bAAAA1000,A]
+ bgez a8, LBL0
+# CHECK-INST:  blt     a14, a2, LBL0
+# CHECK: encoding: [0x27,0x2e,A]
+ blt a14, a2, LBL0
+# CHECK-INST:  blti    a12, -1, LBL0
+# CHECK: encoding: [0xa6,0x0c,A]
+ blti a12, -1, LBL0
+# CHECK-INST:  blti    a0, 32, LBL0
+# CHECK: encoding: [0xa6,0xc0,A]
+ blti a0, 32, LBL0
+# CHECK-INST:  bgeu    a13, a1, LBL0
+# CHECK: encoding: [0x17,0xbd,A]
+ bgeu a13, a1, LBL0
+# CHECK-INST:  bltui   a7, 16, LBL0
+# CHECK: encoding: [0xb6,0xb7,A]
+ bltui a7, 16, LBL0
+# CHECK-INST:  bltz    a6, LBL0
+# CHECK: encoding: [0x96,0bAAAA0110,A]
+ bltz a6, LBL0
+# CHECK-INST:  bne     a3, a4, LBL0
+# CHECK: encoding: [0x47,0x93,A]
+ bne a3, a4, LBL0
+# CHECK-INST:  bnei    a5, 12, LBL0
+# CHECK: encoding: [0x66,0xa5,A]
+ bnei a5, 12, LBL0
+# CHECK-INST:  bnez    a5, LBL0
+# CHECK: encoding: [0x56,0bAAAA0101,A]
+ bnez a5, LBL0
+
+# CHECK-INST:  call0   LBL0
+# CHECK: encoding: [0bAA000101,A,A]
+ call0  LBL0
+# CHECK-INST:  callx0  a1
+# CHECK: encoding: [0xc0,0x01,0x00]
+ callx0 a1
+# CHECK-INST:  dsync
+# CHECK: encoding: [0x30,0x20,0x00]
+ dsync
+# CHECK-INST:  esync
+# CHECK: encoding: [0x20,0x20,0x00]
+ esync
+
+# CHECK-INST:  extui    a1, a2, 7, 8
+# CHECK: encoding: [0x20,0x17,0x74]
+ extui a1, a2, 7, 8
+
+# CHECK-INST:  extw
+# CHECK: encoding: [0xd0,0x20,0x00]
+ extw
+
+# CHECK-INST:  isync
+# CHECK: encoding: [0x00,0x20,0x00]
+ isync
+
+# CHECK-INST:  j       LBL0
+# CHECK: encoding: [0bAA000110,A,A]
+ j LBL0
+# CHECK-INST:  jx      a2
+# CHECK: encoding: [0xa0,0x02,0x00]
+ jx a2
+
+# CHECK-INST:  l8ui    a2, a1, 3
+# CHECK: encoding: [0x22,0x01,0x03]
+ l8ui a2, sp, 3
+# CHECK-INST:  l16si   a3, a1, 4
+# CHECK: encoding: [0x32,0x91,0x02]
+ l16si a3, sp, 4
+# CHECK-INST: l16ui   a4, a1, 6
+# CHECK: encoding: [0x42,0x11,0x03]
+ l16ui a4, sp, 6
+# CHECK-INST: l32i    a5, a1, 8
+# CHECK: encoding: [0x52,0x21,0x02]
+ l32i a5, sp, 8
+# CHECK-INST: l32r    a6, LBL0
+# CHECK: encoding: [0x61,A,A]
+ l32r a6, LBL0
+
+# CHECK-INST: memw
+# CHECK: encoding: [0xc0,0x20,0x00]
+ memw
+
+# CHECK-INST: moveqz  a2, a3, a4
+# CHECK: encoding: [0x40,0x23,0x83]
+ moveqz  a2,a3,a4
+# CHECK-INST: movgez  a3, a11, a12
+# CHECK: encoding: [0xc0,0x3b,0xb3]
+ movgez  a3,a11,a12
+
+# CHECK-INST: movi    a1, -2048
+# CHECK: encoding: [0x12,0xa8,0x00]
+ movi  a1, -2048
+
+# CHECK-INST: movltz  a7, a8, a9
+# CHECK: encoding: [0x90,0x78,0xa3]
+ movltz a7, a8, a9
+# CHECK-INST: movnez  a10, a11, a12
+# CHECK: encoding: [0xc0,0xab,0x93]
+ movnez a10,a11, a12
+
+# CHECK-INST: neg     a1, a3
+# CHECK: encoding: [0x30,0x10,0x60]
+ neg a1, a3
+
+# CHECK-INST: nop
+# CHECK: encoding: [0xf0,0x20,0x00]
+ nop
+
+# CHECK-INST: or      a4, a5, a6
+# CHECK: encoding: [0x60,0x45,0x20]
+ or a4, a5, a6
+
+# CHECK-INST: rer     a3, a4
+# CHECK: encoding: [0x30,0x64,0x40]
+ rer a3, a4
+ 
+# CHECK-INST: ret
+# CHECK: encoding: [0x80,0x00,0x00]
+ ret
+
+# CHECK-INST: rsr     a8, sar
+# CHECK: encoding: [0x80,0x03,0x03]
+ rsr a8, sar
+# CHECK-INST: rsr     a8, sar
+# CHECK: encoding: [0x80,0x03,0x03]
+ rsr.sar a8
+ # CHECK-INST: rsr     a8, sar
+# CHECK: encoding: [0x80,0x03,0x03]
+ rsr a8, 3
+
+
+# CHECK-INST: rsync
+# CHECK: encoding: [0x10,0x20,0x00]
+ rsync
+
+# CHECK-INST: s8i     a2, a1, 3
+# CHECK: encoding: [0x22,0x41,0x03]
+ s8i a2, sp, 3
+# CHECK-INST: s16i    a3, a1, 4
+# CHECK: encoding: [0x32,0x51,0x02]
+ s16i a3, sp, 4
+# CHECK-INST: s32i    a5, a1, 8
+# CHECK: encoding: [0x52,0x61,0x02]
+ s32i a5, sp, 8
+
+# CHECK-INST: sll     a10, a11
+# CHECK: encoding: [0x00,0xab,0xa1]
+ sll a10, a11
+
+# CHECK-INST: slli    a5, a1, 15
+# CHECK: encoding: [0x10,0x51,0x11]
+ slli a5, a1, 15
+
+# CHECK-INST: sra     a12, a3
+# CHECK: encoding: [0x30,0xc0,0xb1]
+ sra a12, a3
+
+# CHECK-INST: srai    a8, a5, 0
+# CHECK: encoding: [0x50,0x80,0x21]
+ srai a8, a5, 0
+
+# CHECK-INST: src     a3, a4, a5
+# CHECK: encoding: [0x50,0x34,0x81]
+ src a3, a4, a5
+
+# CHECK-INST: srl     a6, a7
+# CHECK: encoding: [0x70,0x60,0x91]
+ srl a6, a7
+
+# CHECK-INST: srli    a3, a4, 8
+# CHECK: encoding: [0x40,0x38,0x41]
+ srli a3, a4, 8
+
+# CHECK-INST: ssa8l   a14
+# CHECK: encoding: [0x00,0x2e,0x40]
+ ssa8l a14
+
+# CHECK-INST: ssai    31
+# CHECK: encoding: [0x10,0x4f,0x40]
+ ssai 31
+
+# CHECK-INST: ssl     a0
+# CHECK: encoding: [0x00,0x10,0x40]
+ ssl a0
+
+# CHECK-INST: ssr     a2
+# CHECK: encoding: [0x00,0x02,0x40]
+ ssr a2
+
+# CHECK-INST: sub     a8, a2, a1
+# CHECK: encoding: [0x10,0x82,0xc0]
+ sub  a8, a2, a1
+# CHECK-INST: subx2   a2, a1, a5
+# CHECK: encoding: [0x50,0x21,0xd0]
+ subx2 a2, sp, a5
+# CHECK-INST: subx4   a3, a1, a6
+# CHECK: encoding: [0x60,0x31,0xe0]
+ subx4 a3, sp, a6
+# CHECK-INST: subx8   a4, a1, a7
+# CHECK: encoding: [0x70,0x41,0xf0]
+ subx8 a4, sp, a7
+
+# CHECK-INST: wer     a3, a4
+# CHECK: encoding: [0x30,0x74,0x40]
+ wer a3, a4
+
+# CHECK-INST: wsr     a8, sar
+# CHECK: encoding: [0x80,0x03,0x13]
+ wsr a8, sar
+# CHECK-INST: wsr     a8, sar
+# CHECK: encoding: [0x80,0x03,0x13]
+ wsr.sar a8
+# CHECK-INST: wsr     a8, sar
+# CHECK: encoding: [0x80,0x03,0x13]
+ wsr a8, 3
+
+# CHECK-INST: xor     a6, a4, a5
+# CHECK: encoding: [0x50,0x64,0x30]
+ xor a6, a4, a5
+
+# CHECK-INST: xsr     a8, sar
+# CHECK: encoding: [0x80,0x03,0x61]
+ xsr a8, sar
+# CHECK-INST: xsr     a8, sar
+# CHECK: encoding: [0x80,0x03,0x61
+ xsr.sar a8
+# CHECK-INST: xsr     a8, sar
+# CHECK: encoding: [0x80,0x03,0x61
+ xsr a8, 3
--- llvm-10.0.1.src/test/Object/obj2yaml.test
+++ llvm-10.0.1.src~patched/test/Object/obj2yaml.test
@@ -656,6 +656,25 @@ Symbols:
   - Name:    puts
     Binding: STB_GLOBAL
 
+# RUN: yaml2obj --docnum=2 %s -o %t-xtensa
+# RUN: obj2yaml %t-xtensa | FileCheck %s --check-prefix ELF-XTENSA
+
+# ELF-XTENSA:      FileHeader:
+# ELF-XTENSA-NEXT:   Class:           ELFCLASS32
+# ELF-XTENSA-NEXT:   Data:            ELFDATA2LSB
+# ELF-XTENSA-NEXT:   Type:            ET_EXEC
+# ELF-XTENSA-NEXT:   Machine:         EM_XTENSA
+## As EF_XTENSA_MACH_NONE == 0, it is always printed by obj2yaml.
+# ELF-XTENSA-NEXT:   Flags:           [ EF_XTENSA_XT_INSN, EF_XTENSA_MACH_NONE, EF_XTENSA_XT_LIT ]
+
+--- !ELF
+FileHeader:
+  Class:           ELFCLASS32
+  Data:            ELFDATA2LSB
+  Type:            ET_EXEC
+  Machine:         EM_XTENSA
+  Flags:           [ EF_XTENSA_XT_INSN, EF_XTENSA_XT_LIT ]
+
 # RUN: obj2yaml %p/Inputs/trivial-object-test.elf-avr | FileCheck %s --check-prefix ELF-AVR
 
 # ELF-AVR:      FileHeader:
--- /dev/null
+++ llvm-10.0.1.src~patched/test/tools/llvm-readobj/ELF/reloc-types-xtensa.test
@@ -0,0 +1,182 @@
+## Test that llvm-readobj shows proper relocation type
+## names and values for the Xtensa target.
+
+# RUN: yaml2obj %s -o %t-xtensa.o
+# RUN: llvm-readobj -r --expand-relocs %t-xtensa.o | FileCheck %s
+
+# CHECK: Type: R_XTENSA_NONE (0)
+# CHECK: Type: R_XTENSA_32 (1)
+# CHECK: Type: R_XTENSA_RTLD (2)
+# CHECK: Type: R_XTENSA_GLOB_DAT (3)
+# CHECK: Type: R_XTENSA_JMP_SLOT (4)
+# CHECK: Type: R_XTENSA_RELATIVE (5)
+# CHECK: Type: R_XTENSA_PLT (6)
+# CHECK: Type: R_XTENSA_OP0 (8)
+# CHECK: Type: R_XTENSA_OP1 (9)
+# CHECK: Type: R_XTENSA_OP2 (10)
+# CHECK: Type: R_XTENSA_ASM_EXPAND (11)
+# CHECK: Type: R_XTENSA_ASM_SIMPLIFY (12)
+# CHECK: Type: R_XTENSA_32_PCREL (14)
+# CHECK: Type: R_XTENSA_GNU_VTINHERIT (15)
+# CHECK: Type: R_XTENSA_GNU_VTENTRY (16)
+# CHECK: Type: R_XTENSA_DIFF8 (17)
+# CHECK: Type: R_XTENSA_DIFF16 (18)
+# CHECK: Type: R_XTENSA_DIFF32 (19)
+# CHECK: Type: R_XTENSA_SLOT0_OP (20)
+# CHECK: Type: R_XTENSA_SLOT1_OP (21)
+# CHECK: Type: R_XTENSA_SLOT2_OP (22)
+# CHECK: Type: R_XTENSA_SLOT3_OP (23)
+# CHECK: Type: R_XTENSA_SLOT4_OP (24)
+# CHECK: Type: R_XTENSA_SLOT5_OP (25)
+# CHECK: Type: R_XTENSA_SLOT6_OP (26)
+# CHECK: Type: R_XTENSA_SLOT7_OP (27)
+# CHECK: Type: R_XTENSA_SLOT8_OP (28)
+# CHECK: Type: R_XTENSA_SLOT9_OP (29)
+# CHECK: Type: R_XTENSA_SLOT10_OP (30)
+# CHECK: Type: R_XTENSA_SLOT11_OP (31)
+# CHECK: Type: R_XTENSA_SLOT12_OP (32)
+# CHECK: Type: R_XTENSA_SLOT13_OP (33)
+# CHECK: Type: R_XTENSA_SLOT14_OP (34)
+# CHECK: Type: R_XTENSA_SLOT0_ALT (35)
+# CHECK: Type: R_XTENSA_SLOT1_ALT (36)
+# CHECK: Type: R_XTENSA_SLOT2_ALT (37)
+# CHECK: Type: R_XTENSA_SLOT3_ALT (38)
+# CHECK: Type: R_XTENSA_SLOT4_ALT (39)
+# CHECK: Type: R_XTENSA_SLOT5_ALT (40)
+# CHECK: Type: R_XTENSA_SLOT6_ALT (41)
+# CHECK: Type: R_XTENSA_SLOT7_ALT (42)
+# CHECK: Type: R_XTENSA_SLOT8_ALT (43)
+# CHECK: Type: R_XTENSA_SLOT9_ALT (44)
+# CHECK: Type: R_XTENSA_SLOT10_ALT (45)
+# CHECK: Type: R_XTENSA_SLOT11_ALT (46)
+# CHECK: Type: R_XTENSA_SLOT12_ALT (47)
+# CHECK: Type: R_XTENSA_SLOT13_ALT (48)
+# CHECK: Type: R_XTENSA_SLOT14_ALT (49)
+# CHECK: Type: R_XTENSA_TLSDESC_FN (50)
+# CHECK: Type: R_XTENSA_TLSDESC_ARG (51)
+# CHECK: Type: R_XTENSA_TLS_DTPOFF (52)
+# CHECK: Type: R_XTENSA_TLS_TPOFF (53)
+# CHECK: Type: R_XTENSA_TLS_FUNC (54)
+# CHECK: Type: R_XTENSA_TLS_ARG (55)
+# CHECK: Type: R_XTENSA_TLS_CALL (56)
+
+--- !ELF
+FileHeader:
+  Class:   ELFCLASS32
+  Data:    ELFDATA2LSB
+  Type:    ET_REL
+  Machine: EM_XTENSA
+Sections:
+  - Name:         .rela.text
+    Type:         SHT_RELA
+    Relocations:
+       - Offset: 0x0000000000000000
+         Type:   R_XTENSA_NONE
+       - Offset: 0x0000000000000004
+         Type:   R_XTENSA_32
+       - Offset: 0x0000000000000008
+         Type:   R_XTENSA_RTLD
+       - Offset: 0x000000000000000C
+         Type:   R_XTENSA_GLOB_DAT
+       - Offset: 0x0000000000000010
+         Type:   R_XTENSA_JMP_SLOT
+       - Offset: 0x0000000000000014
+         Type:   R_XTENSA_RELATIVE
+       - Offset: 0x0000000000000018
+         Type:   R_XTENSA_PLT
+       - Offset: 0x000000000000001C
+         Type:   R_XTENSA_OP0
+       - Offset: 0x0000000000000020
+         Type:   R_XTENSA_OP1
+       - Offset: 0x0000000000000024
+         Type:   R_XTENSA_OP2
+       - Offset: 0x0000000000000028
+         Type:   R_XTENSA_ASM_EXPAND
+       - Offset: 0x000000000000002C
+         Type:   R_XTENSA_ASM_SIMPLIFY
+       - Offset: 0x0000000000000030
+         Type:   R_XTENSA_32_PCREL
+       - Offset: 0x0000000000000034
+         Type:   R_XTENSA_GNU_VTINHERIT
+       - Offset: 0x0000000000000038
+         Type:   R_XTENSA_GNU_VTENTRY
+       - Offset: 0x000000000000003C
+         Type:   R_XTENSA_DIFF8
+       - Offset: 0x0000000000000040
+         Type:   R_XTENSA_DIFF16
+       - Offset: 0x0000000000000044
+         Type:   R_XTENSA_DIFF32
+       - Offset: 0x0000000000000048
+         Type:   R_XTENSA_SLOT0_OP
+       - Offset: 0x000000000000004C
+         Type:   R_XTENSA_SLOT1_OP
+       - Offset: 0x0000000000000050
+         Type:   R_XTENSA_SLOT2_OP
+       - Offset: 0x0000000000000054
+         Type:   R_XTENSA_SLOT3_OP
+       - Offset: 0x0000000000000058
+         Type:   R_XTENSA_SLOT4_OP
+       - Offset: 0x000000000000005C
+         Type:   R_XTENSA_SLOT5_OP
+       - Offset: 0x0000000000000060
+         Type:   R_XTENSA_SLOT6_OP
+       - Offset: 0x0000000000000064
+         Type:   R_XTENSA_SLOT7_OP
+       - Offset: 0x0000000000000068
+         Type:   R_XTENSA_SLOT8_OP
+       - Offset: 0x000000000000006C
+         Type:   R_XTENSA_SLOT9_OP
+       - Offset: 0x0000000000000070
+         Type:   R_XTENSA_SLOT10_OP
+       - Offset: 0x0000000000000074
+         Type:   R_XTENSA_SLOT11_OP
+       - Offset: 0x0000000000000078
+         Type:   R_XTENSA_SLOT12_OP
+       - Offset: 0x000000000000007C
+         Type:   R_XTENSA_SLOT13_OP
+       - Offset: 0x0000000000000080
+         Type:   R_XTENSA_SLOT14_OP
+       - Offset: 0x0000000000000084
+         Type:   R_XTENSA_SLOT0_ALT
+       - Offset: 0x0000000000000088
+         Type:   R_XTENSA_SLOT1_ALT
+       - Offset: 0x000000000000008C
+         Type:   R_XTENSA_SLOT2_ALT
+       - Offset: 0x0000000000000090
+         Type:   R_XTENSA_SLOT3_ALT
+       - Offset: 0x0000000000000094
+         Type:   R_XTENSA_SLOT4_ALT
+       - Offset: 0x0000000000000098
+         Type:   R_XTENSA_SLOT5_ALT
+       - Offset: 0x000000000000009C
+         Type:   R_XTENSA_SLOT6_ALT
+       - Offset: 0x00000000000000A0
+         Type:   R_XTENSA_SLOT7_ALT
+       - Offset: 0x00000000000000A4
+         Type:   R_XTENSA_SLOT8_ALT
+       - Offset: 0x00000000000000A8
+         Type:   R_XTENSA_SLOT9_ALT
+       - Offset: 0x00000000000000AC
+         Type:   R_XTENSA_SLOT10_ALT
+       - Offset: 0x00000000000000B0
+         Type:   R_XTENSA_SLOT11_ALT
+       - Offset: 0x00000000000000B4
+         Type:   R_XTENSA_SLOT12_ALT
+       - Offset: 0x00000000000000B8
+         Type:   R_XTENSA_SLOT13_ALT
+       - Offset: 0x00000000000000BC
+         Type:   R_XTENSA_SLOT14_ALT
+       - Offset: 0x00000000000000C0
+         Type:   R_XTENSA_TLSDESC_FN
+       - Offset: 0x00000000000000C4
+         Type:   R_XTENSA_TLSDESC_ARG
+       - Offset: 0x00000000000000C8
+         Type:   R_XTENSA_TLS_DTPOFF
+       - Offset: 0x00000000000000CC
+         Type:   R_XTENSA_TLS_TPOFF
+       - Offset: 0x00000000000000D0
+         Type:   R_XTENSA_TLS_FUNC
+       - Offset: 0x00000000000000D4
+         Type:   R_XTENSA_TLS_ARG
+       - Offset: 0x00000000000000D8
+         Type:   R_XTENSA_TLS_CALL
--- llvm-10.0.1.src/unittests/ADT/TripleTest.cpp
+++ llvm-10.0.1.src~patched/unittests/ADT/TripleTest.cpp
@@ -579,6 +579,18 @@ TEST(TripleTest, ParsedIDs) {
   EXPECT_EQ(Triple::UnknownEnvironment, T.getEnvironment());
   EXPECT_TRUE(T.isArch32Bit());
 
+  T = Triple("xtensa");
+  EXPECT_EQ(Triple::xtensa, T.getArch());
+  EXPECT_EQ(Triple::UnknownVendor, T.getVendor());
+  EXPECT_EQ(Triple::UnknownOS, T.getOS());
+  EXPECT_EQ(Triple::UnknownEnvironment, T.getEnvironment());
+
+  T = Triple("xtensa-unknown-unknown");
+  EXPECT_EQ(Triple::xtensa, T.getArch());
+  EXPECT_EQ(Triple::UnknownVendor, T.getVendor());
+  EXPECT_EQ(Triple::UnknownOS, T.getOS());
+  EXPECT_EQ(Triple::UnknownEnvironment, T.getEnvironment());
+
   T = Triple("huh");
   EXPECT_EQ(Triple::UnknownArch, T.getArch());
 }
@@ -904,6 +916,11 @@ TEST(TripleTest, BitWidthPredicates) {
   EXPECT_FALSE(T.isArch32Bit());
   EXPECT_TRUE(T.isArch64Bit());
   EXPECT_TRUE(T.isRISCV());
+
+  T.setArch(Triple::xtensa);
+  EXPECT_FALSE(T.isArch16Bit());
+  EXPECT_TRUE(T.isArch32Bit());
+  EXPECT_FALSE(T.isArch64Bit());
 }
 
 TEST(TripleTest, BitWidthArchVariants) {
@@ -1050,6 +1067,10 @@ TEST(TripleTest, BitWidthArchVariants) {
   T.setArch(Triple::xcore);
   EXPECT_EQ(Triple::xcore, T.get32BitArchVariant().getArch());
   EXPECT_EQ(Triple::UnknownArch, T.get64BitArchVariant().getArch());
+
+  T.setArch(Triple::xtensa);
+  EXPECT_EQ(Triple::xtensa, T.get32BitArchVariant().getArch());
+  EXPECT_EQ(Triple::UnknownArch, T.get64BitArchVariant().getArch());
 }
 
 TEST(TripleTest, EndianArchVariants) {
--- llvm-10.0.1.src/utils/gn/secondary/llvm/include/llvm/IR/BUILD.gn
+++ llvm-10.0.1.src~patched/utils/gn/secondary/llvm/include/llvm/IR/BUILD.gn
@@ -157,6 +157,16 @@ tablegen("IntrinsicsXCore") {
   td_file = "Intrinsics.td"
 }
 
+tablegen("IntrinsicsXtensa") {
+  visibility = [ ":public_tablegen" ]
+  output_name = "IntrinsicsXtensa.h"
+  args = [
+    "-gen-intrinsic-enums",
+    "-intrinsic-prefix=xtensa",
+  ]
+  td_file = "Intrinsics.td"
+}
+
 # Groups all tablegen() calls that create .inc files that are included in
 # IR's public headers.  //llvm/lib/IR has this as a public_dep, so targets
 # depending on //llvm/lib/IR don't need to depend on this.  This exists
@@ -185,5 +195,6 @@ group("public_tablegen") {
     ":IntrinsicsWebAssembly",
     ":IntrinsicsX86",
     ":IntrinsicsXCore",
+    ":IntrinsicsXtensa",
   ]
 }
